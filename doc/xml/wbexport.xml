<section id="command-export">
    <title>Export data - WbExport</title>

		<para>
			Exports the result of the <emphasis role="bold">next</emphasis>
			SQL statement (which has to produce a result set) to a file without
			loading the data into memory. If you want to save the data that is
			currently displayed in the result area into an external file, please
			use the <link linkend="export">Save Data as</link> feature.
		</para>
		
    <para>If you want to simply export the contents of one or more tables,
      the <literal>-sourcetable</literal> switch can be used to specify the
      tables. In this case no additional SELECT statement is necessary.
      You can also use the <link linkend="dbexplorer-spool">Database Explorer</link>
      to export multiple tables.
    </para>
		
		<note><para>
			When using a <literal>SELECT</literal> based export, you have to 
			run both statements (<literal>WbExport</literal> and <literal>SELECT</literal>)
			as one script. Either select both statements in the editor and choose
			<menuchoice><guimenu>SQL</guimenu><guimenuitem>Execute selected</guimenuitem></menuchoice>, 
			or make the two statements the only statements in the editor and choose
			<menuchoice><guimenu>SQL</guimenu><guimenuitem>Execute all</guimenuitem></menuchoice>.
		</para></note>
		
		
    <para>
      You can also export the result of a <literal>SELECT</literal> statement, by
      selecting the statment in the editor, and then choose
      <menuchoice><guimenu>SQL</guimenu><guimenuitem>Export query result</guimenuitem></menuchoice>.
    </para>
		
		<para>
			When exporting data into a Text or XML file, the content of BLOB columns
			is written into separate files. One file for each column of each row. Text files 
			that are created this way can most probably only be imported using &wb-productname; as 
			the main file will contain the filename of the BLOB data file instead of the actual BLOB data.
			The only other application that I know of, that can handle this type of imports is Oracle's 
			<literal>SQL*Loader</literal> utility. If you run the text export together with the 
			parameter <literal>-writeoracleloader=true</literal> the control file will contain the 
			approriate definitions to read the BLOB data from the external file.
		</para>
		
    <para>The command supports the following parameters:</para>

    <informaltable frame="all">
      <tgroup cols="2" align="left">
        <colspec colname="c1" colwidth="4cm" />
        <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>

          <tbody valign="top">
              <row>
              <entry>-type</entry>

              <entry>
								<para>
									Possible values: <literal>text, sqlinsert, sqlupdate, sqldeleteinsert, xml, html</literal>
								</para>
                <para>
                  Defines the type of the output file. <literal>sqlinsert</literal>
                  will create the necessary <literal>INSERT</literal> statements to put
                  the data into a table. If the records may already exist in the target table
                  but you don't want to (or cannot) delete the content of the table
                  before running the generated script, &wb-productname; can create a DELETE
                  statement for every <literal>INSERT</literal> statement. To create this
                  kind of script, use the <literal>sqldeleteinsert</literal> type.
                </para>
                <para>
                  In order for this to work properly the table needs to have keycolumns defined,
                  or you have to define the keycolumns manually using the <literal>-keycolumns</literal>
                  switch.
                </para>
                <para>
                  <literal>sqlupdate</literal> will generate UPDATE
                  statements that update all non-key columns of the table. This will only
                  generate valid <literal>UPDATE</literal> statements if at least one key
                  column is present. If the table does not have key columns defined, or you
                  want to use different columns, they can be specified using the <literal>-keycolumns</literal>
                  switch.
                </para>
              </entry>
          </row>

          <row>
              <entry>-file</entry>
              <entry>
									Defines the name of the output file. If the file name 
									contains spaces, a dash or other special characters it has to 
									put in single quotes: <literal>-file='c:\my files\test-data.txt'</literal>
              </entry>
          </row>

          <row>
              <entry>-sourcetable</entry>
              <entry>
							<para>Defines a list of tables to be exported. If this
              switch is used, <literal>-outputdir</literal> is also required
              unless exactly one table is specified. If one table is
              specified, the -file parameter is used to generate the file
              for the table. If more then one table is specified, the
              <literal>-outputdir</literal> parameter is used to defined
              the directory where the generated files should be stored.
              Each file will be named as the exported table with the approriate
              extension (.xml, .sql, etc). You can specify * as the table
              name which will then export all tables accessible by the
              current user.
              </para>
              <para>If you want to export tables from a different user
              or schema you can use a schema name combined with a wildcard
              e.g. <literal> -sourcetable=otheruser.*</literal>. In this case
              the generated output files will contain the schema name as part of the
              filename (e.g. <literal>otheruser.person.txt</literal>).
              When <link linkend="command-import">importing</link> these files,
              &wb-productname; will try to import the tables into the schema/user
              specified in the filename. If you want to import them into
              a different user/schema, then you have to use the <literal>-schema</literal>
              switch for the <link linkend="command-import">import</link> command.
              </para>
              </entry>
          </row>
          <row>
              <entry>-outputDir</entry>
              <entry>When using the <literal>-sourcetable</literal> switch
              with multiple tables, this parameter is mandatory and defines
              the directory where the generated files should be stored.
              </entry>
          </row>
          <row>
              <entry>-continueOnError</entry>
              <entry>When exporting more than one table, this parameter controls
							whether the whole export will be terminated if an error occurs during 
							export of one of the tables.
              </entry>
          </row>
          <row>
              <entry>-encoding</entry>
              <entry>Defines the encoding in which the file should be
              written. Common encodings are ISO-8859-1, ISO-8859-15, UTF-8 (or UTF8).
              To get a list of available encodings, execut <literal>WbExport</literal>
              with the parameter <literal>-showencoding</literal>
              </entry>
          </row>
					<row>
						<entry>-showEncodings</entry>
						<entry>Displays the encodings supported by your Java version and
								operating system. If this parameter is present, all other parameters are ignored.
						</entry>
					</row>
					<row>
            <entry>-lineEnding</entry>
            <entry>
							<para>Possible values are: <literal>crlf</literal>, <literal>lf</literal></para>
							<para>
								Defines the line ending to be used for XML or text files. 
								<literal>crlf</literal> puts the ASCII characters #13 and #10 after each line. 
								This is the standard format on Windows based systems. <literal>dos</literal> and
								<literal>win</literal> are synonym values for <literal>crlf</literal>,
								<literal>unix</literal> is a synonym for <literal>lf</literal>.
							</para>
							<para>
								<literal>lf</literal> puts only the ASCII character #10 at the end of each line. 
								This is the standard format on Unix based systems (<literal>unix</literal> 
								is a synonym value for this format).
							</para>
							<para>
								The default line ending used depends on the platform where &wb-productname; is running.
							</para>
            </entry>
          </row>
          <row>
            <entry>-compress</entry>
            <entry>
							<para>
								Selects whether the output file should be compressed 
								and put into a ZIP archive. An archive will be created with the name of the specified outputfile
								but with the extension <literal>zip</literal>. The archive will then contain the specified file 
								(e.g. if you specify <literal>data.txt</literal>, an archive <literal>data.zip</literal>
								will be created containing exactly one entry with the name <literal>data.txt</literal>).
								If the exported result set contains BLOBs, they will be stored in a separate archive, named 
								<literal>data_lobs.zip</literal>.
							</para>
							<para>
								When exporting multiple tables using the <literal>-sourcetable</literal> parameter, 
								then &wb-productname; will create one ZIP archive for each table in the specified output 
								directory with the filename <literal>"tablename".zip</literal>. For any table containing 
								BLOB data, one additional ZIP archive is created.
							</para>
            </entry>
          </row>
					<row>
						<entry>-clobAsFile</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								For SQL, XML and Text export this controls how the contents of CLOB fields 
								are exported. Usually the CLOB content is put directly into the output file
								When generating SQL scripts with WbExport this can be a problem as not all 
								DBMS can cope with long character literals (e.g. Oracle has a limit of 
								4000 bytes). When this parameter is set to true, &wb-productname; will
								create one file for each CLOB column value. This is the same behaviour 
								as with BLOB columns.
							</para>
							<para>
								Text files that are created with this parameter set to true, will
								contain the filename of the generated output file instead of the 
								actual column value. When importing such a file using <literal>WbImport</literal>
								you have to specify the <literal>-clobIsFilename=true</literal> parameter.
								Otherwise the filenames will be stored in the database and not the clob data.
								This parameter is not necessary when importing XML exports, as <literal>WbImport</literal> will
								automatically recognize the external files.
							</para>
							<note><para>
								SQL scripts (<literal>-type=sqlinsert</literal>) generated with <literal>-clobAsFile=true</literal> can only be run with &wb-productname;!
							</para></note>
							<para>
								All CLOB files that are written using the encoding specified with the 
								<literal>-encoding</literal> switch.
								If the <literal>-encoding</literal> parameter is not specified the 
								<link linkend="default-file-encoding">default file encoding</link> will be used.
							</para>
						</entry>
					</row>
					<row>
						<entry>-lobIdCols</entry>
						<entry>
							<para>
								When exporting CLOB or BLOB columns as external files, the filename with the
								LOB content is generated using the row and column number for the currently 
								exported LOB column (e.g. data_r15_c4.data). If you prefer to have the value
								of a unique column combination as part of the file name, you can specify
								those columns using the <literal>-lobIdCols</literal> parameter. The filename
								for the LOB will then be generated using the base name of the export file, 
								the column name of the LOB column and the values of the specified columns.
								If you export your data into a file called user_info and specify <literal>-lobIdCols=id</literal> 
								and your result contains a column called <literal>img</literal>, the LOB files 
								will be named e.g. user_info_img_344.data
							</para>
						</entry>
					</row>
					<row>
						<entry>-extensionColumn</entry>
						<entry>
							<para>
								When exporting CLOB or BLOB columns as external files, the extension of the generated 
								filenames can be defined based on a column of the result set. If the exported
								table contains more than one type of BLOBs (e.g. JPEG, GIF, PDF) and your table
								stores the information to define the extension based on the contents, this can be 
								used to re-generate proper filenames. 
							</para>
							<para>
								This parameter only makes sense if exactly one BLOB column is exported.
							</para>
						</entry>
					</row>
					<row>
						<entry>-filenameColumn</entry>
						<entry>
							<para>
								When exporting CLOB or BLOB columns as external files, the complete filename
								can be taken from a column of the result set (instead of dynamically creating
								a new file based on the row and column numbers). 
							</para>
							<para>
								This parameter only makes sense if exactly one BLOB column is exported.
							</para>
						</entry>
					</row>
					
        </tbody>
      </tgroup>
    </informaltable>

    <section id="spool-sql-parameters">
      <title>Parameters for type SQLUPDATE, SQLINSERT or SQLDELETEINSERT</title>

      <informaltable frame="all">
        <tgroup cols="2" align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>

          <tbody valign="top">
            <row>
              <entry>-table</entry>
              <entry>
								Define the tablename to be used for the UPDATE or INSERT
								statements. This parameter is required if the SELECT statement has
								multiple tables in the FROM list.
								table.
							</entry>
            </row>

						<row>
							<entry id="export-sql-cleanup">-charfunc</entry>
							<entry>
								<para>
									If this parameter is given, any
									non-printable character in a text/character column will be
									replaced with a call to the given function with the ASCII
									value as the parameter. 
								</para> 
								<para>
									If -charfunc=chr is
									given (e.g. for an Oracle syntax), a CR (=13) inside a
								character column will be replaced with:</para>
								<para><literal>INSERT
										INTO ... VALUES (&#39;First line&#39;||chr(13)||&#39;Second
									line&#39; ... )</literal>
								</para>
								<para>This setting will affect ASCII values from 0 to 31</para>
							</entry>
						</row>
						
						<row>
							<entry>-concat</entry>
							
							<entry>
								If the parameter <literal>-charfunc</literal> is used
								&wb-productname; will concatenate the individual pieces using
								the ANSI SQL operator for string concatenation. In case
								your DBMS does not support the ANSI standard (e.g. MS ACCESS)
								you can specify the operator to be used: <literal>-concat=+</literal>
							defines the plus sign as the concatenation operator.</entry>
						</row>
						
            <row>
              <entry>-blobType</entry>

              <entry>
								<para>Possible values: <literal>file</literal>, <literal>dbms</literal>, <literal>ansi</literal>
								</para>
								<para>
									This parameter controls how BLOB data will be put into 
									the generated SQL statements. By default no conversion 
									will be done, so the actual value that is written 
									to the output file depends on the JDBC driver's implementation
									of the Blob interface.
								</para>
								<para>
									The parameter value <literal>file</literal>, will cause
									&wb-productname; to write the contents of each blob column
									into a separate file. The SQL statement will contain the 
									&wb-productname; specific extension to read the blob data
									from the file. For details please refer to <xref linkend="blob-support"/>.
									If you are planning to run the generated SQL scripts using 
									&wb-productname; this is the recommended format.
								</para>
								<note><para>
									When using <literal>-blobType=file</literal> the generated SQL script 
									can only be run with &wb-productname;!
								</para></note>
								<para>
									The parameter value <literal>ansi</literal>, will generate
									"binary strings" that are compatible with the ANSI 
									definition for binary data. MySQL and Microsoft SQL Server support
									these kind of literals.
								</para>
								<para>
									The parameter value <literal>dbms</literal>, will create a DBMS
									specific "binary string". MySQL, HSQLDB, H2 and PostgreSQL 
									are known to support literals for binary data. For other DBMS
									using this option will still create an ansi literal but this 
									might result in an invalid SQL statement. 
								</para>
              </entry>
            </row>
						
						<row id="export-sql-literal-formats">
							<entry>-sqlDateLiterals</entry>
							<entry>
								<para>Possible values: <literal>jdbc</literal>, <literal>ansi</literal>, <literal>dbms</literal>, <literal>default</literal></para>
								<para>
									This parameter controls the generation of date or timestamp
									literals. By default literals that are specific for the current
									DBMS are created. You can also choose to create literals that 
									comply with the JDBC specification or ANSI SQL literals for dates
									and timestamps.
								</para>
								<para>
									<literal>jdbc</literal> selects the creation of JDBC compliant literals. 
									These should be usable with every JDBC based tool, including your own Java code:
									<literal>{d '2004-04-28'}</literal> or 
									<literal>{ts '2002-04-02 12:02:00.042'}</literal>. This is the 
									recommended format if you plan to use &wb-productname; (or any 
									other JDBC based tool) to run the generated statements.
								</para>
								<para>
									The value <literal>ansi</literal> selects the creation of ANSI SQL compliant 
									date literals: <literal>DATE '2004-04-28'</literal> or 
									<literal>TIMESTAMP '2002-04-02 12:04:00'</literal>. Please consult the 
									manual of the target DBMS, to find out whether it supports ANSI compliant
									date literals.
								</para>
								<para>
									The value <literal>default</literal> selects the creation of quoted date and timestamp
									literals in ISO format (e.g. '2004-04-28'). Several DBMS support this format (e.g. Postgres, Microsoft SQL Server)
								</para>

								<para>
									The value <literal>dbms</literal> selects the creation of specific 
									literals to be used with the current DBMS (using e.g. the <literal>to_date()</literal>
									function for Oracle). The format of these literals can be customized if necessary
									in <literal>workbench.settings</literal> using the keys
									<literal>workbench.sql.literals.[type].[datatype].pattern</literal> where 
									[type] is the type specified with this parameter and [datatype] is one of
									<literal>time, date, timestamp</literal>. If you add new literal types, 
									please also adjust the key <literal>workbench.sql.literals.types</literal>
									which is used to show the possible values in the GUI (auto-completion
									"Save As" dialog, Options dialog).
									If no type is specified (or <emphasis>dbms</emphasis>), &wb-productname; first looks for an entry
									where [type] is the current <link linkend="dbid">dbid</link>. If no value
									is found, <literal>default</literal> is used.
								</para>
								<para>
									You can define the default literal format to be used for the WbExport command
									in the <link linkend="options-default-copy-literaltype">options dialog</link>.
								</para>
							</entry>
						</row>
							
            <row>
              <entry>-commitEvery</entry>
              <entry>
									<para>
										A numeric value which identifies
										the number of <literal>INSERT</literal> or <literal>UPDATE</literal> statements
										after which a <literal>COMMIT</literal> is put into the generated SQL script.
									</para>
									<para>-commitevery=100</para>
									<para>will create a <literal>COMMIT;</literal> after every 100th statement.</para>
									<para>
										If this is not specified one <literal>COMMIT;</literal> will be added at the 
										end of the script. To suppress the final COMMIT, you can use
										<literal>-commitEvery=none</literal>. Passing <literal>-commitEvery=atEnd</literal>
										is equivalent to <literal>-commitEvery=0</literal>
									</para>
              </entry>
            </row>

            <row>
              <entry>-createTable</entry>
              <entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									If this parameter is set to true, the necessary <literal>CREATE TABLE</literal> 
									command is put into the output file. This parameter is ignored when creating 
									<literal>UPDATE</literal> statements.
								</para>
              </entry>
            </row>

            <row>
              <entry>-keyColumns</entry>
              <entry>
								<para>
									A comma separated list of column names that occur in the table
									or result set that should be used as the key columns for <literal>UPDATE</literal> 
									or <literal>DELETE</literal>
								</para>
								<para>
									If the table does not have key columns, or the source SELECT statement uses
									a join over several tables, or you do not want to use the key columns defined
									in the database, this key can be used to define the key columns to be used
									for the UPDATE statements. This key overrides any key columns defined on the
									base table of the SELECT statement.
								</para>
              </entry>
            </row>

          </tbody>
        </tgroup>
      </informaltable>
    </section>

    <section id="spool-text-parameters">
      <title>Parameters for the type TEXT</title>

      <informaltable frame="all">
        <tgroup cols="2"  align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>

          <tbody valign="top">
            <row>
              <entry>-delimiter</entry>

              <entry>The given string sequence will be
              placed between two columns. The default is a tab character
              (<literal>-delimiter=\t</literal>
              </entry>
            </row>

            <row>
              <entry>-dateFormat</entry>

							<entry>The date <link linkend="options-date-format">format</link> to be used when
									writing date columns into the output file. 
							</entry>
						</row>

            <row>
              <entry>-timestampFormat</entry>

              <entry>The <link linkend="options-date-format">format</link> to be used when writing
              datetime (or timestamp) columns into the output file.
              </entry>
            </row>

            <row>
              <entry>-quoteChar</entry>

              <entry>
								<para>The character (or sequence of characters) to be used
                  to enclose text (character) data if the delimiter is
                  contained in the data. By default quoting is disabled until a quote character
                  is defined. To set the double quote as the quote character
                  you have to enclose it in single quotes: <literal>-quotechar='"'</literal>
								</para>
              </entry>
            </row>

						<row>
							<entry>-quoteCharEscaping</entry>
							<entry>
								<para>Possible values: <literal>none</literal>, <literal>escape</literal>, <literal>duplicate</literal></para>
								<para>
									Defines how quote characters that appear in the actual data are written to the output file.
								</para>
								<para>
									If no quote character has been defined using the -quoteChar switch, 
									this option is ignored.
								</para>
								<para>
									If <literal>escape</literal> is specified a quote character (defined through 
									-quoteChar) that is embedded in the exported (character) data is written as 
									e.g. <literal>here is a \" quote character</literal>.
								</para>
								<para>
									If <literal>duplicate</literal> is specified, a quote character (defined through 
									-quoteChar) that is embedded in the exported (character) data is written as 
									two quotes e.g. <literal>here is a "" quote character</literal>.
								</para>
							</entry>
						</row>
						
            <row>
              <entry>-quoteAlways</entry>

              <entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									If quoting is enabled (via <literal>-quotechar</literal>,
                  then character data will normally only be quoted
                  if the delimiter is found inside the actual value that is
                  written to the output file. If <literal>-quoteAlways=true</literal> is
                  specified, character data will always be enclosed in the specified quote character.
									This parameter is ignored if not quote character is specified. If you 
									expect the quote character to be contained in the values, you should enable
									character escaping, otherwise the quote character that is part of the 
									exported value will break the quote during import.
								</para>
              </entry>
            </row>

            <row>
              <entry>-decimal</entry>
							<entry>
								The decimal symbol to be used for numbers. The default is a dot (e.g. 3.14152)
              </entry>
            </row>

						<row>
							<entry id="text-escape-switch">-escapeText</entry>
							
							<entry>
								<para>
									This parameter controls the escaping of non-printable
									or non-ASCII characters. Valid options are 
									<literal>ctrl</literal> which will escape everything below ASCII 32 (newline, tab, etc), 
									<literal>7bit</literal> which will escape everything below ASCII 32 and above 126, 
									<literal>8bit</literal> which will escape everything below ASCII 32 and above 255 
									and <literal>extended</literal> which will escape everything outside the 
									range [32-126] and [161-255]
								</para>
								<para>
									This will write a unicode representation of the character into the
									text file e.g. \n for a newline, \u00F6 for &ouml;. This file
									can only be imported using &wb-productname; (at least I don't know
									of any DBMS specific loader that will decode this properly)
								</para>
								<para>
									If character escaping is enabled, then the quote character will be escaped
									inside quoted values and the delimiter will be escaped inside non-quoted
									values. The delimiter could also be escaped inside a quoted value if the 
									delimiter falls into the selected escape range (e.g. a tab character).
								</para>
									
							</entry>
						</row>
						
            <row>
              <entry>-header</entry>

              <entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									If this parameter is set to true, the header (i.e. the column names) are placed into the
									output file. The default is to not create a header line. You can define the default value 
									for this parameter in the file <link linkend="export-text-header-default">workbench.settings</link>.
								</para>
              </entry>
            </row>
						
						<row>
							<entry>-writeOracleLoader</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									This parameter controls the creation of Oracle SQL*Loader
									control files. If it is set to <literal>true</literal>, then &wb-productname;
									will generate a control file for each exported text file,
									that can be used to import the text file using SQL*Loader
									instead of &wb-productname;. The control file has the same
									filename as the output file but with the ending <literal>.ctl</literal>
								</para>
								<para>
									Note that the generated control file will most probably
									need some adjustments before you can actually use it. It is mainly
									meant as a template that needs further refinement.
								</para>
							</entry>
						</row>
						
          </tbody>
        </tgroup>
      </informaltable>
    </section>

    <section id="spool-xml-parameters">
      <title>Parameters for type XML</title>

      <informaltable frame="all">
        <tgroup cols="2" align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody valign="top">
            <row>
              <entry>-table</entry>
              <entry>The given tablename will be put
              into the &#60;table&#62; tag as an attribute.</entry>
            </row>

						<row>
							<entry>-dateFormat</entry>
							<entry>The date <link linkend="options-date-format">format</link> to be used when
									writing date columns into the output file. 
							</entry>
						</row>
						
            <row>
              <entry>-timestampFormat</entry>
              <entry>The <link linkend="options-date-format">format</link> to be used when writing
              datetime (or timestamp) columns into the output file.
              </entry>
            </row>

            <row>
              <entry>-decimal</entry>
              <entry>The decimal symbol to be used for numbers. The default is a dot (e.g. 3.14152)</entry>
            </row>
            <row>
              <entry>-useCDATA</entry>
              <entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									Normally any character data written into the xml file will
                  be processes to escape XML characters (e.g. &lt; will be written as &amp;lt;).
                  If you don't want that escaping, set <literal>-usecdata=true</literal> and
                  all character data (VARCHAR, etc) will be enclosed in a CDATA section.
								</para>
                 <para>
										With <literal>-cdata=true</literal> a HTML value would be written like this:
                 </para>
                 <para>
                  <literal>&lt;![CDATA[&lt;b&gt;This is a title&lt;/b&gt;]]&gt;</literal>
								</para>
								<para>
                  With <literal>-cdata=false</literal> (the default) a HTML value would be written like this:</para>
								<para>
                  <literal>&amp;lt;b&amp;gt;This is a title&amp;lt;/b&amp;gt;</literal>
								</para>
              </entry>
            </row>

            <row>
              <entry>-stylesheet</entry>
              <entry>The name of the XSLT stylesheet that should be used
              to transform the &wb-productname; specific XML file into a
              different format. If -stylesheet is specified, -xsltoutput has
              to be specified as well.</entry>
            </row>
            <row>
              <entry>-xsltOutput</entry>
              <entry>The resulting output file (specified
              with the -file parameter), can be transformed using XSLT after
              the export has finished. This parameter then defines
              the name of the outputfile of the transformation.</entry>
            </row>
            <row>
              <entry>-verboseXML</entry>
              <entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>This parameter controls the tags that
									are used in the XML file and minor formatting features.
									The default is -verboseXML=true and this will generate
									more readable tags and formatting. However the overhead
									imposed by this is quite high. Using -verboseXML=false
									uses shorter tag names (not longer then two characters) and
									does put more information in one line. This output is
									a harder to read for a human but is smaller in size which
									could be important for exports with large result sets.
								</para>
              </entry>
            </row>

          </tbody>
        </tgroup>
      </informaltable>

    </section>
    <section id="export-examples">
      <title>Examples</title>

<programlisting>WbExport -type=text
         -file='c:/data/data.txt'
         -delimiter='|'
         -decimal=',';
SELECT * FROM data_table;</programlisting>

    <para>Will create a text file with the data from <literal>data_table</literal>.
        Each column will be separated with the character | Each fractional number
        will be written with a comma as the decimal separator. As the
        SELECT statement retrieves all rows and columns from the table, this
        could also be written as:
    </para>

<programlisting>WbExport -type=text
         -file='c:/data/data.txt'
         -delimiter='|'
         -decimal=','
         -sourcetable=data_table;</programlisting>
    <para>There is a difference in the behaviour of the command regarding the "Max. Rows" setting
    in the GUI. When you use the <literal>WbExport</literal> command together with
    a <literal>SELECT</literal> query, the Max. Rows setting will be respected
    by the <literal>SELECT</literal> statement (and you will see a warning
    that the result set was limited). When you use the <literal>WbExport</literal>
    with the <literal>-sourcetable</literal> switch, the "Max. Rows" setting
    will not be respected, and all rows from the table will be written into
    the specified file.</para>

    <para>To generate a file that contains SQL INSERT statements that can be
      executed on the target system, the following command can be used:</para>

<programlisting>WbExport -type=sqlinsert
         -file='c:/data/newtable.sql'
         -table=newtable;
SELECT * FROM table1, table2
WHERE table1.column1 = table2.column1;</programlisting>

      <para>will create a SQL scripts which inserts the data from table1
      and table2 into a table called newtable. If the parameter -table is
      omitted, the creation of SQL INSERT statements is only possible, if the SELECT is
      based on a single table (or view).</para>
      <para>For more details on how you can export and import data using the XML format
      please refer to <xref linkend="xml-export-import"/></para>
    </section>
    <section id="export-date-formats">
      <title>Specifying date formats</title>
      <para>The date/time format that can be specified with the <literal>-dateformat</literal>
      or <literal>-timestampformat</literal> accepts fhe following format codes. These
      are the format codes for Java's <ulink url="http://java.sun.com/j2se/1.5.0/docs/api/java/text/SimpleDateFormat.html">SimpleDateFormat</ulink>
      class.
      </para>
    </section>

</section>