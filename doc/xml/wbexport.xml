<section id="command-export">
	<title>Export data using WbExport</title>

	<para>
		The <literal>WbExport</literal> exports contents of the database into external files, e.g.
		plain text ("CSV") or XML.
	</para>

	<para>
		The <literal>WbExport</literal> command can be used like any other SQL command
		(such as <literal>UPDATE</literal> or <literal>INSERT</literal>). This includes the
    usage in scripts that are run in <link linkend="using-scripting">batch mode</link>.
	</para>

  <indexterm><primary>Export</primary><secondary>SQL query result</secondary></indexterm>
  <indexterm><primary>Export</primary><secondary>table</secondary></indexterm>

	<para>
		The <literal>WbExport</literal> command exports either the result of the
    <emphasis role="bold">next</emphasis> SQL Statement
    (which has to produce a result set) or the content of the table(s)
    specified with the <literal>-sourceTable</literal> parameter.
		The data is directly written to the output file and not loaded into memory. The export file(s)
		can be compressed ("zipped") on the fly. <link linkend="command-import">WbImport</link> can
		import the zipped (text or XML) files directly without the need to unzip them.
	</para>

	<para>
		If you want to save the data that is
		currently displayed in the result area into an external file, please
		use the <link linkend="export">Save Data as</link> feature.
		You can also use the <link linkend="dbexplorer-spool">Database Explorer</link>
		to export multiple tables.
	</para>

	<note><para>
		When using a <literal>SELECT</literal> based export, you have to
		run both statements (<literal>WbExport</literal> and <literal>SELECT</literal>)
		as one script. Either select both statements in the editor and choose
		<menuchoice><guimenu>SQL</guimenu><guimenuitem>Execute selected</guimenuitem></menuchoice>,
		or make the two statements the only statements in the editor and choose
		<menuchoice><guimenu>SQL</guimenu><guimenuitem>Execute all</guimenuitem></menuchoice>.
	</para></note>

	<para>
		You can also export the result of a <literal>SELECT</literal> statement, by
		selecting the statment in the editor, and then choose
		<menuchoice><guimenu>SQL</guimenu><guimenuitem>Export query result</guimenuitem></menuchoice>.
	</para>

	<para>
		When exporting data into a Text or XML file, the content of BLOB columns
		is written into separate files. One file for each column of each row. Text files
		that are created this way can most probably only be imported using &wb-productname; as
		the main file will contain the filename of the BLOB data file instead of the actual BLOB data.
		The only other application that I know of, that can handle this type of imports is Oracle's
		<literal>SQL*Loader</literal> utility. If you run the text export together with the
		parameter <literal>-formatFile=oracle</literal> a control file will be created that contains the
		approriate definitions to read the BLOB data from the external file.
	</para>

  <para>
    <important>
      Oracles's <literal>BFILE</literal>, PostgreSQL's <literal>large object</literal> and SQL Server's <literal>filestream</literal>
      types are not real <literal>BLOB</literal> datatypes (from a JDBC point of view) and are currently not exported by WbExport.
      Only columns that are reported as <literal>BLOB</literal>, <literal>BINARY</literal>, <literal>VARBINARY</literal> or <literal>LONGVARBINARY</literal>
      in the column "JDBC type" in the DbExplorer will be exported correctly into a separate file.
    </important>
  </para>

	<section id="wb-export-memory">
		<title>Memory usage and WbExport</title>
    <indexterm><primary>Problems</primary><secondary>memory usage during export</secondary></indexterm>
    <indexterm><primary>Export</primary><secondary>memory problems</secondary></indexterm>

    <para>
      WbExport is designed to directly write the rows that are retrieved from the database
      to the export file without buffering them in memory (except for the XLS and XLSX formats)
   </para>

    <para>
       Some JDBC drivers (e.g. PostgreSQL, jTDS and the Microsoft driver) read the full result obtained
       from the database into memory. In that case, exporting large results might still require a lot
       of memory. Please refer to the chapter <link linkend="troubleshooting">Common problems</link>
       for details on how to configure the individual drivers if this happens to you.
    </para>

  </section>

  <section id="poi-installation">
    <title>Exporting Excel files</title>
    <indexterm><primary>Excel export</primary><secondary>installation</secondary></indexterm>

    <para>
      If you need to export data for Microsoft Excel, additional libraries are required to write the native Excel formats (<literal>xls</literal> and the
      new <literal>xlsx</literal> introduced with Office 2007). Exporting the "SpreadsheetML" format introduced with Office 2003 does not require
      additional libraries.
    </para>

    <para>
      &wb-productname; supports three different Excel file formats:
    </para>

		<informaltable frame="all" id="export-xls-formats">
			<tgroup cols="2" align="left">
				<colspec colname="c1" />
				<colspec colname="c2" />
				<thead>
					<row>
						<entry>Value for <literal>-type</literal> parameter</entry>
						<entry>Description</entry>
					</row>
				</thead>

				<tbody valign="top">
					<row>
						<entry>xlsm</entry>
						<entry>
              <para>
                This is the plain XML ("SpreadsheetML") format introduced with Office 2003. This format is always
                available and does not need any additional libraries.
              </para>
              <para>
                Files with this format should be saved with the extension <emphasis role="bold">xml</emphasis> (otherwise Office is not able to open them properly)
              </para>
            </entry>
          </row>

					<row>
						<entry>xls</entry>
						<entry>
              <para>
                This is the old binary format using by Excel 97 up to 2003. To export this format, only <literal>poi.jar</literal> is needed.
                If the library is not available, this format will not be listed in the export dialog ("Save data as...")
              </para>
              <para>
                Files with this format should be saved with the extension <emphasis role="bold">xls</emphasis>
              </para>
            </entry>
          </row>

					<row>
						<entry>xlsx</entry>
						<entry>
              <para>
                This is the "new" XML format (OfficeOpen XML) introduced with Office 2007. To create this file format,
                additionaly libraries are required. If those libraries are not available,
                this format will not be listed in the export dialog ("Save data as...")
              </para>
              <para>
                Files with this format should be saved with
                the extension <emphasis role="bold">xlsx</emphasis>
              </para>
            </entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable>

    <para>
      For a comparison of the different Microsoft Office XML formats please refer to: <ulink url="http://en.wikipedia.org/wiki/Microsoft_Office_XML_formats"/>
    </para>

    <para id="download-poi-addon">
      You can download all required POI libraries as a single archive from the &wb-productname; homepage:
      <ulink url="http://www.sql-workbench.net/poi-add-on2.zip"/>. After downloading the archive, unzip it
      into the directory where <literal>sqlworkbench.jar</literal> is located.
    </para>

    <important>
      <para>
        To write the file formats XLS and XLSX the entire file needs to be built in memory. When exporting
        results with a large number of rows this will require a substiantal amount of memory.
      </para>
    </important>

    <para>
      If you have downloaded the add-on ZIP before build 112, you have to delete the file
      <emphasis role="bold"><literal>ooxml-schemas-1.0.jar</literal></emphasis> as it has been replaced with <literal>poi-ooxml-schemas.jar</literal>.
    </para>

  </section>

	<simplesect id="wb-export-max-rows">
		<title>WbExport and the "Max. Rows" option</title>
		<para>
			When you use the <literal>WbExport</literal> command together with
			a <literal>SELECT</literal> query, the "Max. Rows" setting will be
			<emphasis role="bold">ignored</emphasis> for the export.
		</para>
	</simplesect>

	<section id="export-parameters">
		<title>General WbExport parameters</title>
    <indexterm><primary>Export</primary><secondary>parameters</secondary></indexterm>

		<informaltable frame="all">
			<tgroup cols="2" align="left">
				<colspec colname="c1" colwidth="4cm" />
				<colspec colname="c2" />
				<thead>
					<row>
						<entry>Parameter</entry>
						<entry>Description</entry>
					</row>
				</thead>

				<tbody valign="top">
					<row>
						<entry>-type</entry>
						<entry>
							<para>
								Possible values: <literal>text, sqlinsert, sqlupdate, sqldeleteinsert, xml, ods, xlsm, xls, xlsx, html, json</literal>
							</para>
							<para>
								Defines the type of the output file. <literal>sqlinsert</literal>
								will create the necessary <literal>INSERT</literal> statements to put
								the data into a table. If the records may already exist in the target table
								but you don't want to (or cannot) delete the content of the table
								before running the generated script, &wb-productname; can create a DELETE
								statement for every <literal>INSERT</literal> statement. To create this
								kind of script, use the <literal>sqldeleteinsert</literal> type.
							</para>
							<para>
								In order for this to work properly the table needs to have keycolumns defined,
								or you have to define the keycolumns manually using the <literal>-keycolumns</literal>
								switch.
							</para>
							<para>
								<literal>sqlupdate</literal> will generate UPDATE
								statements that update all non-key columns of the table. This will only
								generate valid <literal>UPDATE</literal> statements if at least one key
								column is present. If the table does not have key columns defined, or you
								want to use different columns, they can be specified using the <literal>-keycolumns</literal>
								switch.
							</para>
							<para>
								<literal>ods</literal> will generate a spreadsheet file in the OpenDocument
								format that can be opened e.g. with OpenOffice.org.
							</para>
							<para>
								<literal>xlsm</literal> will generate a spreadsheet file in the Microsoft Excel 2003 XML format ("XML Spreadsheet").
                 When using Microsof Office 2010, this export format should should be saved with a file extension
                 of <literal>.xml</literal> in order to be identified correctly.
              </para>
							<para>
								<literal>xls</literal> will generate a spreadsheet file in the propriatary (binary) format
								for Microsoft Excel (97-2003). The file <literal>poi.jar</literal> is required.
							</para>
              <para>
                <literal>xlsx</literal> will generate a spreadsheet file in the default format introduced with Microsof Office 2007.
                Additional external libraries are required in order to be able to use this format. Please read the note at the beginning of
                this section.
							</para>
              <para>
                This parameter supports auto-completion.
              </para>
						</entry>
					</row>

					<row>
						<entry>-file</entry>
						<entry>
              <para>The output file to which the exported data is written.</para>
              <para>
                 This parameter is ignored if <literal>-outputDir</literal> is also specified.
              </para>
						</entry>
					</row>

					<row>
						<entry>-createDir</entry>
						<entry>
              If this parameter is set to <literal>true</literal>, &wb-productname; will create any
							needed directories when creating the output file.
						</entry>
					</row>

					<row>
						<entry id="export-source-table">-sourceTable</entry>
						<entry>
							<para>Defines a list of tables to be exported. If this
								switch is used, <literal>-outputdir</literal> is also required
								unless exactly one table is specified. If one table is
								specified, the -file parameter is used to generate the file
								for the table. If more then one table is specified, the
								<literal>-outputdir</literal> parameter is used to defined
								the directory where the generated files should be stored.
								Each file will be named as the exported table with the approriate
								extension (.xml, .sql, etc). You can specify * as the table
								name which will then export all tables accessible by the
								current user.
							</para>
							<para>
                If you want to export tables from a different user
								or schema you can use a schema name combined with a wildcard
								e.g. <literal> -sourcetable=otheruser.*</literal>. In this case
								the generated output files will contain the schema name as part of the
								filename (e.g. <literal>otheruser.person.txt</literal>).
								When <link linkend="command-import">importing</link> these files,
								&wb-productname; will try to import the tables into the schema/user
								specified in the filename. If you want to import them into
								a different user/schema, then you have to use the <literal>-schema</literal>
								switch for the <link linkend="command-import">import</link> command.
							</para>
              <para>
                This parameter supports auto-completion.
              </para>
						</entry>
					</row>
					<row>
						<entry>-schema</entry>
						<entry>
							<para>
                Define the schema in which the table(s) specified with <literal>-sourceTable</literal>
                are located. This parameter only accepts a single schema name. If you want to
                export tables from more than one schema, you need to fully qualify them as shown
                in the description of the <literal>-sourceTable</literal> parameter.
							</para>
              <para>
                This parameter supports auto-completion.
              </para>
            </entry>
          </row>
					<row>
						<entry id="export-object-types">-types</entry>
						<entry>
              <para>
                Selects the object types to be exported. By default only TABLEs are exported. If you want to export
                the content of VIEWs or SYNONYMs as well, you have to specify all types with this parameter.
              </para>
              <para><literal>-sourceTable=* -types=VIEW,SYNONYM</literal> or <literal>-sourceTable=T% -types=TABLE,VIEW,SYNONYM</literal></para>
              <para>
                This parameter supports auto-completion.
              </para>
            </entry>
          </row>
					<row>
						<entry id="export-exclude-tables">-excludeTables</entry>
						<entry>
              <para>
                The tables listed in this parameter will not be exported. This can be used when all but a few tables
                should be exported from a schema. First all tables specified through <literal>-sourceTable</literal> will
                be evaluated. The tables specified by -excludeTables can include wildcards in the same way, <literal>-sourceTable</literal>
                allows wildcards.
              </para>
              <para>
                <literal>-sourceTable=* -excludeTables=TEMP*</literal> will export all tables, but not those starting with <literal>TEMP</literal>.
              </para>
              <para>
                This parameter supports auto-completion.
              </para>
            </entry>
          </row>

					<row>
						<entry>-sourceTablePrefix</entry>
						<entry>
              <para>
                Define a common prefix for all tables listed with <literal>-sourceTable</literal>.
                When this parameter is specified the existence of each table is not tested any longer
                (as it is normally done).
              </para>
              <para>
                When this parameter is specified the generated statement for exporting the table is
                changed to a <literal>SELECT * FROM [prefix]tableName</literal> instead of listing all columns individually.
              </para>
              <para>
                This can be used when exporting views on tables, when for each table e.g. a view with a certain prefix
                exists (e.g. table <literal>PERSON</literal> has the view <literal>V_PERSON</literal> and the view does
                some filtering of the data.
              </para>
              <para>
                This parameter can <emphasis role="bold">not</emphasis> be used to select tables from a specific schema.
                The prefix will be prepended to the table's <emphasis role="bold">name</emphasis>.
              </para>
            </entry>
					</row>

					<row>
						<entry id="export-outputdir">-outputDir</entry>
						<entry>
              When using the <literal>-sourceTable</literal> switch
							with multiple tables, this parameter is mandatory and defines
							the directory where the generated files should be stored.
						</entry>
					</row>
					<row>
						<entry>-continueOnError</entry>
						<entry>
							When exporting more than one table, this parameter controls
							whether the whole export will be terminated if an error occurs during
							export of one of the tables.
						</entry>
					</row>
					<row>
						<entry id="export-encoding">-encoding</entry>
						<entry>
              <para>
                Defines the encoding in which the file should be
                written. Common encodings are ISO-8859-1, ISO-8859-15, UTF-8 (or UTF8).
                To get a list of available encodings, execut <literal>WbExport</literal>
                with the parameter <literal>-showencoding</literal>. This parameter is ignored
                for XLS, XLSX and ODS exports.
              </para>
              <para>
                This parameter supports auto-completion and if it is invoked for this parameter, it will show a list of encodings
                defined through the configuration property <literal>workbench.export.defaultencodings</literal>
                This is a comma-separated list that can be changed using
                <link linkend="command-setconfig"><literal>WbSetConfig</literal></link>
              </para>
						</entry>
					</row>

					<row>
						<entry>-showEncodings</entry>
						<entry>
							Displays the encodings supported by your Java version and
							operating system. If this parameter is present, all other parameters are ignored.
						</entry>
					</row>

					<row>
						<entry id="export-line-ending">-lineEnding</entry>
						<entry>
							<para>Possible values are: <literal>crlf</literal>, <literal>lf</literal></para>
							<para>
								Defines the line ending to be used for XML or text files.
								<literal>crlf</literal> puts the ASCII characters #13 and #10 after each line.
								This is the standard format on Windows based systems. <literal>dos</literal> and
								<literal>win</literal> are synonym values for <literal>crlf</literal>,
								<literal>unix</literal> is a synonym for <literal>lf</literal>.
							</para>
							<para>
								<literal>lf</literal> puts only the ASCII character #10 at the end of each line.
								This is the standard format on Unix based systems (<literal>unix</literal>
								is a synonym value for this format).
							</para>
							<para>
								The default line ending used depends on the platform where &wb-productname; is running.
							</para>
              <para>
                This parameter supports auto-completion.
              </para>
						</entry>
					</row>

					<row>
						<entry id="export-header">-header</entry>

						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								If this parameter is set to true, the header (i.e. the column names) are placed into the
								first line of output file. The default is to not create a header line. You can define the default value
								for this parameter in the file <link linkend="export-text-header-default">workbench.settings</link>.
								This parameter is valid for text and spreadsheet (OpenDocument, Excel) exports.
							</para>
						</entry>
					</row>

					<row>
						<entry id="export-compress">-compress</entry>
            <para>Possible values: <literal>true</literal>, <literal>false</literal></para>
						<entry>
							<para>
								Selects whether the output file should be compressed
								and put into a ZIP archive. An archive will be created with the name of the specified outputfile
								but with the extension <literal>zip</literal>. The archive will then contain the specified file
								(e.g. if you specify <literal>data.txt</literal>, an archive <literal>data.zip</literal>
								will be created containing exactly one entry with the name <literal>data.txt</literal>).
								If the exported result set contains BLOBs, they will be stored in a separate archive, named
								<literal>data_lobs.zip</literal>.
							</para>
							<para>
								When exporting multiple tables using the <literal>-sourcetable</literal> parameter,
								then &wb-productname; will create one ZIP archive for each table in the specified output
								directory with the filename <literal>"tablename".zip</literal>. For any table containing
								BLOB data, one additional ZIP archive is created.
							</para>
						</entry>
					</row>

					<row>
						<entry>-tableWhere</entry>
						<entry>
							<para>
                Defines an additional <literal>WHERE</literal> clause that is appended to
                all SELECT queries to retrieve the rows from the database. No validation check
                will be done for the syntax or the columns in the where clause. If the specified
                condition is not valid for all exported tables, the export will fail.
							</para>
						</entry>
					</row>

					<row>
						<entry id="export-clobasfile">-clobAsFile</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								For SQL, XML and Text export this controls how the contents of CLOB fields
								are exported. Usually the CLOB content is put directly into the output file
								When generating SQL scripts with WbExport this can be a problem as not all
								DBMS can cope with long character literals (e.g. Oracle has a limit of
								4000 bytes). When this parameter is set to true, &wb-productname; will
								create one file for each CLOB column value. This is the same behaviour
								as with BLOB columns.
							</para>
							<para>
								Text files that are created with this parameter set to true, will
								contain the filename of the generated output file instead of the
								actual column value. When importing such a file using <literal>WbImport</literal>
								you have to specify the <literal>-clobIsFilename=true</literal> parameter.
								Otherwise the filenames will be stored in the database and not the clob data.
								This parameter is not necessary when importing XML exports, as <literal>WbImport</literal> will
								automatically recognize the external files.
							</para>
							<para>
                <important>
									SQL exports (<literal>-type=sqlinsert</literal>) generated with
									<literal>-clobAsFile=true</literal> can only be used with &wb-productname;.
                </important>
							</para>
							<para>
								All CLOB files that are written using the encoding specified with the
								<literal>-encoding</literal> switch.
								If the <literal>-encoding</literal> parameter is not specified the
								<link linkend="default-file-encoding">default file encoding</link> will be used.
							</para>
						</entry>
					</row>

					<row>
						<entry id="export-lobidcol">-lobIdCols</entry>
						<entry>
							<para>
								When exporting CLOB or BLOB columns as external files, the filename with the
								LOB content is generated using the row and column number for the currently
								exported LOB column (e.g. data_r15_c4.data). If you prefer to have the value
								of a unique column combination as part of the file name, you can specify
								those columns using the <literal>-lobIdCols</literal> parameter. The filename
								for the LOB will then be generated using the base name of the export file,
								the column name of the LOB column and the values of the specified columns.
								If you export your data into a file called user_info and specify <literal>-lobIdCols=id</literal>
								and your result contains a column called <literal>img</literal>, the LOB files
								will be named e.g. user_info_img_344.data
							</para>
						</entry>
					</row>

					<row>
						<entry id="export-lobfiles-per-dir">-lobsPerDirectory</entry>
						<entry>
							<para>
								When exporting CLOB or BLOB columns as external files, the generated files
                can be distributed over several directories to avoid an excessive number of
                files in a single directory. The parameter <literal>lobsPerDirectory</literal> defines
                how many LOB files are written into a single directory. When the specified number of files have been written,
                a new directory is created. The directories are always created as a sub-directory of the target directory. The name
                for each directory is the base export filename plus "_lobs" plus a running number. So if you export
                the data into a file "the_big_table.txt", the LOB files will be stored in "the_big_table_lobs_1",
                "the_big_table_lobs_2", "the_big_table_lobs_3" and so on.
							</para>
              <para>
                The directories will be created if needed, but if the directories already exist (e.g. because of a previous
                export) <emphasis role="bold">their contents will not be deleted</emphasis>!
              </para>
						</entry>
					</row>


					<row>
						<entry id="export-extensioncol">-extensionColumn</entry>
						<entry>
							<para>
								When exporting CLOB or BLOB columns as external files, the extension of the generated
								filenames can be defined based on a column of the result set. If the exported
								table contains more than one type of BLOBs (e.g. JPEG, GIF, PDF) and your table
								stores the information to define the extension based on the contents, this can be
								used to re-generate proper filenames.
							</para>
							<para>
								This parameter only makes sense if exactly one BLOB column of a table is exported.
							</para>
						</entry>
					</row>

					<row>
						<entry id="export-lob-filename">-filenameColumn</entry>
						<entry>
							<para>
								When exporting CLOB or BLOB columns as external files, the complete filename
								can be taken from a column of the result set (instead of dynamically creating
								a new file name based on the row and column numbers).
							</para>
							<para>
								This parameter only makes sense if exactly one BLOB column of a table is exported.
							</para>
						</entry>
					</row>

					<row>
						<entry id="export-append">-append</entry>
						<entry>
							<para>
								Possible values: <literal>true</literal>,<literal>false</literal>
							</para>
							<para>
								Controls whether results are appended to an existing file, or overwrite an existing
								file. This parameter is only supported for text, SQL, XLS and XLSX export types.
							</para>
              <para>
                When used with XLS oder XSLX exports, a new worksheet will be created.
              </para>
						</entry>
					</row>

					<row>
						<entry id="export-dateformat">-dateFormat</entry>
						<entry>
							The date <link linkend="options-date-format">format</link> to be used when
							writing date columns into the output file. This parameter is ignored for
							SQL exports.
						</entry>
					</row>

					<row>
						<entry>-timestampFormat</entry>
						<entry>
							The <link linkend="options-date-format">format</link> to be used when writing
							datetime (or timestamp) columns into the output file. This parameter is ignored
							for SQL exports.
						</entry>
					</row>

					<row>
						<entry id="export-blob-type">-blobType</entry>
						<entry>
							<para>Possible values: <literal>file</literal>, <literal>dbms</literal>, <literal>ansi</literal>, <literal>base64</literal>
							</para>
							<para>
								This parameter controls how BLOB data will be put into the generated SQL statements.
								By default no conversion will be done, so the actual value that is written
								to the output file depends on the JDBC driver's implementation
								of the Blob interface. It is only valid for Text, SQL and XML exports, although not
                all parameter values make sense for all export types.
							</para>
              <para>
                The type <literal>base64</literal> is primarily intended for Text exports (e.g. to be used with PostgreSQL's <literal>COPY</literal> command)
              </para>
              <para>
                The types <literal>dbms</literal> and <literal>ansi</literal> are intended for SQL exports and generate
                a representation of the binary data as part of the SQL statement. <literal>DBMS</literal> will use a format that is understood by the
                DBMS you are exporting from, while <literal>ansi</literal> will generate a standard hex based representation of the binary data. The
                syntax generated by the <literal>ansi</literal> format is not understood by all DBMS!
              </para>
              <para>
                Two additional SQL literal formats are available that can be used together with PostgreSQL: <literal>pgDecode</literal> and <literal>pgEscape</literal>.
                <literal>pgDecode</literal> will generate a hex representation using PostgreSQL's <ulink url="http://www.postgresql.org/docs/current/static/functions-binarystring.html">decode()</ulink> function.
                Using <literal>decode</literal> is a very compact format. <literal>pgEscape</literal> will use PostgreSQL's <ulink url="http://www.postgresql.org/docs/current/static/datatype-binary.html">escaped octets</ulink>,
                and generates much bigger statements (due to the increase escaping overhead).
              </para>
              <para>
                When using <literal>file</literal>, <literal>base64</literal> or <literal>ansi</literal> the file can be imported using
                <link linkend="command-import"><literal>WbImport</literal></link>
              </para>
							<para>
								The parameter value <literal>file</literal>, will cause
								&wb-productname; to write the contents of each blob column
								into a separate file. The SQL statement will contain the
								&wb-productname; specific extension to read the blob data
								from the file. For details please refer to <xref linkend="blob-support"/>.
								If you are planning to run the generated SQL scripts using
								&wb-productname; this is the recommended format.
							</para>
							<para>
                <important>
                  Note that SQL scripts generated with <literal>-blobType=file</literal>
                  can only be run with &wb-productname;
                </important>
							</para>
							<para>
								The parameter value <literal>ansi</literal>, will generate
								"binary strings" that are compatible with the ANSI
								definition for binary data. MySQL and Microsoft SQL Server support
								these kind of literals.
							</para>
							<para>
								The parameter value <literal>dbms</literal>, will create a DBMS
								specific "binary string". MySQL, HSQLDB, H2 and PostgreSQL
								are known to support literals for binary data. For other DBMS
								using this option will still create an ansi literal but this
								might result in an invalid SQL statement.
							</para>
              <para>
                This parameter supports auto-completion.
              </para>
						</entry>
					</row>

          <row>
            <entry id="export-replace">-replaceExpression -replaceWith</entry>
            <entry>
              <para>
                Using these parameters, arbitrary text can be replaced during the export. <literal>-replaceExpression</literal>
                defines the regular expression that is to be replaced. <literal>-replaceWith</literal> defines the replacement value.
                <literal>-replaceExpression='(\n|\r\n)' -replaceWith=' '</literal> will replace all newline characters with a blank.
              </para>
              <para>
                The search and replace is done on the "raw" data retrieved from the database before the values
                are converted to the corresponding output format. In particular this means replacing is done
                before any <link linkend="text-escape-switch">character escaping</link> takes place.
              </para>
              <para>
                Because the search and replace is done before the data is converted to the output format, it
                can be used for all export types (text, xml, Excel, ...).
              </para>
              <para>
                Only character columns (<literal>CHAR</literal>, <literal>VARCHAR</literal>, <literal>CLOB</literal>, <literal>LONGVARCHAR</literal>) are taken into account.
              </para>
            </entry>
          </row>

					<row>
						<entry id="export-trim-char-data">-trimCharData</entry>

						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
                If this parameter is set to true, values from <literal>CHAR</literal> columns will be trimmed from trailing
                whitespace. This is equivalent to the <link linkend="profile-trim-char-data">Trim CHAR data</link> in the connection profile.
							</para>
						</entry>
					</row>

					&progress-parameter;

				</tbody>
			</tgroup>
		</informaltable>
	</section>

	<section id="export-text-parameters">
    <title>Parameters for text export</title>

    <indexterm><primary>Export</primary><secondary>text files</secondary></indexterm>

		<informaltable frame="all">
			<tgroup cols="2"  align="left">
				<colspec colname="c1" colwidth="4cm" />
				<colspec colname="c2" />
				<thead>
					<row>
						<entry>Parameter</entry>
						<entry>Description</entry>
					</row>
				</thead>

				<tbody valign="top">
					<row>
						<entry id="export-text-delimiter">-delimiter</entry>

						<entry>The given string sequence will be
						placed between two columns. The default is a tab character
						(<literal>-delimiter=\t</literal>
						</entry>
					</row>

					<row>
						<entry>-rowNumberColumn</entry>
						<entry>
							If this parameter is specified with a value, the value defines the name
							of an additional column that will contain the rownumber. The row number will always be
							exported as the first column. If the text file is not created with
							a header (<literal>-header=false</literal>) a value must still be provided to enable
							the creation of the additional column.
						</entry>
					</row>

					<row>
						<entry>-quoteChar</entry>

						<entry>
							<para>The character (or sequence of characters) to be used
								to enclose text (character) data if the delimiter is
								contained in the data. By default quoting is disabled until a quote character
								is defined. To set the double quote as the quote character
								you have to enclose it in single quotes: <literal>-quotechar='"'</literal>
							</para>
						</entry>
					</row>

					<row>
						<entry>-quoteCharEscaping</entry>
						<entry>
							<para>Possible values: <literal>none</literal>, <literal>escape</literal>, <literal>duplicate</literal></para>
							<para>
								Defines how quote characters that appear in the actual data are written to the output file.
							</para>
							<para>
								If no quote character has been defined using the -quoteChar switch,
								this option is ignored.
							</para>
							<para>
								If <literal>escape</literal> is specified a quote character (defined through
								-quoteChar) that is embedded in the exported (character) data is written as
								e.g. <literal>here is a \" quote character</literal>.
							</para>
							<para>
								If <literal>duplicate</literal> is specified, a quote character (defined through
								-quoteChar) that is embedded in the exported (character) data is written as
								two quotes e.g. <literal>here is a "" quote character</literal>.
							</para>
              <para>
                This parameter supports auto-completion.
              </para>
						</entry>
					</row>

					<row>
						<entry>-quoteAlways</entry>

						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								If quoting is enabled (via <literal>-quoteChar</literal>,
								then character data will normally only be quoted
								if the delimiter is found inside the actual value that is
								written to the output file. If <literal>-quoteAlways=true</literal> is
								specified, character data will always be enclosed in the specified quote character.
								This parameter is ignored if not quote character is specified. If you
								expect the quote character to be contained in the values, you should enable
								character escaping, otherwise the quote character that is part of the
								exported value will break the quote during import.
							</para>
              <para>
                NULL values will not be quoted even if this parameter is set to true. This
                is usefull to distinguish between NULL values and empty strings.
              </para>

						</entry>
					</row>

					<row>
						<entry>-decimal</entry>
						<entry>
							The decimal symbol to be used for numbers. The default is a dot (e.g. 3.14152)
						</entry>
					</row>

					<row>
						<entry id="text-escape-switch">-escapeText</entry>

						<entry>
							<para>
								This parameter controls the escaping of non-printable
								or non-ASCII characters. Valid options are
								<literal>ctrl</literal> which will escape everything below ASCII 32 (newline, tab, etc),
								<literal>7bit</literal> which will escape everything below ASCII 32 and above 126,
								<literal>8bit</literal> which will escape everything below ASCII 32 and above 255
								and <literal>extended</literal> which will escape everything outside the
								range [32-126] and [161-255]
							</para>
							<para>
                This will write a "short-hand" representation of control characters (e.g. <literal>\n</literal>
                for a newline) and a unicode representation for characters above ASCII 126
                (e.g. <literal>\u00F6</literal> for <literal>&ouml;</literal>). This file
								can only be imported using &wb-productname; (at least I don't know
								of any DBMS specific loader that will decode this properly).
							</para>
							<para>
								If character escaping is enabled, then the quote character will be escaped
								inside quoted values and the delimiter will be escaped inside non-quoted
								values. The delimiter could also be escaped inside a quoted value if the
								delimiter falls into the selected escape range (e.g. a tab character).
							</para>
              <para>
                To import a text file with escaped values using <link linkend="text-import-decode">WbImport</link>,
                the <literal>-decode=true</literal> must be used.
              </para>
              <para>
                This parameter supports auto-completion.
              </para>
						</entry>
					</row>

					<row>
						<entry id="text-nullstring">-nullString</entry>
						<entry>
							<para>
                Defines the string value that should be written into the output file for a <literal>NULL</literal> value.
                This value will be enclosed with the specified quote character only if <literal>-quoteAlways=true</literal>
                is specified as well.
							</para>
						</entry>
					</row>

					<row>
						<entry>-formatFile</entry>
						<entry>
							<para>Possible values: <literal>postgres</literal>, <literal>oracle</literal>, <literal>sqlserver</literal>, <literal>db2</literal>, <literal>mysql</literal></para>
							<para>
								This parameter controls the creation of a control file for
								the bulk load utilities of some DBMS.
								<itemizedlist>
									<listitem><simpara><literal>postgres</literal> will create a SQL script with the necessary <ulink url="http://www.postgresql.org/docs/current/static/sql-copy.html"><literal>COPY</literal></ulink> syntax to import the generated text file</simpara></listitem>
									<listitem><simpara><literal>oracle</literal> will create a control file (.ctl) for Oracle's <ulink url="http://download.oracle.com/docs/cd/B28359_01/server.111/b28319/part_ldr.htm">SQL*Loader</ulink> utility</simpara></listitem>
                  <listitem><simpara><literal>sqlserver</literal> will create a format file (.fmt) for Microsoft's <ulink url="http://msdn.microsoft.com/en-us/library/ms162802%28v=SQL.90%29.aspx"><literal>bcp</literal></ulink> utility</simpara></listitem>
                  <listitem><simpara><literal>db2</literal>will create a SQL script with a DB2 <ulink url="http://publib.boulder.ibm.com/infocenter/db2luw/v9r7/index.jsp?topic=/com.ibm.db2.luw.admin.cmd.doc/doc/r0008304.html"><literal>IMPORT</literal></ulink> command</simpara></listitem>
                  <listitem><simpara><literal>mysql</literal>will create a SQL script with a MySQL <ulink url="http://dev.mysql.com/doc/refman/5.5/en/load-data.html"><literal>LOAD DATA INFILE</literal></ulink> command</simpara></listitem>
								</itemizedlist>
							</para>
							<para>
								You can specify more than one format (separated by a comma). In that case one control file for each format will be created.
							</para>
							<note>
                <para>The generated format file(s) are intended as a starting point for your own adjustments. Don't expect them to be complete.</para>
              </note>
              <para>
                This parameter supports auto-completion.
              </para>
						</entry>
					</row>

				</tbody>
			</tgroup>
		</informaltable>
	</section>

	<section id="export-xml-parameters">
    <title>Parameters for XML export</title>
    <indexterm><primary>Export</primary><secondary>XML files</secondary></indexterm>

		<informaltable frame="all">
			<tgroup cols="2" align="left">
				<colspec colname="c1" colwidth="4cm" />
				<colspec colname="c2" />
				<thead>
					<row>
						<entry>Parameter</entry>
						<entry>Description</entry>
					</row>
				</thead>
				<tbody valign="top">
					<row>
						<entry>-table</entry>
						<entry>
              The given tablename will be put into the <literal>&#60;table&#62;</literal> tag as an attribute.
						</entry>
					</row>

					<row>
						<entry>-decimal</entry>
						<entry>The decimal symbol to be used for numbers. The default is a dot (e.g. 3.14152)</entry>
					</row>

					<row>
						<entry id="export-xml-cdata">-useCDATA</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								Normally all data written into the xml file will
								be written with escaped XML characters (e.g. &lt; will be written as &amp;lt;).
								If you don't want that escaping, set <literal>-useCDATA=true</literal> and
								all character data (VARCHAR, etc) will be enclosed in a CDATA section.
							</para>
							 <para>
									With <literal>-useCDATA=true</literal> a HTML value would be written like this:
							 </para>
							 <para>
								<literal>&lt;![CDATA[&lt;b&gt;This is a title&lt;/b&gt;]]&gt;</literal>
							</para>
							<para>
								With <literal>-useCDATA=false</literal> (the default) a HTML value would be written like this:</para>
							<para>
								<literal>&amp;lt;b&amp;gt;This is a title&amp;lt;/b&amp;gt;</literal>
							</para>
						</entry>
					</row>

					<row>
						<entry id="export-stylesheet">-stylesheet</entry>
						<entry>The name of the XSLT stylesheet that should be used
						to transform the &wb-productname; specific XML file into a
						different format. If -stylesheet is specified, -xsltoutput has
						to be specified as well.</entry>
					</row>

					<row>
						<entry>-xsltOutput</entry>
						<entry>The resulting output file (specified
						with the -file parameter), can be transformed using XSLT after
						the export has finished. This parameter then defines
						the name of the outputfile of the transformation.</entry>
					</row>
					<row>
						<entry>-verboseXML</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
                This parameter controls the tags that are used in the XML file and minor formatting features.
								The default is -verboseXML=true and this will generate more readable tags and formatting. However the overhead
								imposed by this is quite high. Using -verboseXML=false uses shorter tag names
                (not longer then two characters) and does put more information in one line. This output is
								harder to read for a human but is smaller in size which could be important for exports with large result sets.
							</para>
						</entry>
					</row>
				</tbody>
			</tgroup>
		</informaltable>
	</section>

	<section id="export-sql-parameters">
    <title>Parameters for type SQLUPDATE, SQLINSERT or SQLDELETEINSERT</title>
    <indexterm><primary>Export</primary><secondary>SQL INSERT script</secondary></indexterm>
    <indexterm><primary>Export</primary><secondary>SQL UPDATE script</secondary></indexterm>

		<informaltable frame="all">
			<tgroup cols="2" align="left">
				<colspec colname="c1" colwidth="4cm" />
				<colspec colname="c2" />
				<thead>
					<row>
						<entry>Parameter</entry>
						<entry>Description</entry>
					</row>
				</thead>

				<tbody valign="top">
					<row>
						<entry>-table</entry>
						<entry>
							Define the tablename to be used for the UPDATE or INSERT
							statements. This parameter is required if the SELECT statement has
							multiple tables in the FROM list.
							table.
						</entry>
					</row>

					<row>
						<entry id="export-sql-cleanup">-charfunc</entry>
						<entry>
							<para>
								If this parameter is given, any
								non-printable character in a text/character column will be
								replaced with a call to the given function with the ASCII
								value as the parameter.
							</para>
							<para>
								If -charfunc=chr is
								given (e.g. for an Oracle syntax), a CR (=13) inside a
							character column will be replaced with:</para>
							<para><literal>INSERT
									INTO ... VALUES (&#39;First line&#39;||chr(13)||&#39;Second
								line&#39; ... )</literal>
							</para>
							<para>This setting will affect ASCII values from 0 to 31</para>
						</entry>
					</row>

					<row>
						<entry>-concat</entry>

						<entry>
							If the parameter <literal>-charfunc</literal> is used
							&wb-productname; will concatenate the individual pieces using
							the ANSI SQL operator for string concatenation. In case
							your DBMS does not support the ANSI standard (e.g. MS ACCESS)
							you can specify the operator to be used: <literal>-concat=+</literal>
						defines the plus sign as the concatenation operator.</entry>
					</row>

					<row>
						<entry id="export-sql-literal-formats">-sqlDateLiterals</entry>
						<entry>
							<para>Possible values: <literal>jdbc</literal>, <literal>ansi</literal>, <literal>dbms</literal>, <literal>default</literal></para>
							<para>
								This parameter controls the generation of date or timestamp
								literals. By default literals that are specific for the current
								DBMS are created. You can also choose to create literals that
								comply with the JDBC specification or ANSI SQL literals for dates
								and timestamps.
							</para>
							<para>
								<emphasis role="bold"><literal>jdbc</literal></emphasis> selects the creation of JDBC compliant literals.
								These should be usable with every JDBC based tool, including your own Java code:
								<literal>{d '2004-04-28'}</literal> or
								<literal>{ts '2002-04-02 12:02:00.042'}</literal>. This is the
								recommended format if you plan to use &wb-productname; (or any
								other JDBC based tool) to run the generated statements.
							</para>

							<para>
								<emphasis role="bold"><literal>ansi</literal></emphasis> selects the creation of ANSI SQL compliant
								date literals: <literal>DATE '2004-04-28'</literal> or
								<literal>TIMESTAMP '2002-04-02 12:04:00'</literal>. Please consult the
								manual of the target DBMS, to find out whether it supports ANSI compliant
								date literals.
							</para>
							<para>
								<emphasis role="bold"><literal>default</literal></emphasis> selects the creation of quoted date and timestamp
								literals in ISO format (e.g. '2004-04-28'). Several DBMS support this format (e.g. PostgreSQL, Microsoft SQL Server)
							</para>

							<para>
								<emphasis role="bold"><literal>dbms</literal></emphasis> selects the creation of specific
								literals to be used with the current DBMS (using e.g. the <literal>to_date()</literal>
								function for Oracle). The format of these literals can be customized if necessary
								in <literal>workbench.settings</literal> using the keys
								<literal>workbench.sql.literals.[type].[datatype].pattern</literal> where
								[type] is the type specified with this parameter and [datatype] is one of
								<literal>time, date, timestamp</literal>. If you add new literal types,
								please also adjust the key <literal>workbench.sql.literals.types</literal>
								which is used to show the possible values in the GUI (auto-completion
								"Save As" dialog, Options dialog).
								If no type is specified (or <emphasis>dbms</emphasis>), &wb-productname; first looks for an entry
								where [type] is the current <link linkend="dbid">dbid</link>. If no value
								is found, <literal>default</literal> is used.
							</para>
							<para>
								You can define the default literal format to be used for the WbExport command
								in the <link linkend="options-default-copy-literaltype">options dialog</link>.
							</para>
              <para>
                This parameter supports auto-completion.
              </para>
						</entry>
					</row>

					<row>
						<entry>-commitEvery</entry>
						<entry>
							<para>
								A numeric value which identifies
								the number of <literal>INSERT</literal> or <literal>UPDATE</literal> statements
								after which a <literal>COMMIT</literal> is put into the generated SQL script.
							</para>
							<para>-commitevery=100</para>
							<para>will create a <literal>COMMIT;</literal> after every 100th statement.</para>
							<para>
								If this is not specified one <literal>COMMIT;</literal> will be added at the
								end of the script. To suppress the final COMMIT, you can use
								<literal>-commitEvery=none</literal>. Passing <literal>-commitEvery=atEnd</literal>
								is equivalent to <literal>-commitEvery=0</literal>
							</para>
						</entry>
					</row>

					<row>
						<entry id="export-sql-createtable">-createTable</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								If this parameter is set to true, the necessary <literal>CREATE TABLE</literal>
								command is put into the output file. This parameter is ignored when creating
								<literal>UPDATE</literal> statements.
							</para>
              <para>
                Note that this will only create the table including its primary key.
                This will <emphasis role="bold">not</emphasis> create other constraints (such as foreign key or unique constraints)
                nor will it create indexes on the target table.
              </para>
						</entry>
					</row>

					<row>
						<entry>-useSchema</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
                If this parameter is set to <literal>true</literal>, all table names
                are prefixed with the approriate schema. The default is taken from
                the global option <link linkend="opt-sql-export-include-owner">Include owner in export</link>
							</para>
						</entry>
					</row>

					<row>
						<entry>-keyColumns</entry>
						<entry>
							<para>
								A comma separated list of column names that occur in the table
								or result set that should be used as the key columns for <literal>UPDATE</literal>
								or <literal>DELETE</literal>
							</para>
							<para>
								If the table does not have key columns, or the source SELECT statement uses
								a join over several tables, or you do not want to use the key columns defined
								in the database, this key can be used to define the key columns to be used
								for the UPDATE statements. This key overrides any key columns defined on the
								base table of the SELECT statement.
							</para>
						</entry>
					</row>

					<row>
						<entry id="sql-export-identity-cols">-includeAutoIncColumns</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
              <para>Default value: defined by <link linkend="opt-sql-include-identity">global option</link></para>
              <para>
                With this parameter you can override the <link linkend="opt-sql-include-identity">global option</link>
                to include identity and auto-increment columnfor <literal>INSERT</literal> statements.
              </para>
						</entry>
					</row>

					<row>
						<entry id="sql-export-readonly-cols">-includeReadOnlyColumns</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
              <para>Default value: <literal>false</literal></para>
              <para>
                By default, columns that are marked as read-only by the JDBC driver
                or are defined as a computed column are not part of generated SQL statements. By
                setting this parameter to <literal>true</literal>, those columns will be included
                in <literal>INSERT</literal> statements.
              </para>
						</entry>
					</row>

				</tbody>
			</tgroup>
		</informaltable>
	</section>

	<section id="export-ods-parameters">
    <title>Parameters for Spreadsheet types (ods, xslm, xls, xlsx)</title>
    <indexterm><primary>Export</primary><secondary>Spreadsheet</secondary></indexterm>
    <indexterm><primary>Export</primary><secondary>OpenOffice</secondary></indexterm>
    <indexterm><primary>Export</primary><secondary>Excel</secondary></indexterm>

		<informaltable frame="all">
			<tgroup cols="2" align="left">
				<colspec colname="c1" colwidth="4cm" />
				<colspec colname="c2" />
				<thead>
					<row>
						<entry>Parameter</entry>
						<entry>Description</entry>
					</row>
				</thead>
				<tbody valign="top">

					<row>
						<entry id="export-spreadsheet-title">-title</entry>
						<entry>The name to be used for the worksheet</entry>
					</row>

					<row>
						<entry id="export-infosheet">-infoSheet</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
              <para>Default value: <literal>false</literal></para>
              <para>
                If set to true, a second worksheet will be created that contains the generating SQL of the export.
								For ods exports, additional export information is available in the document properties.
              </para>
            </entry>
					</row>

					<row>
						<entry id="export-fixed-header">-fixedHeader</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
              <para>Default value: <literal>true</literal>  unless a target sheet is specified</para>
              <para>
                If set to true, the header row will be "frozen" in the Worksheet so that
                it will not scroll out of view.
              </para>
            </entry>
					</row>

					<row>
						<entry id="export-autofilter">-autoFilter</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
              <para>Default value: <literal>true</literal> unless a target sheet is specified</para>
              <para>
                If set to true, the "auto-filter" fetaure for the column headers will be turned on.
              </para>
            </entry>
					</row>

					<row>
						<entry id="export-optimize-colwidth">-autoColWidth</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
              <para>Default value: <literal>true</literal> unless a target sheet is specified</para>
              <para>
                If set to true, the width of the columns is adjusted to the width of the content.
              </para>
            </entry>
					</row>

          <row>
            <entry id="export-targetsheet">-targetSheet  -targetSheetName</entry>
            <entry>
              <para>Possible values: any valid index or name for a worksheet in an existing Excel file</para>
              <para>This parameter is only available for XLS and XLSX exports</para>
              <para>
                When using this parameter, the data will be written into an existing file and worksheet without
                changing the formatting in the spreadsheet. No formatting is applied as it is assumed
                that the target worksheet is properly set up.
              </para>
               <note>
                <para>
                  The parameters <literal>-autoFilter</literal>, <literal>-fixedHeader</literal> and <literal>-autoColWidth</literal> can still be used.
                  If <literal>-targetSheet</literal> or <literal>-targetSheetName</literal> are specified they default to
                  <literal>false</literal> unless they are explicitely passed as <literal>true</literal>.
                </para>
                <para>
                  If the parameters <literal>-dateFormat</literal> or <literal>-timestampFormat</literal> are specified
                  together with a target sheet, the format for date/timestamp columns in the Excel sheet will be overwritten.
                  To overwrite the format in the Excel sheet, those parameters must be specified explicitely.
                </para>
               </note>
              <para>
                If this parameter is used, the target file specified with the <literal>-file</literal> parameter
                <emphasis role="bold">must</emphasis> already exist
              </para>
              <para>
                If <literal>-targetSheet</literal> is supplied, the value for <literal>-targetSheetName</literal> is ignored
              </para>
              <para>
                These parameters support auto-completion if the <literal>-file</literal> parameter is already supplied.
              </para>
            </entry>
          </row>

				</tbody>
			</tgroup>
		</informaltable>
	</section>

	<section id="export-html-parameters">
    <title>Parameters for HTML export</title>
    <indexterm><primary>Export</primary><secondary>HTML</secondary></indexterm>

		<informaltable frame="all">
			<tgroup cols="2" align="left">
				<colspec colname="c1" colwidth="4cm" />
				<colspec colname="c2" />
				<thead>
					<row>
						<entry>Parameter</entry>
						<entry>Description</entry>
					</row>
				</thead>
				<tbody valign="top">
					<row>
						<entry>-createFullHTML</entry>
            <entry>
              <para>Possible values: <literal>true</literal>, <literal>false</literal></para>
              <para>Default value: <literal>true</literal></para>
              <para>
                If this is set to true, a full HTML page (including &lt;html&gt;, &lt;body&gt; tags)
                will be created.
               </para>
            </entry>
					</row>
					<row>
						<entry>-escapeHTML</entry>
            <entry>
              <para>Possible values: <literal>true</literal>, <literal>false</literal></para>
              <para>Default value: <literal>true</literal></para>
              <para>
                If this is set to true, values inside the data will be escaped (e.g. the &lt; sign will
                be written as &amp;lt;) so that they are rendered properly in an HTML page. If your data
                contains HTML tag that should be saved as HTML tags to the output, this parameter must
                be false.
               </para>
            </entry>
					</row>
					<row>
						<entry>-title</entry>
						<entry>The title for the HTML page (put into the &lt;title&gt; tag of the generated output)</entry>
					</row>
					<row>
						<entry>-preDataHtml</entry>
						<entry>
              <para>
                With this parameter you can specify a HTML chunk that will be added before the export
                data is written to the output file. This can be used to e.g. create a heading
                for the data: <literal>-preDataHtml='&lt;h1&gt;List of products&lt;/h1&gt;'</literal>.
              </para>
              <para>
                The value will be written to the output file "as is". Any escaping of the HTML
                must be provided in the parameter value.
              </para>
            </entry>
					</row>
					<row>
						<entry>-postDataHtml</entry>
						<entry>
              <para>
                With this parameter you can specify a HTML chunk that will be added after the
                data has been written to the output file.
              </para>
            </entry>
					</row>
				</tbody>
			</tgroup>
		</informaltable>
	</section>

	<section id="export-json-parameters">
    <title>Parameters for JSON export</title>

    <indexterm><primary>Export</primary><secondary>JSON</secondary></indexterm>

		<informaltable frame="all">
			<tgroup cols="2"  align="left">
				<colspec colname="c1" colwidth="4cm" />
				<colspec colname="c2" />
				<thead>
					<row>
						<entry>Parameter</entry>
						<entry>Description</entry>
					</row>
				</thead>

				<tbody valign="top">
					<row>
						<entry>-nullString</entry>
						<entry>
							<para>
                Defines the string value that should be written into the output file for a <literal>NULL</literal> value.
							</para>
						</entry>
					</row>
        </tbody>

      </tgroup>
    </informaltable>
  </section>

	<section id="export-compress">
		<title>Compressing export files</title>
    <indexterm><primary>Export</primary><secondary>compress</secondary></indexterm>

		<para>
			The <literal>WbExport</literal> command supports compressing of the generated output files.
			This includes the "main" export file as well as any associated LOB files.
		</para>
		<para>
			When using <link linkend="command-import"><literal>WbImport</literal></link> you can import
			the data stored in the archives without unpacking them. Simply specify the archive name
			with the <literal>-file</literal> parameter. &wb-productname; will detect that the input file
			is an archive and will extract the information "on the fly". Assume the following export
			command:
		</para>
		<programlisting>WbExport -type=text -file=/home/data/person.txt -compress=true -sourcetable=person;</programlisting>
		<para>
			This command will create the file <literal>/home/data/person.zip</literal> that will contain the
			specified <literal>person.txt</literal>. To import this export into the table employee, you can
			use the following command:
		</para>
		<programlisting>WbImport -type=text -file=/home/data/person.zip -table=employee;</programlisting>

		<para>
			Assuming the <literal>PERSON</literal> table had a BLOB colum (e.g. a picture of the person),
			the <literal>WbExport</literal> command would have created an additional file called
			<literal>person_blobs.zip</literal> that would contain all BLOB data. The <literal>WbImport</literal>
			command will automatically read the BLOB data from that archive.
		</para>
	</section>

	<section id="export-examples">
		<title>Examples</title>

		<section id="export-example-simple">

			<title>Simple plain text export</title>
<programlisting>WbExport -type=text
         -file='c:/data/data.txt'
         -delimiter='|'
         -decimal=','
         -sourcetable=data_table;</programlisting>

			<para>
				Will create a text file with the data from <literal>data_table</literal>.
				Each column will be separated with the character | Each fractional number
				will be written with a comma as the decimal separator.
			</para>

		</section>

    <section id="export-multi-table">
      <title>Exporting multiple tables</title>
<programlisting>WbExport -type=text
         -outputDir='c:/data'
         -delimiter=';'
         -header=true
         -sourcetable=table_1, table_2, table_3, table_4;</programlisting>

      <para>
        This will export each specified table into a text file in the specified directory. The files are named <literal>"table_1.txt"</literal>,
        <literal>"table_2.txt"</literal> and so on. To export all tables of a schema, the <literal>-sourceTable</literal> parameter supports wildcards:
      </para>

<programlisting>WbExport -type=text
         -outputDir='c:/data'
         -delimiter=';'
         -header=true
         -sourcetable=my_schema.*;</programlisting>

      <para>
        Limiting the export data when using a table based export, can be done using the <literal>-tableWhere</literal> argument.
        This requires that the specified <literal>WHERE</literal> condition is valid for all tables, e.g. when every table has a
        column called <literal>MODIFIED_DATE</literal>
      </para>

<programlisting>WbExport -type=text
         -outputDir='c:/data'
         -delimiter=';'
         -header=true
         -tableWhere="WHERE modified_date > DATE '2009-04-02'"
         -sourcetable=table_1, table_2, table_3, table_4;</programlisting>

      <para>
        This will add the specified where clause to <emphasis role="bold">each</emphasis> <literal>SELECT</literal>, so that only rows are
        exported that were changed after April 2nd, 2009
      </para>

    </section>

		<section id="export-example-select">
			<title>Export based on a SELECT statement</title>
<programlisting>WbExport -type=text
         -file='c:/data/data.txt'
         -delimiter=','
         -decimal=','
         -dateFormat='yyyy-MM-dd';
SELECT * FROM data_table;</programlisting>
		</section>

		<section id="export-schema-export">
			<title>Export a complete schema</title>

			<para>
				To export all tables from the current connection into tab-separated files
				and compress the files, you can use the following statement:
			</para>
<programlisting>WbExport -type=text
         -outputDir=c:/data/export
         -compress=true
         -sourcetable=*;</programlisting>
			<para>
				This will create one zip file for each table containing the exported data as a
				text file. If a table contains BLOB columns, the blob data will be written into
				a separate zip file.
			</para>

			<para>
				The files created by the above statement can be imported into another database
				using the following command:
			</para>

<programlisting>WbImport -type=text
         -sourceDir=c:/data/export
         -extension=zip
         -checkDependencies=true;</programlisting>
		</section>

		<section id="export-example-insert">
			<title>Export as SQL INSERT script</title>
			<para>
				To generate a file that contains <literal>INSERT</literal> statements that can be
				executed on the target system, the following command can be used:
			</para>

<programlisting>WbExport -type=sqlinsert
         -file='c:/data/newtable.sql'
         -table=newtable;
SELECT * FROM table1, table2
WHERE table1.column1 = table2.column1;</programlisting>

			<para>
				will create a SQL script which that contains statements like
				<literal>INSERT INTO newtable (...) VALUES (...);</literal> and the
				list of columns are all columns that are defined by the SELECT statement.
			</para>
			<para>
				If the parameter -table is omitted, the creation of SQL
				<literal>INSERT</literal> statements is only possible,
				if the SELECT is based on a single table (or view).
			</para>
		</section>
		<section id="export-example-lobs">
			<title>Exporting LOB data</title>
			<note>
				<para>
					To extract the contents of CLOB columns you have to specify
					the parameter <link linkend="export-clobasfile"><literal>-clobAsFile=true</literal></link>,
					otherwise the contents of the CLOB columns will be written directly into the export file.
					BLOB columns will always be exported into separate tables.
				</para>
			</note>

			<para>
				When exporting tables that contain BLOB columns, one file for each blob column and row
				will be created. By default the generated filenames will contain the row and column number
				to make the names unique. You can however control the creation of filenames when exporting
				LOB columns using several different approaches. If a unique name is stored within the table
				you can use the <link linkend="export-lob-filename"><literal>-filenameColumn</literal></link>
				parameter to generate the filenames based on the contents of that column:
			</para>
<programlisting>WbExport -file='c:/temp/blob_table.txt'
         -type=text
         -delimiter=','
         -filenameColumn=file_name;</programlisting>
		 <para>
			 Will create the file <literal>blob_table.txt</literal> and for each blob a file
			 where the name is retrieved from the column <literal>BLOB_TABLE.FILE_NAME</literal>.
			 Note that if the filename column is not unique, blob files will be overwritten without
			 an error message.
		 </para>

		 <para>
			 You can also base the export on a SELECT statement and then generate the filename
			 using several columns:
		 </para>
<programlisting>WbExport -file='c:/temp/blob_table.txt'
         -type=text
         -delimiter=','
         -filenameColumn=fname;
SELECT blob_column, 'data_'||id_column||'_'||some_name||'.'||type_column as fname
FROM blob_table;</programlisting>

			<para>
				This examples assumes that the following columns are part of the table <literal>blob_table</literal>:
				<literal>id_column</literal>, <literal>some_name</literal> and <literal>type_column</literal>.
				The filenames for the blob of each row will be taken from the computed column
				<literal>fname</literal>. To be able to reference the column in the <literal>WbExport</literal>
				you must give it an alias.
			</para>
			<para>
				This approach assumes that only a single blob column is exported. When exporting multiple
				blob columns from a single table, it's only possible to create unique filenames
				using the row and column number (the default behaviour).
			</para>
		</section>

		<section id="export-replace-data">
			<title>Replace data during export</title>
			<para>
        When writing the export data, values in character columns can be replaced using regular expressions.
			</para>
<programlisting>WbExport -file='/path/to/export.txt'
         -type=text
         -replaceExpression='(\n|\r\n)' -replaceWith='*'
         -sourceTable=export_table;</programlisting>
       <para>
         This will replace each newline (either Windows' CR/LF or Unix LF) with the character *.
       </para>
       <para>
         The value for <literal>-replaceExpression</literal> defines a regular expression. In the example
         above multiple new lines will be replace with multiple <literal>*</literal> characters. To replace consecutive
         new lines with a single <literal>*</literal> character, use the regular expression <literal>-replaceExpression='(\n|\r\n)+'</literal>.
         (Note the + sign after the brackets)
       </para>

    </section>
	</section>

</section>