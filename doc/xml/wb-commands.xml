<section id="wb-commands">
	<title>Special &wb-productname; commands</title>

  <section id="command-export">
    <title>Export data - WbExport</title>

    <para>Exports the result of the <emphasis role="bold">next</emphasis>
        SQL statement (which has to produce a result set) to a file without
        loading the data into memory. If you want to save the data that is
        currently displayed in the result area into an external file, please
        use the <link linkend="export">Save Data as</link> feature.
    </para>
    <para>If you want to simply export the contents of one or more tables,
      the <literal>-sourcetable</literal> switch can be used to specify the
      tables. In this case no additional SELECT statement is necessary.
      You can also use the <link linkend="dbexplorer-spool">Database Explorer</link>
      to export multiple tables.
    </para>
    <para>
      You can also export the result of a <literal>SELECT</literal> statement, by
      selecting the statment in the editor, and then choose
      <menuchoice><guimenu>SQL</guimenu><guimenuitem>Export query result</guimenuitem></menuchoice>.
    </para>
		<para>
			When exporting data into a Text or XML file, the content of BLOB columns
			is written into separate files. One file for each column of each row. Text files 
			that are created this way can most probably onyl be imported again using &wb-productname; as 
			the main file will contain the filename of the BLOB data file instead of the actual BLOB data.
			The only other application that I know of, that can handle this type of imports is Oracle's 
			<literal>SQL*Loader</literal> utility. If you run the text export together with the 
			parameter <literal>-writeoracleloader=true</literal> the control file will contain the 
			approriate definitions to read the BLOB data from the external file.
		</para>
		
    <para>The command supports the following parameters:</para>

    <informaltable frame="all">
      <tgroup cols="2" align="left">
        <colspec colname="c1" colwidth="4cm" />
        <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>

          <tbody valign="top">
              <row>
              <entry><para>-type=[text |sqlinsert |sqlupdate |sqldeleteinsert |xml |html]</para></entry>

              <entry>
                <para>
                  Defines the type of the output file. <literal>sqlinsert</literal>
                  will create the necessary <literal>INSERT</literal> statements to put
                  the data into a table. If the records may already exist in the target table
                  but you don't want to (or cannot) delete the content of the table
                  before running the generated script, &wb-productname; can create a DELETE
                  statement for every <literal>INSERT</literal> statement. To create this
                  kind of script, use the <literal>sqldeleteinsert</literal> type.
                </para>
                <para>
                  In order for this to work properly the table needs to have keycolumns defined,
                  or you have to define the keycolumns manually using the <literal>-keycolumns</literal>
                  switch.
                </para>
                <para>
                  <literal>sqlupdate</literal> will generate UPDATE
                  statements that update all non-key columns of the table. This will only
                  generate valid <literal>UPDATE</literal> statements if at least one key
                  column is present. If the table does not have key columns defined, or you
                  want to use different columns, they can be specified using the <literal>-keycolumns</literal>
                  switch.
                </para>
              </entry>
          </row>

          <row>
              <entry><para>-file=&#60;filename&#62;</para></entry>
              <entry><para>Defines the name of the output file </para></entry>
          </row>

          <row>
              <entry><para>-sourcetable=table1,table2</para></entry>
              <entry><para>Defines the table(s) to be exported. If this
              switch is used, <literal>-outputdir</literal> is also required
              unless exactly one table is specified. If one table is
              specified, the -file parameter is used to generate the file
              for the table. If more then one table is specified, the
              <literal>-outputdir</literal> parameter is used to defined
              the directory where the generated files should be stored.
              Each file will be named as the exported table with the approriate
              extension (.xml, .sql, etc). You can specify * as the table
              name which will then export all tables accessible by the
              current user.
              </para>
              <para>If you want to export tables from a different user
              or schema you can use a schema name combined with a wildcard
              e.g. <literal> -sourcetable=otheruser.*</literal>. In this case
              the generated output files will contain the schema name as part of the
              filename (e.g. <literal>otheruser.person.txt</literal>).
              When <link linkend="command-import">importing</link> these files,
              &wb-productname; will try to import the tables into the schema/user
              specified in the filename. If you want to import them into
              a different user/schema, then you have to use the <literal>-schema</literal>
              switch for the <link linkend="command-import">import</link> command.
              </para>
              </entry>
          </row>
          <row>
              <entry><para>-outputdir=directory</para></entry>
              <entry><para>When using the <literal>-sourcetable</literal> switch
              with multiple tables, this parameter is mandatory and defines
              the directory where the generated files should be stored.
              </para></entry>
          </row>
          <row>
              <entry><para>-encoding</para></entry>
              <entry><para>Defines the encoding in which the file should be
              written. Common encodings are ISO-8859-1, ISO-8859-15, UTF-8 (or UTF8).
              To get a list of available encodings, execut <literal>WbExport</literal>
              with the parameter <literal>-showencoding</literal>
              </para></entry>
          </row>
          <row>
              <entry><para>-showencodings</para></entry>
              <entry><para>Displays the encodings supported by your Java version and
              operating system. If this parameter is present, all other parameters are ignored.
              </para></entry>
          </row>
          <row>
            <entry><para>-lineending</para></entry>
            <entry><para>Defines the line ending used for XML or text files. Possible
            values are: <literal>dos</literal>, <literal>win</literal>, <literal>crlf</literal>
            to create files that use the file ending using a CR (ASCII value 13) followed by
            a LF (ASCII value 10). For a single character line ending using the LF character
            use the value <literal>lf</literal> or <literal>unix</literal>.
            The default line ending used depends on the platform where &wb-productname; is running.
            </para>
            </entry>
          </row>
          <row>
            <entry><para>-compress</para></entry>
            <entry><para>Selects whether the output file of a text or XML export should be compressed 
						and put into a ZIP archive. If you specify <literal>-file=data.txt</literal>and 
						<literal>-compres=true</literal>, a ZIP archive with the name <literal>data.zip</literal>
						will be created that will contain the specified <literal>data.txt</literal>. 
						If the exported result set contains BLOBs, they will be stored in a separate archive, named 
						<literal>data_blobs.zip</literal>.
            </para>
            </entry>
          </row>

        </tbody>
      </tgroup>
    </informaltable>

    <section id="spool-sql-parameters">
      <title>Parameters for type SQLUPDATE, SQLINSERT or SQLDELETEINSERT</title>

      <informaltable frame="all">
        <tgroup cols="2" align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>

          <tbody valign="top">
            <row>
              <entry><para>-table</para></entry>

              <entry><para>Define the tablename to be used for the UPDATE or INSERT
              statements. This parameter is required if the SELECT statement has
              multiple tables in the FROM list. It can be used if only the data
              is retrieved from only one table to UPDATE or INSERT into a different
              table.</para></entry>
            </row>

            <row>
              <entry><para id="export-sql-cleanup">-charfunc</para></entry>

              <entry><para>If this parameter is given, any
              non-printable character in a text/character column will be
              replaced with a call to the given function with the ASCII
              value as the parameter. </para> <para>If -charfunc=chr is
              given (e.g. for an Oracle syntax), a CR (=13) inside a
              character column will be replaced with:</para>
              <para><literal>INSERT
              INTO ... VALUES (&#39;First line&#39;||chr(13)||&#39;Second
              line&#39; ... )</literal></para>

              <para>This setting will affect ASCII values from 0 to 31</para>
              </entry>
            </row>

            <row>
              <entry><para>-concat</para></entry>

              <entry><para>If the parameter <literal>-charfunc</literal> is used
              &wb-productname; will concatenate the individual pieces using
              the ANSI SQL operator for string concatenation. In case
              your DBMS does not support the ANSI standard (e.g. MS ACCESS)
              you can specify the operator to be used:</para>
              <para><literal>-concat=+</literal></para><para> defines the plus sign
              as the concatenation operator.</para></entry>
            </row>

            <row>
              <entry><para>-commitevery</para></entry>

              <entry><para>A numeric value which identifies
              the number of <literal>INSERT</literal> or <literal>UPDATE</literal> statements
              after which a <literal>COMMIT</literal> is put into the generated SQL script.</para>
              <para>-commitevery=100</para>
              <para>will create a <literal>COMMIT;</literal> after every 100th statement.</para>
              </entry>
            </row>

            <row>
              <entry><para>-createtable=[true|false]</para></entry>

              <entry><para>If this parameter is set to true,
              the necessary <literal>CREATE TABLE</literal> command is put into the output
              file. This parameter is ignored when creating <literal>UPDATE</literal>
              statements.</para>
              </entry>
            </row>

            <row>
              <entry><para>-keycolumns=column1, column2, ...</para></entry>

              <entry><para>
              If the table does not have key columns, or the source SELECT statement uses
              a join over several tables, or you do not want to use the key columns defined
              in the database, this key can be used to define the key columns to be used
              for the UPDATE statements. This key overrides any key columns defined on the
              base table of the SELECT statement.
              </para></entry>
            </row>

          </tbody>
        </tgroup>
      </informaltable>
    </section>

    <section id="spool-text-parameters">
      <title>Parameters for the type TEXT</title>

      <informaltable frame="all">
        <tgroup cols="2"  align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>

          <tbody valign="top">
            <row>
              <entry><para>-delimiter</para></entry>

              <entry><para>The given string sequence will be
              placed between two columns. The default is a tab character
              (<literal>-delimiter=\t</literal>
              </para></entry>
            </row>

            <row>
              <entry><para>-dateformat</para></entry>

              <entry><para>The date format to be used when
              writing date columns into the output file. The syntax of the
              format definition, is the same as for the SimpleDateFormat
              class.</para></entry>
            </row>

            <row>
              <entry><para>-datetimeformat</para></entry>

              <entry><para>The format to be used when writing
              datetime (or timestamp) columns into the output file.
              </para></entry>
            </row>

            <row>
              <entry><para>-quotechar</para></entry>

              <entry><para>The character (or sequence of characters) to be used
                  to enclose text (character) data if the delimiter is
                  contained in the data. By default quoting is disabled until a quote character
                  is defined. To set the double quote as the quote character
                  you have to enclose it in single quotes: <literal>-quotechar='"'</literal>
              </para></entry>
            </row>

            <row>
              <entry><para>-quoteAlways</para></entry>

              <entry><para>If quoting is enabled (via <literal>-quotechar</literal>,
                  then character data will only be quoted
                  if the delimiter is found inside the actual value that is
                  written to the output file. If <literal>-quoteAlways=true</literal> is
                  specified, character data will always be
                  enclosed in the specified quote character.</para>
              </entry>
            </row>

            <row>
              <entry><para>-decimal</para></entry>

              <entry><para>The decimal symbol to be used for
                  numbers. The default is a dot (e.g. 3.14152)</para>
              </entry>
            </row>

                        <!--
            <row>
              <entry><para>-cleancr=[true|false]</para></entry>

              <entry><para>Controls the handling of non
                  printable characters inside character columns. If
                  <literal>-cleancr=true</literal>, any character &#60; ASCII 32 will
                  be replaced with a space character. This results in
                  exported data that is different to the content of the database,
                  but will allow importing using tools that do not
                  support embedded newlines.
                  If you plan to use <literal>WbImport</literal> to import
                  the textfile, then using the <literal>-escapetext</literal> flag
                  is the recommended way to deal with special characters. Using
                  the text encoding offered by <literal>WbImport/WbExport</literal>
                  special characters can be written and restored using text files that would
                  otherwise not support this.
              </para></entry>
            </row>
            -->

            <row>
              <entry><para id="text-escape-switch">-escapetext</para></entry>

              <entry><para>This parameter controls the escaping of non-printable
              or non-ASCII characters. Valid options are <literal>ctrl</literal> which
              will escape everything below ASCII 32 (newline, tab, etc), <literal>7bit</literal>
              which will escape everything below ASCII 32 and above 126, <literal>8bit</literal>
              which will escape everything below ASCII 32 and above 255 and <literal>extended</literal>
              which will escape everything outside the range [32-126] and [161-255]
              </para>
              <para>This will write a unicode representation of the character into the
              text file e.g. \n for a newline, \u00F6 for &ouml;. This file
              can only be imported using &wb-productname; (at least I don't know
              of any DBMS specific loader that will decode this properly)</para>
              </entry>
            </row>

            <row>
              <entry><para>-header=[true|false]</para></entry>

              <entry><para>If this parameter is set to true,
              the header (i.e. the column names) are placed into the
              output file. The default is to not create a header line.
							You can define the default value for this parameter 
							in the file <link linkend="export-text-header-default">workbench.settings</link>.
              </para></entry>
            </row>
						<row>
							<entry><para>-writeoracleloader=[true|false]</para></entry>
							<entry><para>
									This parameter controls the creation of Oracle SQL*Loader
									control files. If it is set to true, then &wb-productname;
									will generate a control file for each exported text file,
									that can be used to import the text file using SQL*Loader
									instead of &wb-productname;. The control file has the same
									filename as the output file but with the ending <literal>.ctl</literal>
								</para>
								<para>
									Note that the generated control file will most probably
									need some adjustments before you can actually use it. It is mainly
									meant as a template that needs further refinement.
								</para>
							</entry>
						</row>
						
          </tbody>
        </tgroup>
      </informaltable>
    </section>

    <section id="spool-xml-parameters">
      <title>Parameters for type XML</title>

      <informaltable frame="all">
        <tgroup cols="2" align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody valign="top">
            <row>
              <entry><para>-table</para></entry>
              <entry><para>The given tablename will be put
              into the &#60;table&#62; tag as an attribute.</para></entry>
            </row>

            <row>
              <entry><para>-dateformat</para></entry>
              <entry><para>The date format to be used when
              writing date columns into the output file. The syntax of the
              format definition, is the same as for the SimpleDateFormat
              class.</para></entry>
            </row>

            <row>
              <entry><para>-datetimeformat</para></entry>
              <entry><para>The format to be used when writing
              datetime (or timestamp) columns into the output file.
              </para></entry>
            </row>

            <row>
              <entry><para>-decimal</para></entry>
              <entry><para>The decimal symbol to be used for
              numbers. The default is a dot (e.g. 3.14152)</para></entry>
            </row>
            <row>
              <entry><para>-usecdata</para></entry>
              <entry><para>Normally any character data written into the xml file will
                  be processes to escape XML characters (e.g. &lt; will be written as &amp;lt;).
                  If you don't want that escaping, set <literal>-usecdata=true</literal> and
                  all character data (VARCHAR, etc) will be enclosed in a CDATA section.</para>
                  <para>With <literal>-cdata=true</literal> a HTML value would be written like this:</para>
                  <para>
                  <literal>&lt;![CDATA[&lt;b&gt;This is a title&lt;/b&gt;]]&gt;</literal>
                  </para>
                  <para>
                  With <literal>-cdata=false</literal> (the default) a HTML value would be written like this:</para>
                  <para>
                  <literal>&amp;lt;b&amp;gt;This is a title&amp;lt;/b&amp;gt;</literal>
                  </para>
              </entry>
            </row>

            <row>
              <entry><para>-stylesheet</para></entry>
              <entry><para>The name of the XSLT stylesheet that should be used
              to transform the &wb-productname; specific XML file into a
              different format. If -stylesheet is specified, -xsltoutput has
              to be specified as well.</para></entry>
            </row>
            <row>
              <entry><para>-xsltoutput</para></entry>
              <entry><para>The resulting output file (specified
              with the -file parameter), can be transformed using XSLT after
              the export has finished. This parameter then defines
              the name of the outputfile of the transformation.</para></entry>
            </row>
            <row>
              <entry><para>-verboseXML=[true|false]</para></entry>
              <entry><para>This parameter controls the tags that
              are used in the XML file and minor formatting features.
              The default is -verboseXML=true and this will generate
              more readable tags and formatting. However the overhead
              imposed by this is quite high. Using -verboseXML=false
              uses shorter tag names (not longer then two characters) and
              does put more information in one line. This output is
              a harder to read for a human but is smaller in size which
              could be important for exports with large result sets.
              </para></entry>
            </row>

          </tbody>
        </tgroup>
      </informaltable>

    </section>
    <section id="export-examples">
      <title>Examples</title>

<programlisting>WbExport -type=text
         -file='c:/data/data.txt'
         -delimiter='|'
         -decimal=',';
SELECT * FROM data_table;</programlisting>

    <para>Will create a text file with the data from <literal>data_table</literal>.
        Each column will be separated with the character | Each fractional number
        will be written with a comma as the decimal separator. As the
        SELECT statement retrieves all rows and columns from the table, this
        could also be written as:
    </para>

<programlisting>WbExport -type=text
         -file='c:/data/data.txt'
         -delimiter='|'
         -decimal=','
         -sourcetable=data_table;</programlisting>
    <para>There is a difference in the behaviour of the command regarding the "Max. Rows" setting
    in the GUI. When you use the <literal>WbExport</literal> command together with
    a <literal>SELECT</literal> query, the Max. Rows setting will be respected
    by the <literal>SELECT</literal> statement (and you will see a warning
    that the result set was limited). When you use the <literal>WbExport</literal>
    with the <literal>-sourcetable</literal> switch, the "Max. Rows" setting
    will not be respected, and all rows from the table will be written into
    the specified file.</para>

    <para>To generate a file that contains SQL INSERT statements that can be
      executed on the target system, the following command can be used:</para>

<programlisting>WbExport -type=sqlinsert
         -file='c:/data/newtable.sql'
         -table=newtable;
SELECT * FROM table1, table2
WHERE table1.column1 = table2.column1;</programlisting>

      <para>will create a SQL scripts which inserts the data from table1
      and table2 into a table called newtable. If the parameter -table is
      omitted, the creation of SQL INSERT statements is only possible, if the SELECT is
      based on a single table (or view).</para>
      <para>For more details on how you can export and import data using the XML format
      please refer to <xref linkend="xml-export-import"/></para>
    </section>
    <section id="export-date-formats">
      <title>Specifying date formats</title>
      <para>The date/time format that can be specified with the <literal>-dateformat</literal>
      or <literal>-timestampformat</literal> accepts fhe following format codes. These
      are the format codes for Java's <ulink url="http://java.sun.com/j2se/1.4.2/docs/api/java/text/SimpleDateFormat.html">SimpleDateFormat</ulink>
      class.
      </para>
    </section>

</section>

  <section id="command-import">
    <title>Import data - WbImport</title>
    <para>The WbImport command can be used to import data from text or
          XML files into a table in the database. WbImport can read the XML files generated by the
    <link linkend="command-export">WbExport</link> command&apos;s XML format. It can
    also read text files created by the WbExport command that escape non-printable
    characters.
    </para>
    <para>During the import of text files, empty lines (i.e. lines which only
          contain whitespace) will be silently ignored. The text import does not support records
          spanning multiple lines in the input file. If the input file is created using
          WbExport then it is recommended to use the <literal>-escapetext</literal> switch
          to escape non-printable characters which could break text import.
      </para>
        <para>The <link linkend="data-pumper">DataPumper</link> can also be used to import text files
        into a database table, though it does not offer all of the possibilities as the
    <literal>WbImport</literal> command.
        </para>

    <para>The WbImport command has the following syntax</para>
    <informaltable frame="all">
      <tgroup cols="2" align="left">
        <colspec colname="c1" colwidth="4cm" />
        <colspec colname="c2"/>
        <thead>
          <row>
            <entry>Parameter</entry>
            <entry>Description</entry>
          </row>
        </thead>
        <tbody valign="top">
          <row>
            <entry><para>-type=[xml|text]</para></entry>
            <entry><para>Defines the type of the input file</para></entry>
          </row>
          <row>
            <entry><para>-file</para></entry>
            <entry><para>Defines the full name of the input file. Alternatively
            you can also specify a directory (using <literal>-sourcedir</literal>
            from which all xml files are imported</para></entry>
          </row>
          <row>
            <entry><para>-sourcedir</para></entry>
            <entry><para>Defines a directory which contains import files. All
            files from that directory will be imported. If this switch is used
            with text files, then it is assumed that each filename (without the extension)
            defines the target table.
                        </para></entry>
          </row>
          <row>
            <entry><para>-extension</para></entry>
            <entry><para>When using the <literal>-sourcedir</literal> switch, the
            extension for the files can be defined. All files ending with the supplied
            value will be processed. (e.g. <literal>-extension=csv</literal>).
            The extension given is case-sensitiv (i.e. <literal>TXT</literal> is something
            different than <literal>txt</literal>
                        </para></entry>
          </row>
          <row>
            <entry><para>-commitevery</para></entry>
            <entry><para>Issue a commit every (number) rows. If this parameter
            is not passed (or a value of zero or lower), then &wb-productname; will commit
            everything when all rows have been imported. </para></entry>
          </row>
          <row>
            <entry><para>-mode</para></entry>
            <entry><para>Defines how the data should be sent to the database. Possible
            values are <literal>INSERT</literal>, <literal>UPDATE</literal>,
            <literal>INSERT,UPDATE</literal> and <literal>UPDATE,INSERT</literal>
            For details please refer to the <link linkend="import-update-mode">update mode</link>
            explanation.
            </para>
            </entry>
          </row>
          <row>
            <entry><para>-ContinueOnError</para></entry>
            <entry><para>This parameter controls the behaviour when errors occur during
            the import. The default is <literal>true</literal>, meaning that the import
            will continue even if an error occurs during file parsing or updating the database.
            Set this parameter to <literal>false</literal>
            if you want to stop the import as soon as an error occurs.
            </para></entry>
          </row>
          <row>
            <entry><para>-keyColumns</para></entry>
            <entry><para>Defines the key columns for the target table. This parameter
            is only necessary if import is running in <literal>UPDATE</literal> mode.
            </para>
            <para>
            This parameter is ignored if files are imported using the <literal>-sourcedir</literal>
            parameter
            </para></entry>
          </row>
          <row>
            <entry><para>-table</para></entry>
            <entry><para>Defines the table into which the data should be imported</para>
            <para>This parameter is ignored files are imported using the <literal>-sourcedir</literal>
            parameter
            </para></entry>
          </row>
          <row>
            <entry><para>-schema</para></entry>
            <entry><para>Defines the schema into which the data should be imported. This
            is necessary for DBMS that support schemas, and you want to import
            the data into a different schema, then the current one.</para>
            </entry>
          </row>
          <row>
            <entry><para>-encoding</para></entry>
            <entry><para>Define the encoding for the input file. For XML files
            the default encoding is UTF-8, for text files it's ISO-8859-1</para></entry>
          </row>
          <row>
            <entry><para>-deletetarget</para></entry>
            <entry><para>If this parameter is set to true, data from the target table will
            be deleted (using <literal>DELETE FROM ...</literal>) before the import is started.
            </para></entry>
          </row>
          <row>
            <entry><para>-usebatch</para></entry>
            <entry><para>Enable or disable the use of the JDBC batch update features. If the
            JDBC driver supports this, the INSERT (or UPDATE) performance can be increased.
            This parameter will be ignored if the driver does not support batch updates or if
            the mode is not UPDATE or INSERT (i.e. if <literal>-mode=update,insert</literal>
              or <literal>-mode=insert,update</literal>is used).
              Note that for some JDBC drivers this means that all SQL statements that
              are generated for the input file will be kept in memory until the batch
              is execute, so for large input files this might lead to memory problems.
              In this case the size of the batch queue should be controlled using
              the <literal>-batchsize</literal> parameter.
            </para></entry>
          </row>
          <row>
              <entry><para>-batchsize</para></entry>
              <entry><para>
                  Controls the size of the batch if <literal>-usebatch=true</literal>
                  is used. If this parameter is not specified then <emphasis role="bold">all</emphasis>
                  generated SQL statements will be put into the batch queue</para>
              </entry>
          </row>
          <row>
              <entry><para>-updatewhere</para></entry>
              <entry><para>When using <link linkend="import-update-mode">update mode</link>
                an additional <literal>WHERE</literal> clause can be specified to limit
                the rows that are updated. The value of the <literal>-updatewhere</literal>
                parameter will be added to the generated <literal>UPDATE</literal> statement.
                If the value starts with the keyword <literal>AND</literal> or <literal>OR</literal>
                the value will be added without further changes, otherwise the value
                will be added as an <literal>AND</literal> clause enclosed in brackets.
                This parameter will be ignored if update mode is not active.
              </para>
              </entry>
          </row>

        </tbody>
      </tgroup>
    </informaltable>

    <section id="import-text-parameters">
      <title>Parameters for the type TEXT</title>

      <informaltable frame="all">
        <tgroup cols="2"  align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>

          <tbody valign="top">
            <row>
              <entry><para>-filecolumns</para></entry>
              <entry><para>A comma separated list of the table columns in the import file
              Each column from the file should be listed with the approriate column
              name from the target table. This parameter also defines
              the order in which those columns appear in the file.
              If the file does not contain a header line or the header line does not
              contain the names of the columns in the database (or has different names),
              this parameter has to be supplied. If a column from the input
              file has no match in the target table, then it should be specified with
              the name $wb_skip$. You can also specify the $wb_skip$ flag for
              columns which are present but that you want to exclude from the
              import.
              </para>
              <para>This parameter is ignored when the <literal>-sourcedir</literal>
              parameter is used.</para>
                            </entry>
            </row>
            <row>
              <entry><para>-importcolumns</para></entry>
              <entry><para>Defines the columns that should be imported. If all
              columns from the input file should be imported (the default), then
              this parameter can be ommited. If only certain columns should be
              imported then the list of columns can be specified here. The column
              names should match the names provided with the -filecolumns switch.
              The same result can be achieved by providing the columns
              that should be excluded as <literal>$wb_skip$</literal> columns
              in the <literal>-filecolumns</literal> switch. Which one you choose
              is mainly a matter of taste. Listing all columns and excluding
              some using <literal>-importcolumns</literal> might be more readable
              because the structure of the file is still "visible" in the
              <literal>-filecolumns</literal> switch.</para>
              <para>This parameter is ignored when the <literal>-sourcedir</literal>
              parameter is used.</para>
                            </entry>
            </row>
            <row>
              <entry><para>-delimiter</para></entry>
              <entry><para>Define the character which separates columns in one line. Records are always
              separated by newlines (either CR/LF or only a LF character)</para></entry>
            </row>

            <row>
              <entry><para>-dateformat</para></entry>
              <entry><para>The format for date columns
              The syntax of the format definition, is the same as for the SimpleDateFormat
              class.</para></entry>
            </row>

            <row>
              <entry><para>-datetimeformat</para></entry>
              <entry><para>The format for datetime (or timestamp) columns in the input file.
              </para></entry>
            </row>

            <row>
              <entry><para>-quotechar</para></entry>
              <entry><para>The character which was used to quote values where the delimiter is contained.
              </para></entry>
            </row>

            <row>
              <entry><para>-decimal</para></entry>
              <entry><para>The decimal symbol to be used for
              numbers. The default is a dot.</para></entry>
            </row>

            <row>
              <entry><para>-header=[true|false]</para></entry>
              <entry><para>If set to true, indicates that the file contains a header
              line with the column names for the target table. This will also ignore
              the data from the first line of the file. If the column names
              to be imported are defined using the <literal>-filecolumns</literal> 
			  or the <literal>-importcolumns</literal> switch,
              this parameter has to be set to true nevertheless, otherwise the first row
              would be treated as a regular data row.</para>
              <para>This parameter is always set to true when the <literal>-sourcedir</literal>
              parameter is used.</para>
                            </entry>
            </row>
            <row>
              <entry><para>-decode=[true|false]</para></entry>
              <entry><para>This controls the decoding of escaped characters. If the
              export file was e.g. written with <link linkend="text-escape-switch">escaping enabled</link>
              then you need to set <literal>-decode=true</literal> in order to interpret string sequences
              like \t, \n or escaped Unicode characters properly. This is not enabled by default
              because applying the necessary checks has an impact on the performance.
              </para></entry>
            </row>
            <row>
              <entry><para>-columnfilter</para></entry>
              <entry><para>
                This defines a filter on column level that selects only certain rows
                from the input file to be sent to the database. The filter has to be
                define <literal>as column1="regex",column2="regex"</literal>
              </para>
              <para>If more then one column is listed, then all expressions must match
              in order for the input row to be processed. The expressions to be applied to
              the input value are regular expressions.
              </para>
              <para>This parameter is ignored when the <literal>-sourcedir</literal>
              parameter is used.</para>
                            </entry>
            </row>
            <row>
              <entry><para>-linefilter</para></entry>
              <entry><para>
              To define a filter on the level of the input row (rather then
              for each column individually) you can define a regular expression
              that is applied to the whole input row. As the regular expressioin
              will be applied to the input row as it is retrieved from the
              input file, the column delimiter(s) have to be taken into account
              when defining the regular expression.
              </para></entry>
            </row>
            <row>
              <entry><para>-blobisfilename</para></entry>
              <entry><para>
								When exporting tables that have BLOB columns using <link linkend="command-export">WbExport</link>
								into text files, each BLOB will be written into a separate file. The actual column 
								data of the text file will contain the file name of the external file. 
								When importing text files that do not reference external files
								into tables with BLOB columns setting this paramter to false, will send the content 
								of the BLOB column "as is" to the DBMS. This will of course only work
								if the JDBC driver can handle the data that in the BLOB columns of the 
								text file. The default for this parameter is <literal>true</literal>
              </para></entry>
            </row>
						
          </tbody>
        </tgroup>
      </informaltable>

      <para>Examples:</para>
      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,birthday
         -dateformat="yyyy-MM-dd";</programlisting>

     <para>
         This imports a file with three columns into a table named person. The
         first column in the file is <literal>lastname</literal>, the second column
         is <literal>firstname</literal> and the third column is <literal>birhtday</literal>.
         Values in date columns are formated as yyyy-MM-dd
     </para>

      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,$wb_skip$,birthday
         -dateformat="yyyy-MM-dd";</programlisting>

     <para>
         This will import a file with four columns. The third column in the file
         does not have a corresponding column in the table <literal>person</literal>
         so its specified as <literal>$wb_skip$</literal> and will not be imported.
     </para>

      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,phone,birthday
         -importcolumns=lastname,firstname;</programlisting>

      <para>
          This will import a file with four columns where all columns
          exist in the target table. Only <literal>lastname</literal> and
          <literal>firstname</literal> will be imported. The same effect could
          be achieved by specifying $wb_skip$ for the last two columns and leaving
          out the -importcolumns switch. Using -importcolumns is a bit more readable
          because you can still see the structure of the input file. The
          version with <literal>$wb_skip$</literal> is mandatory if the input file
          contains columns that do not exist in the target table.
      </para>

     <para>If you want to import certain rows from the input file, you can
     use regular expressions:</para>
      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,birthday
         -columnfilter=lastname="^Bee.*",firstname="^Za.*"
         -dateformat="yyyy-MM-dd";</programlisting>
     <para>The above statement will import only rows where the column <literal>lastname</literal>
     contains values that start with <literal>Bee</literal> and the column <literal>firstname</literal>
     contains values that start with <literal>Za</literal>. So <literal>Zaphod Beeblebrox</literal>
     would be imported, <literal>Arthur Beeblebrox</literal> would not be imported.
     </para>
     <para>
     If you want to learn more about regular expressions, please have a look
     at <ulink url="http://www.regular-expressions.info/"/>
     </para>

     <para>If you want to limit the rows that are updated but cannot filter them
      from the input file using <literal>-columnfilter</literal> or <literal>-linefilter</literal>,
      use the <literal>-updatewhere</literal> parameter:</para>
      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=id,lastname,firstname,birthday
         -keycolumns=id
         -mode=update
         -updatewhere="source &lt;&gt; 'manual'"</programlisting>
      <para>This will update the table <literal>PERSON</literal>. The generated <literal>UPDATE</literal>
      statement would normally be: <literal>UPDATE person SET lastname=?, firstname=?, birthday=? WHERE id=?</literal>.
      The table contains entries that are maintained manually (identified by the value 'manual' in
      the column <literal>source</literal>) and should not be updated by &wb-productname;. By specifying
      the <literal>-updatewhere</literal> parameter, the above <literal>UPDATE</literal> statement will
      be extended to <literal>WHERE id=? AND (source &lt;&gt; 'manual')</literal>. Thus skipping
      records that are flagged as manual even if they are contained in the input file.
      </para>

            <note>
                When importing text files, records spanning multiple lines in the input
                file are <emphasis role="strong">not</emphasis> supported, even when
                they are quoted.
            </note>
    </section>

    <section id="import-xml-parameters">
      <title>Parameters for the type XML</title>
      <para>The XML import only works with files generated by the <link linkend="command-export">WbExport</link>
      command.</para>
        <informaltable frame="all">
          <tgroup cols="2"  align="left">
            <colspec colname="c1" colwidth="4cm" />
            <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody valign="top">
              <row>
                <entry><para>-verboseXML=[true|false]</para></entry>
                <entry><para>If the XML was generated with <literal>-verboseXML=false</literal>
                then this needs to be specified also when importing the file.
                Beginning with build 78, the &wb-productname; writes the information
                about the used tags into the meta information. So it is no
                longer necessary to specify whether -verboseXML was true when
                creating the XML file.
                </para></entry>
              </row>
              <row>
                <entry><para>-sourcedir</para></entry>
                <entry><para>Specify a director which contains the XML files.
                All files in that directory ending with ".xml"
                (lowercase!) will be processed.
                The table into which the data is imported is read
                from the XML file, also the columns to be imported. The parameters
                <literal>-keycolumns</literal>, <literal>-table</literal> and
                <literal>-file</literal> are ignored if this parameter is specified.
                If XML files are used that are generated with a version prior to
                build 78, then all files need to use either the long or short
                tag format and the <literal>-verboseXML=false</literal> parameter has
                to be specified if the short format was used.
                </para>
                <para>When importing several files at once, the files will be
                imported into the tables specified in the XML files. You cannot
                specify a different table (apart from editing the XML file
                before starting the import).
                </para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
    </section>

    <section id="import-update-mode">
      <title>Update mode</title>
      <para>The <literal>-mode</literal> parameter controls the way the data is send
        to the database. The default is <literal>INSERT</literal>. &wb-productname; will
        generate an <literal>INSERT</literal> statement for each record. If the <literal>INSERT</literal>
        fails no further processing takes place for that record.
      </para>
      <para>If <literal>-mode</literal> is set to <literal>UPDATE</literal>, &wb-productname; will
        generate an <literal>UPDATE</literal> statement for each row. In order for this to work,
        the table needs to have a primary key defined, and all columns of the primary key need to
        be present in the import file. Otherwise the generated <literal>UPDATE</literal> statement
        will modify rows that should not be modified. This can be used to update existing
        data in the database based on the data from the export file.
      </para>
      <para>To either update or insert data into the table, both keywords can be specified
        for the <literal>-mode</literal> parameter. The order in which they appear as the parameter
        value, defines the order in which the respective statements are sent to the database. If the first
        statement fails, the second will be executed. For <literal>-mode=insert,update</literal> to
        work properly a primary or unique key has to be defined on the table. &wb-productname;
        will catch any exception (=error) when inserting a record, then it will try updating
        the record, based on the specified keycolumns.
        The <literal>-mode=update,insert</literal> works the other way. First &wb-productname;
        will try to update the record based on the primary keys. If the DBMS signals that no rows
        have been updated, it is assumed that the row does not exist and the record will be inserted
        into the table. This mode is recommended when no primary or unique key is defined on the table,
        and an <literal>INSERT</literal> would always succeed.
      </para>
      <para>The keycolumns defined with the <literal>-keycolumns</literal> parameter don't
      have to match the real primary key, but they should identify one row uniquely.
      </para>
     <para>You cannot use the update mode, if you select <emphasis role="bold">only</emphasis> key columns.
     The values from the source are used to build up the <literal>WHERE</literal> clause for the
     <literal>UPDATE</literal> statement. If ony key columns are defined, then there would be nothing to
     update.
      </para>

      <para>
        For maximum performance, choose the update strategy that will result in a succssful
        first statement more often. As a rule of thumb:
        <itemizedlist>
          <listitem>Use <literal>-mode=insert,update</literal>, if you expect more rows to be inserted then updated.</listitem>
          <listitem>Use <literal>-mode=update,insert</literal>, if you expect more rows to be updated then inserted.</listitem>
        </itemizedlist>
      </para>
    </section>

  </section>

    <section id="command-copy">
      <title>Copy one database to another - WbCopy</title>

		<para>
			The <literal>WbCopy</literal> is essentially the command line version of the
			the <link linkend="data-pumper">DataPumper</link>. For a more detailed explanation
			of the copy process, please refer to that section. It bascially chains a WbExport and a
			<literal>WbImport</literal> statement without the need of an intermediate data file.
			The <literal>WbCopy</literal> command requires that a connection to the source and target
			database can be made at the same time.
		</para>

      <section id="wbcopy-general-parameters">

        <title>General parameters for the <literal>WbCopy</literal> command.</title>
        <informaltable frame="all">
          <tgroup cols="2"  align="left">
            <colspec colname="c1" colwidth="4cm" />
            <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>

            <tbody valign="top">
              <row>
                <entry><para>-sourceprofile</para></entry>
                <entry><para>The name of the connection profile to use as the source connection.
                If -sourceprofile is not specified, the current connection is used as the source.
                </para></entry>
              </row>
              <row>
                <entry><para>-targetprofile</para></entry>
                <entry><para>The name of the connection profile to use as the target connection. If either
                -targetprofile is not specified, the current connection is used as the target.</para></entry>
              </row>
              <row>
                <entry><para>-commitevery</para></entry>
                <entry><para>The number of rows after which a commit is send to the target database.</para></entry>
              </row>
              <row>
                <entry><para>-deletetarget=[true|false]</para></entry>
                <entry><para>If this parameter is set to true, all rows are deleted from the
                target table before copying the data.</para></entry>
              </row>
              <row>
                <entry><para>-mode</para></entry>
                <entry><para>Defines how the data should be sent to the database. Possible
                values are <literal>INSERT</literal>, <literal>UPDATE</literal>,
                <literal>INSERT,UPDATE</literal> and <literal>UPDATE,INSERT</literal>. Please
                refer to the description of the WbImport command for details on the update mode.
                </para></entry>
              </row>
              <row>
                <entry><para>-keycolumns</para></entry>
                <entry><para>Defines the key columns for the target table. This parameter
                is only necessary if import is running in <literal>UPDATE</literal> mode.
                </para></entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </section>

      <section id="wbcopy-single-table">
        <title>Copying data from a single table.</title>
        <informaltable frame="all">
          <tgroup cols="2"  align="left">
            <colspec colname="c1" colwidth="4cm" />
            <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody valign="top">
              <row>
                <entry><para>-sourcetable=&lt;tablename&gt;</para></entry>
                <entry><para>The name of the table to be copied.</para></entry>
              </row>
              <row>
                <entry><para>-sourcewhere=&lt;condition&gt;</para></entry>
                <entry><para>A <literal>WHERE</literal> condition that is applied to the source table.</para></entry>
              </row>
              <row>
                <entry><para>-targettable=&lt;tablename&gt;</para></entry>
                <entry><para>The name of the table into which the data should be written.</para></entry>
              </row>
              <row>
                <entry><para>-createtarget=[true|false]</para></entry>
                <entry><para>If this parameter is set to <literal>true</literal> the target table
                will be created, if it doesn't exist.</para></entry>
              </row>
              <row>
                <entry><para>-droptarget=[true|false]</para></entry>
                <entry><para>If this parameter is set to <literal>true</literal> the target table
                will be dropped before it is create. This parameter is ignored if -createtarget
                is <literal>false</literal></para></entry>
              </row>
              <row>
                <entry><para>-columns=[&lt;list&gt;|&lt;mapping&gt;]</para></entry>
                <entry>
                  <para>Defines the columns to be copied. If this parameter is not specified, then
                  all matching columns are copied from source to target. Matching
                  is done on name <emphasis role="bold">and</emphasis> data type.
                  </para>
                  <para>&lt;list&gt; is a list of columns in the source table. The data from
                  each table will be copied into the corresponding column in the target table.
                  If <literal>-createtarget=true</literal>, then
                  the list also defines the columns of the target table. The names have to be separated
                  by comma: <literal>-columns=firstname, lastname, zipcode</literal>
                  </para>
                  <para>
                  &lt;mapping&gt; defines a column mapping between the source and the target table
                  if the column names do no match. If <literal>-createtable=true</literal> then the
                  target table will be created from the specified target names:
                  <literal>-columns=firstname/surname, lastname/name, zipcode/zip</literal> Will copy the column
                  <literal>firstname</literal> from the source table to a column named <literal>surname</literal>
                  in the target table, and so on.
                  </para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </section>

      <section id="command-copy-query">
        <title>Copying data based on a SQL query</title>
        <informaltable frame="all">
          <tgroup cols="2"  align="left">
            <colspec colname="c1" colwidth="4cm" />
            <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry><para>-sourcequery=&lt;SELECT statement&gt;</para></entry>
                <entry><para>The SQL query to be used as the source data (instead of a table).</para></entry>
              </row>
              <row>
                <entry><para>-columns=&lt;list&gt;</para></entry>
                <entry><para>The list of columns of the target table, in the order
                in which they appear in the source table.</para></entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </section>

      <section id="copy-update-mode">
        <title>Update mode</title>
        <para>The <literal>COPY</literal> command understands the same update mode
        parameter as the <literal>WbImport</literal> command. For a discussion on
        the different update modes, please refer to the <link linkend="import-update-mode">WbImport</link>
        command.</para>
      </section>

      <section id="copy-examples">
        <title>Examples:</title>
        <para>Copy all columns from one table to another table with the same columns:</para>
        <programlisting>WbCopy -sourceprofile=ProfileA
       -targerprofile=ProfileB
       -sourcetable=the_table
       -targettable=the_other_table;</programlisting>

        <para>Copy all columns from one table to another table with the same columns, but
              only certain rows.</para>
        <programlisting>WbCopy -sourceprofile=ProfileA
       -targerprofile=ProfileB
       -sourcetable=the_table
       -sourcewhere="lastname LIKE 'D%'
       -targettable=the_other_table;</programlisting>

        <para>Copy only selected columns to a table with different column names. Before the
                    copy is started all rows are deleted from the target table:
        </para>
        <programlisting>WbCopy -sourceprofile=ProfileA
       -targerprofile=ProfileB
       -sourcetable=person
       -targettable=contact
       -deletetarget=true
       -columns=firstname/surname, lastname/name, birthday/bday;</programlisting>

       <para>If you use this way to map columns, please make sure that you
                 don't use the forward slash as the <link linkend="options-alternate-delimiter">alternate delimiter</link>.
                 This can be achieved by either specifying a different character sequence or making sure
                 that - if you use the forward slash - the current script does not end with it, as
                 this turns on the usage of the alternate delimiter. The above example would work even if
                 the forward slash was used as the alternate delimiter, because the whole command is
                 terminated with a semicolon, which disables the usage of the alternate delimiter.
       </para>

        <para>Copy data based on a SQL query, matching the columns
                    from the query to the corresponding columns from the target table:
        </para>

        <programlisting>WbCopy -sourceprofile=ProfileA
       -targerprofile=ProfileB
       -sourcequery="SELECT firstname, lastname, birthday FROM person"
       -targettable=contact
       -deletetarget=true
       -columns=surname, name, bday;</programlisting>
       <para>The order in the <literal>-columns</literal> parameter <emphasis role="bold">must</emphasis>
       match the order in the <literal>SELECT</literal> statement!</para>
     </section>

    </section>

    <section id="command-selectblob">
      <title>Extracting BLOB content - WbSelectBlob</title>
      <para>To save the contents of a <literal>BLOB</literal> or <literal>CLOB</literal> column
        into an external file the <literal>WbSelectBlob</literal> command can be used. Most DBMS
        support reading of <literal>CLOB</literal> (character data) columns directly, so depending
        on your DBMS (and JDBC driver) this command might only be needed for binary data.
      </para>
      <para>The syntax is very similar to the regular <literal>SELECT</literal> statement, an additional
        <literal>INTO</literal> keyword specifies the name of the external file into which the
        data should be written:
      </para>
      <programlisting>WbSelectBlob blob_column
INTO c:/temp/image.bmp
FROM theTable
WHERE id=42;</programlisting>
            <para>Even if you specify more then one column in the column list, &wb-productname; will only
                use the first column. If the SELECT returns more then one row, then one 
								outputfile will be created for each row. Additional files will be created with 
								a counter indicating the row number from the result. In the above
								example, image.bmp, image_1.bmp, image_3.bmp and so on, would be created.
                If you want to export addtional columns together with the BLOB contents, please
                use the <link linkend="command-export">WbExport</link> together with the XML format.
            </para>
            <note>
                You can full manipulate (save, view, upload) the contents of BLOB columns in a result set.
                Please refer to <xref linkend="blob-support"/> for details.
            </note>
    </section>


    <section id="command-schema-report">
      <title>Create a report of the database objects - WbReport</title>

      <para>Creates an XML report of selected tables. This report could be used
      to generate an HTML documentation of the database (e.g. using the <link linkend="command-xslt">XSLT</link>
      command). This report can also be generated from within the <link linkend="dbexplorer">Database Object Explorer</link>
      </para>
      <para>
        The resulting XML file can  be transformed into a HTML documentation of your database schema.
        Sample stylesheets can be downloaded from   <ulink url="http://www.sql-workbench.net/xstl.html"/>.
        If you have XSLT stylsheets that you would like to share, please send them to
        <email>support@sql-workbench.net</email>.
      </para>

      <para>Using this command you can reverse engineer an existing database. The XML file
      can then be used to generate a HTML documentation of the database or to be transformed
      into a format that is supported by your design tool.</para>
            <para>To see table and column comments with an Oracle database, you need to
            <link linkend="oracle-enable-remarks">enable remarks reporting</link> for the JDBC
            driver in order to see the comments.</para>

      <para>The command supports the following parameters:</para>

      <informaltable frame="all">
        <tgroup cols="2" align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>

          <tbody valign="top">
            <row>
              <entry><para>-file</para></entry>
              <entry><para>The filename of the output file.</para></entry>
            </row>
            <row>
                <entry><para>-tables</para></entry>
                <entry><para>A (comma separated) list of tables to report. Default is
                all tables. If this parameter is specified <literal>-schemas</literal> is ignored.
                If you want to generate the report on tables from different users/schemas you have
                to use fully qualified names in the list (e.g. <literal>-tables=MY_USER.TABLE1,OTHER_USER.TABLE2</literal>)
                You can also specify wildcards in the table name: <literal>-table=CONTRACT_%</literal> will create
                an XML report for all tables that start with <literal>CONTRACT_</literal>
                </para></entry>
            </row>
            <row>
                <entry><para>-schemas</para></entry>
                <entry><para>A (comma separated) list of schemas to generate the report from.
                For each user/schema all tables are included in the report. e.g.
                <literal>-schemas=MY_USER,OTHER_USER</literal> would generate a report
                for all tables in the schemas <literal>MY_USER</literal> and <literal>OTHER_USER</literal>.
                </para></entry>
            </row>
            <row>
                <entry><para>-namespace</para></entry>
                <entry><para>The namespace to be used for the XML tags. By default no
                namespace is used. If you supply a value for this e.g. <literal>wb</literal> the tag <literal>&lt;schema-report&gt;
                </literal> would be written as <literal>&lt;wb:schema-report&gt;</literal>
                </para></entry>
            </row>
            <row>
                <entry><para>-includetables</para></entry>
                <entry><para>Control the output of table information for the report. The default is
                          <literal>true</literal>. Valid values are <literal>true</literal>, <literal>false</literal>.
                </para></entry>
            </row>
            <row>
                <entry><para>-includeprocedures</para></entry>
                <entry><para>Control the output of stored procedure information for the report. The default is
                <literal>false</literal>. Valid values are <literal>true</literal>, <literal>false</literal>.
                </para></entry>
            </row>
            <row>
                <entry><para>-format</para></entry>
                <entry><para>The format of the outputfile. The default is the &wb-productname;
                specific XML format. Using <literal>-format=dbdesigner</literal> you can generate
                an XML file suitable to be opened with DbDesigner4
                </para></entry>
            </row>
          </tbody>
        </tgroup>
     </informaltable>
   </section>

   <section id="command-schema-diff">
    <title>Compare two database schemas - WbSchemaDiff</title>
    <para>The <literal>WbSchemaDiff</literal> analyzes two schemas (or a list of tables)
    and outputs the differences between those schemas as an XML file. The XML file
    describes the changes that need to be applied to the target schema to have
    the same structure as the reference schema, e.g. modify column definitions,
    remove or add tables, remove or add indexes.
    </para>
    <para>The output is intended to be transformed using XSLT (e.g. with the
    <link linkend="command-xslt">XSLT Command</link>).
        Sample XSLT transformations
    can be found on the <ulink url="http://www.sql-workbench.net/xslt.html">&wb-productname; homepage</ulink>
    </para>
      <para>The command supports the following parameters:</para>

      <informaltable frame="all">
				<tgroup cols="2" align="left">
					<colspec colname="c1" colwidth="4cm" />
					<colspec colname="c2" />
					<thead>
						<row>
							<entry>Parameter</entry>
							<entry>Description</entry>
						</row>
					</thead>

					<tbody valign="top">
						<row>
							<entry><para>-referenceProfile</para></entry>
							<entry><para>The name of the connection profile for the reference
							connection. If this is not specified, then the current connection is
							used.</para></entry>
						</row>
						<row>
							<entry><para>-targetProfile</para></entry>
							<entry><para>The name of the connection profile for the target
								connection (the one that needs to be migrated). If this is not
								specified, then the current connection is used.</para>
								<para>If you use the current connection for reference and target,
								then you should prefix the table names with schema/user or
								use the <literal>-referenceschema</literal> and
								<literal>-targetschema</literal> parameters.</para>
							</entry>
						</row>
						<row>
							<entry><para>-file</para></entry>
							<entry><para>The filename of the output file. If this
							is not supplied the output will be written to the message area</para></entry>
						</row>

						<row>
							<entry><para>-referenceTables</para></entry>
							<entry><para>A (comma separated) list of tables that are the reference
								tables, to be checked.
							</para></entry>
						</row>
						<row>
							<entry><para>-targetTables</para></entry>
							<entry><para>A (comma separated) list of tables in the target
								connection to be compared to the source tables. The tables
								are "matched" by their position in the list. The first table in the
								<literal>-referenceTables</literal> parameter is compared to the
								first table in the <literal>-targetTables</literal> parameter, and so
								on. Using this parameter you can compare tables that do not have the
								same name.</para>
								<para>If you omit this parameter, then all tables from the
									target connection with the same names as those listed in
									<literal>-referenceTables</literal> are compared.
								</para>
								<para>If you omit both parameters, then all tables that the
									user can access are retrieved from the source connection
									and compared to the tables with the same name in the target
									connection.
								</para>
							</entry>
						</row>
						<row>
							<entry><para>-referenceSchema</para></entry>
							<entry><para>
								Compare all tables from the specified schema (user)
							</para></entry>
						</row>
						<row>
							<entry><para>-targetSchema</para></entry>
							<entry><para>A schema in the target
								connection to be compared to the tables from the reference schema.
							</para>
							</entry>
						</row>

						<row>
							<entry><para>-namespace</para></entry>
							<entry><para>The namespace to be used for the XML tags. By default no
								namespace is used. If you supply a value for this e.g. <literal>wb</literal> the tag <literal>&lt;schema-report&gt;
								</literal> would be written as <literal>&lt;wb:modify-table&gt;</literal>
							</para></entry>
						</row>
						<row>
							<entry><para>-encoding</para></entry>
							<entry><para>The encoding to be used for the XML file. The
								default is UTF-8
							</para></entry>
						</row>
						<row>
							<entry><para>-includePrimaryKeys=[true|false]</para></entry>
							<entry><para>Select whether primary key constraint definitions should be compared as well.
								The default is to compare primary keys.
							</para></entry>
						</row>
						<row>
							<entry><para>-includeForeignKeys=[true|false]</para></entry>
							<entry><para>Select whether foreign key constraint definitions should be compared as well.
								The default is to compare foreign keys.
							</para></entry>
						</row>
						<row>
							<entry><para>-includeConstraints=[true|false]</para></entry>
							<entry><para>Select whether table and column (check) constraints
								should be compared as well. &wb-productname; compares the constraint
								definition (SQL) as stored in the database. When comparing schemas from
								different DBMS systems this will not return the desired results.</para>
								<para>The default is to not compare table constraints.</para>
							</entry>
						</row>
						<!--
						<row>
						<entry><para>-includecomments=[true|false]</para></entry>
						<entry><para>Select whether table and column comments should be compared as well.
						The default is to not compare comments. When using an Oracle database, you need
						to <link linkend="oracle-enable-remarks">enable remarks reporting</link> for the JDBC
						driver in order to use this feature.
						</para></entry>
						</row>
						-->
						<row>
							<entry><para>-includeViews=[true|false]</para></entry>
							<entry><para>Select whether views should also be compared. When comparing
								views, the source as it is stored in the DBMS is compared. This comparison
								is case-sensitiv, which means <literal>SELECT * FROM foo;</literal> will be
								reported as a difference to <literal>select * from foo;</literal> even
								if they are logically the same. A comparison across different DBMS will also not
								work properly!
							</para>
								<para>The default is to include view definitions.</para>
							</entry>
						</row>

						<row>
							<entry><para>-includeIndex=[true|false]</para></entry>
							<entry><para>Select whether indexes should be compared as well.  The default
								is to not compare index definitions.
							</para></entry>
						</row>
						
						<row>
							<entry><para>-useJdbcTypes=[true|false]</para></entry>
							<entry>
								<para>
									Define whether to compare the DBMS specific data types, or 
									the JDBC data type returned by the driver. When comparing 
									tables from two different DBMS it is recommended to use
									<literal>-useJdbcType=true</literal> as this will make the 
									comparison a bit more DBMS-independent. When comparing e.g. 
									Oracle vs. PostgreSQL character columns defined as 
									<literal>VARCHAR2(100)</literal> would be reported as beeing different
									to a <literal>VARCHAR(100)</literal> column which is not really true
									(as PostgreSQL's <literal>VARCHAR</literal> and Oracle's <literal>VARCHAR2</literal>
									are identical). Provided both drivers report the columns a java.sql.Types.VARCHAR
									they would be considered as identical when using <literal>-useJdbcType=true</literal>.
								</para>
							</entry>
						</row>
						
					</tbody>
				</tgroup>
      </informaltable>

   </section>

  <section id="command-xslt">
    <title>Run an XSLT transformation - WbXslt</title>

    <para>Transforms an XML file via a XSLT stylesheet. This can be used to format
    XML input files into the correct format for &wb-productname; or to transform
    the output files that are generated by the various &wb-productname; commands.</para>
    <para>Parameters for the XSLT command:</para>
      <informaltable frame="all">
        <tgroup cols="2"  align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>

          <tbody valign="top">
            <row>
              <entry><para>-inputfile</para></entry>
              <entry><para>The name of the XML source file.</para></entry>
            </row>
            <row>
              <entry><para>-xsltoutput</para></entry>
              <entry><para>The name of the generated output file.</para></entry>
            </row>
            <row>
              <entry><para>-stylesheet</para></entry>
              <entry><para>The name of the XSLT stylesheet to be used.</para></entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
  </section>

    <section id="command-vardef">
      <title>Define a script variable - WbVarDef</title>

      <para>This defines an internal variable which is used for variable substitution during
      SQL execution. Details can be found in the chapter <xref linkend="using-variables"/>.
      </para>
      <para>The syntax for defining a variable is: <literal>WbVarDef variable=value</literal></para>
      <para>The variable definition can also be read from a file. The file should list
      each variable definition on one line (this is the format of a normal Java properties
      file). Lines beginning with a <literal>#</literal> sign are ignored.
      The syntax is <literal>WBVARDEF -file=&lt;filename&gt;</literal>
      </para>
      <para>You can also specify a file when starting &wb-productname; with the
      parameter <literal>-vardef=&lt;filename&gt;</literal>.
      For details see see <link linkend="cmdline-vardef">Reading variables from a file</link>.
      </para>
    </section>

    <section id="command-vardelete">
      <title>Delete a script variable - WbVarDelete</title>

      <para>This removes an internal variable from the variable list.
       Details can be found in the chapter <xref linkend="using-variables"/>.
      </para>
    </section>

    <section id="command-varlist">
      <title>Show defined script variables - WbVarList</title>

      <para>This list all defined variables from the variable list.
       Details can be found in the chapter <xref linkend="using-variables"/>.
      </para>
    </section>

    <section id="command-wbinclude">
      <title>Execute a SQL script - WbInclude (@)</title>
      <para>
         With the <literal>WbInclude</literal> command you run SQL scripts without
         actually loading them into the editor, or call other scripts from within
         a script. The format of the command is <literal>WbInclude filename;</literal>.
         For DBMS other then MS SQL, the command can be abbreviated using the @ sign: <literal>@filename;</literal>
         is equivalent to <literal>WbInclude filename;</literal>.
         The script that is run in this way may also include other scripts.
      </para>
      <para>
         The reason for excluding MS SQL is, that when creating stored procedures in MS SQL, the procedure
         parameters are identified using the @ sign, thus &wb-productname; would interpret the lines
         with the variable definition as the WbInclude command. If you want to use the @ command
         with MS SQL, you can <link linkend="options-enable-shortinclude">configure</link> this in your
         <literal>workbench.settings</literal> configuration file.
      </para>
			<note>
				If the included SQL script contains <literal>SELECT</literal> queries, the result
				of those queries will <emphasis role="bold">not</emphasis> be displayed in the GUI
			</note>
      <para>The long version of the command accepts additional parameters.
        When using the long version, the filename needs to be passed as a parameter as well.
      </para>
      <para>
          Only files up to a <link linkend="options-max-script-size">certain size</link> will be read into memory. Files exceeding
          this size will be processes statement by statement. In this case the automatic
          detection of the <link linkend="alternate-delimiter-usage">alternate delimiter</link> will
          not work. If your scripts exceed the maximum size and do use the alternate delimiter
          you will have to use the "long" version so that you can specify the actual
          delimiter used in your script.
      </para>
      <para>The command supports the following parameters:</para>

      <informaltable frame="all">
        <tgroup cols="2" align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>

          <tbody valign="top">
            <row>
              <entry>-file</entry>
              <entry>The filename of the file to be included.</entry>
            </row>
            <row>
                <entry>-continueOnError</entry>
                <entry>Defines the behaviour if an error occurs in one of the statements.
                If this is set to <literal>true</literal> then script execution will continue
                even if one statement fails. If set to <literal>false</literal> script execution
                will be halted on the first error. The default value is <literal>false</literal>
                </entry>
            </row>
            <row>
                <entry>-delimiter</entry>
                <entry>Specify the delimiter that is used in the script.</entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>

      <para>Execute <literal>my_script.sql</literal></para>
      <programlisting>@my_script.sql;</programlisting>
      <para>Execute <literal>my_script.sql</literal> but abort on the first error</para>
      <programlisting>wbinclude -file="my_script.sql" -continueOnError=false;</programlisting>
    </section>

    <section id="command-define-pk">
      <title>Define primary key columns - WbDefinePK</title>
      <para>
            To be able to directly edit data in the result set (grid) &wb-productname; needs
            a primary key on the underlying table. In some cases these primary keys are not present or
            cannot be retrieved from the database (e.g. when using updateable views).
            To still be able to automatically update a result based on those tables (without always
            manually defining the primary key) you can manually define a primary
            key using the <literal>WbDefinePk</literal> command.
      </para>
      <para>
            Assuming you have an updateable view called <literal>v_person</literal> where
            the primary key is the column <literal>person_id</literal>. When you simply do a
            <literal>SELECT * FROM v_person</literal>, &wb-productname; will prompt you for the
            primary key when you try to save changes to the data. If you run
      </para>

      <programlisting>WbDefinePk v_person=person_id</programlisting>
      <para>before retrieving the result, &wb-productname; will automatically
            use the <literal>person_id</literal> as the primary key (just as if this
            information had been retrieved from the database).</para>
            <para>To delete a definition simply call the command with an empty column list:</para>
            <programlisting>WbDefinePk v_person=</programlisting>
            <para>If you want to define certain mappings permanently, this can be done using
            a mapping file that is specified in the <link linkend="options-pkmapping">configuration file</link>.
            The file specified has to be a text file with each line containing one
            primary key definition in the same format as passed to this command. The global mapping will
            automatically be saved when you exit the application if a filename has been defined.
            If no file is defined, then all PK mappings that you define are lost when
            exiting the application (unless you explicitely save them using
            <link linkend="command-save-pkmap">WbSavePkMap</link>
      </para>

      <programlisting>v_person=person_id
v_data=id1,id2</programlisting>
      <para>will define a primary key for the view <literal>v_person</literal> and one for
            the view <literal>v_data</literal>. The definitions stored in that file can
            be overwritten using the <literal>WbDefinePk</literal> command, but those changes
            won't be saved to the file. This file will be read for all database connections and
            is not profile specific. If you have conflicting primary key definitions for
            different databases, you'll need to execute the <literal>WbDefinePk</literal> command
            each time, rather then specifying the keys in the mapping file.
      </para>
      <para>
            When you define the key columns for a table through the GUI, you have the option
            to remember the defined mapping. If this option is checked, then that mapping
            will be added to the global map (just as if you had executed <literal>WbDefinePk</literal>
            manually.
      </para>
      <note>
            The mappings will be stored with lowercase table names internally, regardless on
            how you specify them.
      </note>

    </section>

    <section id="command-list-pk">
      <title>List defined primary key columns - WbListPKDef</title>
      <para>To view the currently defined primary keys, execute the command
      <literal>WbListPkDef</literal>.</para>
    </section>

    <section id="command-load-pkmap">
      <title>Load primary key mappings - WbLoadPKMap</title>
      <para>
        To load the additional primary key definitions from a file, you can
        use the the <literal>WbLoadPKMap</literal> command. If a filename is defined
        in the <link linkend="options-pkmapping">configuration file</link> then that
        file is loaded. Alternatively if no file is configured, or if you want to
        load a different file, you can specify the filename using the <literal>-file</literal>
        parameter.
      </para>
    </section>

    <section id="command-save-pkmap">
      <title>Save primary key mappings - WbSavePKMap</title>
      <para>
        To save the current primary key definitions to a file, you can
        use the the <literal>WbSavePKMap</literal> command. If a filename is defined
        in the <link linkend="options-pkmapping">configuration file</link> then the
        definition is stored in that file. Alternatively if no file is configured, or if you want to
        store the current mapping into a different file, you can specify the filename
        using the <literal>-file</literal> parameter.
      </para>
    </section>

    <section id="command-enableout" xreflabel="ENABLEOUT">
      <title>Enable Oracle's DBMS_OUTPUT package - ENABLEOUT</title>

      <para>This command enables the <literal>DBMS_OUTPUT</literal> package when connected to
      an Oracle database. On other systems this command does nothing. After
      the <literal>DBMS_OUTPUT</literal> package is enabled, any message written with
      dbms_output.put_line() are displayed in the message pane after
      executing a SQL statement. It is equivalent to calling the
      dbms_output.enable() procedure.</para>

      <para>The <literal>DBMS_OUTPUT</literal> package can be enabled automatically when a
      connection is established. See <xref linkend="options-enable-out"/></para>
    </section>

    <section id="command-disableout">
      <title>Disable Oracle's DBMS_OUTPUT package - DISABLEOUT</title>

      <para>This disables the <literal>DBMS_OUTPUT</literal> package for an Oracle database.
      This is equivalent to calling dbms_output.disable() procedure.</para>
    </section>

    <section id="command-wbfeedback">
        <title>Control feedback messages - WbFeedback</title>
        <para>
            Normally &wb-productname; prints the results for each statement
            into the message panel. As this feedback can slow down the execution
            of large scripts, you can disable the feedback using the <literal>WbFeedback</literal>
            command. When <literal>WbFeedback OFF</literal> is executed, only a summary of the
            number of executed statements will be displayed, once the script execution has
            finished. This is the same behaviour as selecting "Consolidate script log" in the
            options window. The only difference is, that the setting through <literal>WbFeedback</literal>
            is temporary and does not affect the global setting.
        </para>
    </section>

  <section id="command-desc">
    <title>Show table structure - DESCRIBE</title>

    <para>Describe shows the definition of the given table. It can be
    abbreviated with DESC. The command expects the table name as a parameter.</para>
    <programlisting>DESC person;</programlisting>
    <para>If you want to show the structure of a table from a different user, you need
    to prefix the table name with the desired user</para>
    <programlisting>DESCRIBE otheruser.person;</programlisting>
  </section>


  <section id="command-list">
    <title>List tables - WbList</title>

    <para>This command lists all available tables (including views and
      synonyms). This output is equivalent to the left part of the Database
      Object Explorer&#39;s Table tab.
    </para>
  </section>

  <section id="command-listprocs">
    <title>List stored procedures - WbListProcs</title>

    <para>This command will list all stored procedures available to the
    current user. The output of this command is equivalent to the Database
    Explorer&apos;s Procedure tab.</para>
  </section>

  <section id="command-listcat">
    <title>List catalogs - WbListCat</title>

    <para>Lists the available catalogs or databases. The output of this
    command depends on the underlying JDBC driver and DBMS. For MS SQL
    Server this lists the available databases (which then could be changed
    by USE &#60;dbname&#62;)</para>

    <para>For Oracle this command returns nothing (as Oracle does not
    implement the concept of catalogs)</para>
    <para>This command calls the JDBC driver&apos;s <literal>getCatalogs()</literal> method and will
    return its result. If on your database system this command does not display
    a list, it is most likely that your DBMS does not support catalogs (e.g. Oracle)
    or the driver does not implement this feature.
    </para>
  </section>

</section>