<section id="wb-commands">
	<title>Special &wb-productname; commands</title>

  <section id="command-export">
    <title>Export data - WbExport</title>

    <para>Exports the result of the <emphasis role="bold">next</emphasis>
        SQL statement (which has to produce a result set) to a file without
        loading the data into memory. If you want to save the data that is
        currently displayed in the result area into an external file, please
        use the <link linkend="export">Save Data as</link> feature.
    </para>
    <para>If you want to simply export the contents of one or more tables,
      the <literal>-sourcetable</literal> switch can be used to specify the
      tables. In this case no additional SELECT statement is necessary.
      You can also use the <link linkend="dbexplorer-spool">Database Explorer</link>
      to export multiple tables.
    </para>
    <para>
      You can also export the result of a <literal>SELECT</literal> statement, by
      selecting the statment in the editor, and then choose
      <menuchoice><guimenu>SQL</guimenu><guimenuitem>Export query result</guimenuitem></menuchoice>.
    </para>
		<para>
			When exporting data into a Text or XML file, the content of BLOB columns
			is written into separate files. One file for each column of each row. Text files 
			that are created this way can most probably only be imported using &wb-productname; as 
			the main file will contain the filename of the BLOB data file instead of the actual BLOB data.
			The only other application that I know of, that can handle this type of imports is Oracle's 
			<literal>SQL*Loader</literal> utility. If you run the text export together with the 
			parameter <literal>-writeoracleloader=true</literal> the control file will contain the 
			approriate definitions to read the BLOB data from the external file.
		</para>
		
    <para>The command supports the following parameters:</para>

    <informaltable frame="all">
      <tgroup cols="2" align="left">
        <colspec colname="c1" colwidth="4cm" />
        <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>

          <tbody valign="top">
              <row>
              <entry>-type</entry>

              <entry>
								<para>
									Possible values: <literal>text, sqlinsert, sqlupdate, sqldeleteinsert, xml, html</literal>
								</para>
                <para>
                  Defines the type of the output file. <literal>sqlinsert</literal>
                  will create the necessary <literal>INSERT</literal> statements to put
                  the data into a table. If the records may already exist in the target table
                  but you don't want to (or cannot) delete the content of the table
                  before running the generated script, &wb-productname; can create a DELETE
                  statement for every <literal>INSERT</literal> statement. To create this
                  kind of script, use the <literal>sqldeleteinsert</literal> type.
                </para>
                <para>
                  In order for this to work properly the table needs to have keycolumns defined,
                  or you have to define the keycolumns manually using the <literal>-keycolumns</literal>
                  switch.
                </para>
                <para>
                  <literal>sqlupdate</literal> will generate UPDATE
                  statements that update all non-key columns of the table. This will only
                  generate valid <literal>UPDATE</literal> statements if at least one key
                  column is present. If the table does not have key columns defined, or you
                  want to use different columns, they can be specified using the <literal>-keycolumns</literal>
                  switch.
                </para>
              </entry>
          </row>

          <row>
              <entry>-file</entry>
              <entry>
									Defines the name of the output file. If the file name 
									contains spaces, a dash or other special characters it has to 
									put in single quotes: <literal>-file='c:\my files\test-data.txt'</literal>
              </entry>
          </row>

          <row>
              <entry>-sourcetable</entry>
              <entry>
							<para>Defines a list of tables to be exported. If this
              switch is used, <literal>-outputdir</literal> is also required
              unless exactly one table is specified. If one table is
              specified, the -file parameter is used to generate the file
              for the table. If more then one table is specified, the
              <literal>-outputdir</literal> parameter is used to defined
              the directory where the generated files should be stored.
              Each file will be named as the exported table with the approriate
              extension (.xml, .sql, etc). You can specify * as the table
              name which will then export all tables accessible by the
              current user.
              </para>
              <para>If you want to export tables from a different user
              or schema you can use a schema name combined with a wildcard
              e.g. <literal> -sourcetable=otheruser.*</literal>. In this case
              the generated output files will contain the schema name as part of the
              filename (e.g. <literal>otheruser.person.txt</literal>).
              When <link linkend="command-import">importing</link> these files,
              &wb-productname; will try to import the tables into the schema/user
              specified in the filename. If you want to import them into
              a different user/schema, then you have to use the <literal>-schema</literal>
              switch for the <link linkend="command-import">import</link> command.
              </para>
              </entry>
          </row>
          <row>
              <entry>-outputDir</entry>
              <entry>When using the <literal>-sourcetable</literal> switch
              with multiple tables, this parameter is mandatory and defines
              the directory where the generated files should be stored.
              </entry>
          </row>
          <row>
              <entry>-continueOnError</entry>
              <entry>When exporting more than one table, this parameter controls
							whether the whole export will be terminated if an error occurs during 
							export of one of the tables.
              </entry>
          </row>
          <row>
              <entry>-encoding</entry>
              <entry>Defines the encoding in which the file should be
              written. Common encodings are ISO-8859-1, ISO-8859-15, UTF-8 (or UTF8).
              To get a list of available encodings, execut <literal>WbExport</literal>
              with the parameter <literal>-showencoding</literal>
              </entry>
          </row>
					<row>
						<entry>-showEncodings</entry>
						<entry>Displays the encodings supported by your Java version and
								operating system. If this parameter is present, all other parameters are ignored.
						</entry>
					</row>
					<row>
            <entry>-lineEnding</entry>
            <entry>
							<para>Possible values are: <literal>crlf</literal>, <literal>lf</literal></para>
							<para>
								Defines the line ending to be used for XML or text files. 
								<literal>crlf</literal> puts the ASCII characters #13 and #10 after each line. 
								This is the standard format on Windows based systems (<literal>dos</literal> and
								<literal>win</literal> are synonym values for <literal>crl</literal>).
							</para>
							<para>
								<literal>lf</literal> puts only the ASCII character #10 at the end of each line. 
								This is the standard format on Unix based systems (<literal>unix</literal> 
								is a synonym value for this format).
							</para>
							<para>
								The default line ending used depends on the platform where &wb-productname; is running.
							</para>
            </entry>
          </row>
          <row>
            <entry>-compress</entry>
            <entry>
							<para>
								Selects whether the output file should be compressed 
								and put into a ZIP archive. An archive will be created with the name of the specified outputfile
								but with the extension <literal>zip</literal>. The archive will then contain the specified file 
								(e.g. if you specify <literal>data.txt</literal>, an archive <literal>data.zip</literal>
								will be created containing exactly one entry with the name <literal>data.txt</literal>).
								If the exported result set contains BLOBs, they will be stored in a separate archive, named 
								<literal>data_lobs.zip</literal>.
							</para>
							<para>
								When exporting multiple tables using the <literal>-sourcetable</literal> parameter, 
								then &wb-productname; will create one ZIP archive for each table in the specified output 
								directory with the filename <literal>"tablename".zip</literal>. For any table containing 
								BLOB data, one additional ZIP archive is created.
							</para>
            </entry>
          </row>
					<row>
						<entry>-clobAsFile</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								For SQL, XML and Text export this controls how the contents of CLOB fields 
								are exported. Usually the CLOB content is put directly into the output file
								When generating SQL scripts with WbExport this can be a problem as not all 
								DBMS can cope with long character literals (e.g. Oracle has a limit of 
								4000 bytes). When this parameter is set to true, &wb-productname; will
								create one file for each CLOB column value. This is the same behaviour 
								as with BLOB columns.
							</para>
							<para>
								Text files that are created with this parameter set to true, will
								contain the filename of the generated output file instead of the 
								actual column value. When importing such a file using <literal>WbImport</literal>
								you have to specify the <literal>-clobIsFilename=true</literal> parameter.
								Otherwise the filenames will be stored in the database and not the clob data.
								This parameter is not necessary when importing XML exports, as <literal>WbImport</literal> will
								automatically recognize the external files.
							</para>
							<note>
								SQL scripts (<literal>-type=sqlinsert</literal>) generated with <literal>-clobAsFile=true</literal> can only be run with &wb-productname;!
							</note>
							<para>
								All CLOB files that are written using the encoding specified with the 
								<literal>-encoding</literal> switch.
								If the <literal>-encoding</literal> parameter is not specified the 
								<link linkend="default-file-encoding">default file encoding</link> will be used.
							</para>
						</entry>
					</row>
					<row>
						<entry>-lobIdCols</entry>
						<entry>
							<para>
								When exporting CLOB or BLOB columns as external files, the filename with the
								LOB content is generated using the row and column number for the currently 
								exported LOB column (e.g. data_r15_c4.data). If you prefer to have the value
								of a unique column combination as part of the file name, you can specify
								those columns using the <literal>-lobIdCols</literal> parameter. The filename
								for the LOB will then be generated using the base name of the export file, 
								the column name of the LOB column and the values of the specified columns.
								If you export your data into a file called user_info and specify <literal>-lobIdCols=id</literal> 
								and your result contains a column called <literal>img</literal>, the LOB files 
								will be named e.g. user_info_img_344.data
							</para>
						</entry>
					</row>
        </tbody>
      </tgroup>
    </informaltable>

    <section id="spool-sql-parameters">
      <title>Parameters for type SQLUPDATE, SQLINSERT or SQLDELETEINSERT</title>

      <informaltable frame="all">
        <tgroup cols="2" align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>

          <tbody valign="top">
            <row>
              <entry>-table</entry>
              <entry>
								Define the tablename to be used for the UPDATE or INSERT
								statements. This parameter is required if the SELECT statement has
								multiple tables in the FROM list.
								table.
							</entry>
            </row>

						<row>
							<entry id="export-sql-cleanup">-charfunc</entry>
							<entry>
								<para>
									If this parameter is given, any
									non-printable character in a text/character column will be
									replaced with a call to the given function with the ASCII
									value as the parameter. 
								</para> 
								<para>
									If -charfunc=chr is
									given (e.g. for an Oracle syntax), a CR (=13) inside a
								character column will be replaced with:</para>
								<para><literal>INSERT
										INTO ... VALUES (&#39;First line&#39;||chr(13)||&#39;Second
									line&#39; ... )</literal>
								</para>
								<para>This setting will affect ASCII values from 0 to 31</para>
							</entry>
						</row>
						
						<row>
							<entry>-concat</entry>
							
							<entry>
								If the parameter <literal>-charfunc</literal> is used
								&wb-productname; will concatenate the individual pieces using
								the ANSI SQL operator for string concatenation. In case
								your DBMS does not support the ANSI standard (e.g. MS ACCESS)
								you can specify the operator to be used: <literal>-concat=+</literal>
							defines the plus sign as the concatenation operator.</entry>
						</row>
						
            <row>
              <entry>-blobType</entry>

              <entry>
								<para>Possible values: <literal>file</literal>, <literal>ansi</literal>,
								<literal>dbms</literal>
								</para>
								<para>
									This parameter controls how BLOB data will be put into 
									the generated SQL statements. By default no conversion 
									will be done, so the actual value that is written 
									to the output file depends on the JDBC driver's implementation
									of the Blob interface.
								</para>
								<para>
									The parameter value <literal>file</literal>, will cause
									&wb-productname; to write the contents of each blob column
									into a separate file. The SQL statement will contain the 
									&wb-productname; specific extension to read the blob data
									from the file. For details please refer to <xref linkend="blob-support"/>.
									If you are planning to run the generated SQL scripts using 
									&wb-productname; this is the recommended format.
								</para>
								<note>
									When using <literal>-blobType=file</literal> the generated SQL script 
									can only be run with &wb-productname;!
								</note>
								<para>
									The parameter value <literal>ansi</literal>, will generate
									"binary strings" that are compatible with the ANSI 
									definition for binary data. MySQL and Microsoft SQL Server support
									these kind of literals.
								</para>
								<para>
									The parameter value <literal>dbms</literal>, will create a DBMS
									specific "binary string". For MySQL and Microsoft SQL Server this
									is the same as <literal>ansi</literal>. For HSQLDB and PostgreSQL 
									a different syntax is needed. 
								</para>
              </entry>
            </row>
            <row>
              <entry>-commitEvery</entry>
              <entry>
									<para>
										A numeric value which identifies
										the number of <literal>INSERT</literal> or <literal>UPDATE</literal> statements
										after which a <literal>COMMIT</literal> is put into the generated SQL script.
									</para>
									<para>-commitevery=100</para>
									<para>will create a <literal>COMMIT;</literal> after every 100th statement.</para>
              </entry>
            </row>

            <row>
              <entry>-createTable</entry>
              <entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									If this parameter is set to true, the necessary <literal>CREATE TABLE</literal> 
									command is put into the output file. This parameter is ignored when creating 
									<literal>UPDATE</literal> statements.
								</para>
              </entry>
            </row>

            <row>
              <entry>-keyColumns</entry>
              <entry>
								<para>
									A comma separated list of column names that occur in the table
									or result set that should be used as the key columns for <literal>UPDATE</literal> 
									or <literal>DELETE</literal>
								</para>
								<para>
									If the table does not have key columns, or the source SELECT statement uses
									a join over several tables, or you do not want to use the key columns defined
									in the database, this key can be used to define the key columns to be used
									for the UPDATE statements. This key overrides any key columns defined on the
									base table of the SELECT statement.
								</para>
              </entry>
            </row>

          </tbody>
        </tgroup>
      </informaltable>
    </section>

    <section id="spool-text-parameters">
      <title>Parameters for the type TEXT</title>

      <informaltable frame="all">
        <tgroup cols="2"  align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>

          <tbody valign="top">
            <row>
              <entry>-delimiter</entry>

              <entry>The given string sequence will be
              placed between two columns. The default is a tab character
              (<literal>-delimiter=\t</literal>
              </entry>
            </row>

            <row>
              <entry>-dateFormat</entry>

							<entry>The date <link linkend="options-date-format">format</link> to be used when
									writing date columns into the output file. 
							</entry>
						</row>

            <row>
              <entry>-dateTimeFormat</entry>

              <entry>The <link linkend="options-date-format">format</link> to be used when writing
              datetime (or timestamp) columns into the output file.
              </entry>
            </row>

            <row>
              <entry>-quoteChar</entry>

              <entry>
								<para>The character (or sequence of characters) to be used
                  to enclose text (character) data if the delimiter is
                  contained in the data. By default quoting is disabled until a quote character
                  is defined. To set the double quote as the quote character
                  you have to enclose it in single quotes: <literal>-quotechar='"'</literal>
								</para>
              </entry>
            </row>

            <row>
              <entry>-quoteAlways</entry>

              <entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									If quoting is enabled (via <literal>-quotechar</literal>,
                  then character data will only be quoted
                  if the delimiter is found inside the actual value that is
                  written to the output file. If <literal>-quoteAlways=true</literal> is
                  specified, character data will always be
                  enclosed in the specified quote character.
								</para>
              </entry>
            </row>

            <row>
              <entry>-decimal</entry>
							<entry>
								The decimal symbol to be used for numbers. The default is a dot (e.g. 3.14152)
              </entry>
            </row>

						<row>
							<entry id="text-escape-switch">-escapeText</entry>
							
							<entry>
								<para>
									This parameter controls the escaping of non-printable
									or non-ASCII characters. Valid options are <literal>ctrl</literal> which
									will escape everything below ASCII 32 (newline, tab, etc), <literal>7bit</literal>
									which will escape everything below ASCII 32 and above 126, <literal>8bit</literal>
									which will escape everything below ASCII 32 and above 255 and <literal>extended</literal>
									which will escape everything outside the range [32-126] and [161-255]
								</para>
								<para>
									This will write a unicode representation of the character into the
									text file e.g. \n for a newline, \u00F6 for &ouml;. This file
									can only be imported using &wb-productname; (at least I don't know
									of any DBMS specific loader that will decode this properly)
								</para>
							</entry>
						</row>
						
            <row>
              <entry>-header</entry>

              <entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									If this parameter is set to true, the header (i.e. the column names) are placed into the
									output file. The default is to not create a header line. You can define the default value 
									for this parameter in the file <link linkend="export-text-header-default">workbench.settings</link>.
								</para>
              </entry>
            </row>
						
						<row>
							<entry>-writeOracleLoader</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									This parameter controls the creation of Oracle SQL*Loader
									control files. If it is set to <literal>true</literal>, then &wb-productname;
									will generate a control file for each exported text file,
									that can be used to import the text file using SQL*Loader
									instead of &wb-productname;. The control file has the same
									filename as the output file but with the ending <literal>.ctl</literal>
								</para>
								<para>
									Note that the generated control file will most probably
									need some adjustments before you can actually use it. It is mainly
									meant as a template that needs further refinement.
								</para>
							</entry>
						</row>
						
          </tbody>
        </tgroup>
      </informaltable>
    </section>

    <section id="spool-xml-parameters">
      <title>Parameters for type XML</title>

      <informaltable frame="all">
        <tgroup cols="2" align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody valign="top">
            <row>
              <entry>-table</entry>
              <entry>The given tablename will be put
              into the &#60;table&#62; tag as an attribute.</entry>
            </row>

						<row>
							<entry>-dateFormat</entry>
							<entry>The date <link linkend="options-date-format">format</link> to be used when
									writing date columns into the output file. 
							</entry>
						</row>
						
            <row>
              <entry>-dateTimeFormat</entry>
              <entry>The <link linkend="options-date-format">format</link> to be used when writing
              datetime (or timestamp) columns into the output file.
              </entry>
            </row>

            <row>
              <entry>-decimal</entry>
              <entry>The decimal symbol to be used for numbers. The default is a dot (e.g. 3.14152)</entry>
            </row>
            <row>
              <entry>-useCDATA</entry>
              <entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									Normally any character data written into the xml file will
                  be processes to escape XML characters (e.g. &lt; will be written as &amp;lt;).
                  If you don't want that escaping, set <literal>-usecdata=true</literal> and
                  all character data (VARCHAR, etc) will be enclosed in a CDATA section.
								</para>
                 <para>
										With <literal>-cdata=true</literal> a HTML value would be written like this:
                 </para>
                 <para>
                  <literal>&lt;![CDATA[&lt;b&gt;This is a title&lt;/b&gt;]]&gt;</literal>
								</para>
								<para>
                  With <literal>-cdata=false</literal> (the default) a HTML value would be written like this:</para>
								<para>
                  <literal>&amp;lt;b&amp;gt;This is a title&amp;lt;/b&amp;gt;</literal>
								</para>
              </entry>
            </row>

            <row>
              <entry>-stylesheet</entry>
              <entry>The name of the XSLT stylesheet that should be used
              to transform the &wb-productname; specific XML file into a
              different format. If -stylesheet is specified, -xsltoutput has
              to be specified as well.</entry>
            </row>
            <row>
              <entry>-xsltOutput</entry>
              <entry>The resulting output file (specified
              with the -file parameter), can be transformed using XSLT after
              the export has finished. This parameter then defines
              the name of the outputfile of the transformation.</entry>
            </row>
            <row>
              <entry>-verboseXML</entry>
              <entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>This parameter controls the tags that
									are used in the XML file and minor formatting features.
									The default is -verboseXML=true and this will generate
									more readable tags and formatting. However the overhead
									imposed by this is quite high. Using -verboseXML=false
									uses shorter tag names (not longer then two characters) and
									does put more information in one line. This output is
									a harder to read for a human but is smaller in size which
									could be important for exports with large result sets.
								</para>
              </entry>
            </row>

          </tbody>
        </tgroup>
      </informaltable>

    </section>
    <section id="export-examples">
      <title>Examples</title>

<programlisting>WbExport -type=text
         -file='c:/data/data.txt'
         -delimiter='|'
         -decimal=',';
SELECT * FROM data_table;</programlisting>

    <para>Will create a text file with the data from <literal>data_table</literal>.
        Each column will be separated with the character | Each fractional number
        will be written with a comma as the decimal separator. As the
        SELECT statement retrieves all rows and columns from the table, this
        could also be written as:
    </para>

<programlisting>WbExport -type=text
         -file='c:/data/data.txt'
         -delimiter='|'
         -decimal=','
         -sourcetable=data_table;</programlisting>
    <para>There is a difference in the behaviour of the command regarding the "Max. Rows" setting
    in the GUI. When you use the <literal>WbExport</literal> command together with
    a <literal>SELECT</literal> query, the Max. Rows setting will be respected
    by the <literal>SELECT</literal> statement (and you will see a warning
    that the result set was limited). When you use the <literal>WbExport</literal>
    with the <literal>-sourcetable</literal> switch, the "Max. Rows" setting
    will not be respected, and all rows from the table will be written into
    the specified file.</para>

    <para>To generate a file that contains SQL INSERT statements that can be
      executed on the target system, the following command can be used:</para>

<programlisting>WbExport -type=sqlinsert
         -file='c:/data/newtable.sql'
         -table=newtable;
SELECT * FROM table1, table2
WHERE table1.column1 = table2.column1;</programlisting>

      <para>will create a SQL scripts which inserts the data from table1
      and table2 into a table called newtable. If the parameter -table is
      omitted, the creation of SQL INSERT statements is only possible, if the SELECT is
      based on a single table (or view).</para>
      <para>For more details on how you can export and import data using the XML format
      please refer to <xref linkend="xml-export-import"/></para>
    </section>
    <section id="export-date-formats">
      <title>Specifying date formats</title>
      <para>The date/time format that can be specified with the <literal>-dateformat</literal>
      or <literal>-timestampformat</literal> accepts fhe following format codes. These
      are the format codes for Java's <ulink url="http://java.sun.com/j2se/1.4.2/docs/api/java/text/SimpleDateFormat.html">SimpleDateFormat</ulink>
      class.
      </para>
    </section>

</section>

  <section id="command-import">
		<title>Import data - WbImport</title>
		<para>The WbImport command can be used to import data from text or
			XML files into a table in the database. WbImport can read the XML files generated by the
			<link linkend="command-export">WbExport</link> command&apos;s XML format. It can
			also read text files created by the WbExport command that escape non-printable
			characters.
		</para>
		<para>During the import of text files, empty lines (i.e. lines which only
			contain whitespace) will be silently ignored. The text import does not support records
			spanning multiple lines in the input file. If the input file is created using
			WbExport then it is recommended to use the <literal>-escapetext</literal> switch
			to escape non-printable characters which could break text import.
		</para>
		<para>The <link linkend="data-pumper">DataPumper</link> can also be used to import text files
			into a database table, though it does not offer all of the possibilities as the
			<literal>WbImport</literal> command.
		</para>
		<para>
			Archives created with the <literal>WbExport</literal> command using the 
			<literal>-compress=true</literal> parameter can be imported using <literal>WbImport</literal>
			command. You simply need to specifiy the archive file created by <literal>WbExport</literal>, and 
			<literal>WbImport</literal> will automatically detect the archive. For an example on creating 
			and importing compressed exports, please refer to <link linkend="export-compress">compressing export files</link>
		</para>
		
		<para>The WbImport command has the following syntax</para>
		<informaltable frame="all">
			<tgroup cols="2" align="left">
				<colspec colname="c1" colwidth="4cm" />
				<colspec colname="c2"/>
				<thead>
					<row>
						<entry>Parameter</entry>
						<entry>Description</entry>
					</row>
				</thead>
				<tbody valign="top">
					<row>
						<entry>-type</entry>
						<entry>
							<para>Possible values: <literal>xml</literal>, <literal>text</literal></para>
							<para>Defines the type of the input file</para>
						</entry>
					</row>
					<row>
						<entry>-file</entry>
						<entry>
							<para>
								Defines the full name of the input file. Alternatively
								you can also specify a directory (using <literal>-sourcedir</literal>)
								from which all xml files are imported
							</para>
						</entry>
					</row>
					<row>
						<entry>-sourcedir</entry>
						<entry>
							<para>
								Defines a directory which contains import files. All
								files from that directory will be imported. If this switch is used
								with text files, then it is assumed that each filename (without the extension)
								defines the target table.
							</para>
						</entry>
					</row>
					<row>
						<entry>-extension</entry>
						<entry>
							<para>
								When using the <literal>-sourcedir</literal> switch, the
								extension for the files can be defined. All files ending with the supplied
								value will be processed. (e.g. <literal>-extension=csv</literal>).
								The extension given is case-sensitiv (i.e. <literal>TXT</literal> is something
								different than <literal>txt</literal>
							</para>
						</entry>
					</row>
					<row>
						<entry>-commitEvery</entry>
						<entry>
							<para>
                A numeric value that defines the number of rows after which a <literal>COMMIT</literal>
								is sent to the DBMS. If this parameter is not passed (or a value of zero or lower), 
								then &wb-productname; will commit when all rows have been imported. When using batch execution 
								it is recommended to commit the batch using the <literal>-commitBatch</literal> parameter.
							</para>
						</entry>
					</row>
					<row>
						<entry>-mode</entry>
						<entry>
								<para>Defines how the data should be sent to the database. Possible
								values are '<literal>INSERT</literal>', '<literal>UPDATE</literal>',
								'<literal>INSERT,UPDATE</literal>' and '<literal>UPDATE,INSERT</literal>'
								For details please refer to the <link linkend="import-update-mode">update mode</link>
								explanation.
							</para>
						</entry>
					</row>
					<row>
						<entry>-continueOnError</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>This parameter controls the behaviour when errors occur during
								the import. The default is <literal>true</literal>, meaning that the import
								will continue even if an error occurs during file parsing or updating the database.
								Set this parameter to <literal>false</literal> if you want to stop the import as soon as an error occurs.
						</para>
						<para>
							The default value for this parameter can be controlled in the <link linkend="import-continue-default">settings file</link>
							and it will be displayed if you run <literal>WbImport</literal> without any parameters.
						</para>
						</entry>
					</row>
					<row>
						<entry>-keyColumns</entry>
						<entry>
							<para>
								Defines the key columns for the target table. This parameter
								is only necessary if import is running in <literal>UPDATE</literal> mode.
							</para>
							<para>
								This parameter is ignored if files are imported using the <literal>-sourcedir</literal>
								parameter
							</para>
						</entry>
					</row>
					
					<row>
						<entry>-table</entry>
						<entry>
							<para>Defines the table into which the data should be imported</para>
							<para>
								This parameter is ignored, if the files are imported using the
								<literal>-sourcedir</literal> parameter
							</para>
						</entry>
					</row>
					
					<row>
						<entry>-schema</entry>
						<entry>
							Defines the schema into which the data should be imported. This
							is necessary for DBMS that support schemas, and you want to import
							the data into a different schema, then the current one.
						</entry>
					</row>
					
					<row>
						<entry>-encoding</entry>
						<entry>Defines the encoding of the input file (and possible CLOB files)</entry>
					</row>
					
					<row>
						<entry>-deleteTarget</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								If this parameter is set to true, data from the target table will
								be deleted (using <literal>DELETE FROM ...</literal>) before the import is started.
							</para>
						</entry>
					</row>

					<row>
						<entry>-truncateTable</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								This is essentially the same as <literal>-deleteTarget</literal>, but will 
								use the command <literal>TRUNCATE</literal> to delete the contents of the 
								table. For those DBMS that support this command, deleting rows 
								is usually faster compared to the <literal>DELETE</literal> command, but
								it cannot be rolled back.
							</para>
						</entry>
					</row>
					
					<row>
						<entry>-batchSize</entry>
						<entry>
							<para>
								A numeric value that defines the size of the batch queue. 
								Any value greater than 1 will enable batch mode. If the
								JDBC driver supports this, the INSERT (or UPDATE) performance can be increased
								drastically.
							</para>
							<para>
								This parameter will be ignored if the driver does not support batch updates or if
								the mode is not <literal>UPDATE</literal> or <literal>INSERT</literal> 
								(i.e. if <literal>-mode=update,insert</literal> or <literal>-mode=insert,update</literal> is used).
							</para>
						</entry>
					</row>
					
					<row>
						<entry>-commitBatch</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								If using batch execution (by specifying a batch size using the <literal>-batchSize</literal>
								parameter) each batch will be committed when this parameter is set to <literal>true</literal>.
								This is slightly different to using <literal>-commitEvery</literal> with the value of the 
								<literal>-batchSize</literal> parameter. The latter one will add a COMMIT statement to 
								the batch queue, rather than calling the JDBC commit() method. Some drivers 
								do not allow to add different statements in a batch queue. So, if a frequent 
								<literal>COMMIT</literal> is needed, this parameter should be used.
							</para>
							<para>
								When you specify <literal>-commitBatch</literal> the parameter 
								<literal>-commitEvery</literal> will be ignored. If no batch size 
								is given, then <literal>-commitBatch</literal> will be ignored.
							</para>
						</entry>
					</row>
					
					<row>
						<entry>-updateWhere</entry>
						<entry>
							<para>
								When using <link linkend="import-update-mode">update mode</link>
								an additional <literal>WHERE</literal> clause can be specified to limit
								the rows that are updated. The value of the <literal>-updatewhere</literal>
								parameter will be added to the generated <literal>UPDATE</literal> statement.
								If the value starts with the keyword <literal>AND</literal> or <literal>OR</literal>
								the value will be added without further changes, otherwise the value
								will be added as an <literal>AND</literal> clause enclosed in brackets.
								This parameter will be ignored if update mode is not active.
							</para>
						</entry>
					</row>
					
					<row>
						<entry>-startRow</entry>
						<entry>
							A numeric value to define the first row to be imported. Any row before the
							specified row will be ignored. The header row is not counted 
							to determine the row number. For a text file with a header 
							row, the pysical line 2 is row 1 (one) for this parameter.
						</entry>
					</row>
					
					<row>
						<entry>-endRow</entry>
						<entry>
							A numeric value to define the last row to be imported. The import
							will be stopped after this row has been imported. When you 
							specify <literal>-startRow=10</literal> and <literal>-endRow=20</literal>
							11 rows will be imported (i.e. rows 10 to 20). If this is a text file
							import with a header row, this would correspond to the physical lines
							11 to 21 in the input file as the header row is not counted.
						</entry>
					</row>
					
				</tbody>
			</tgroup>
		</informaltable>
		
		<section id="import-text-parameters">
      <title>Parameters for the type TEXT</title>

			<informaltable frame="all">
				<tgroup cols="2"  align="left">
					<colspec colname="c1" colwidth="4cm" />
					<colspec colname="c2" />
					<thead>
						<row>
							<entry>Parameter</entry>
							<entry>Description</entry>
						</row>
					</thead>
					
					<tbody valign="top">
						
						<row>
							<entry>-fileColumns</entry>
							<entry>
								<para>
									A comma separated list of the table columns in the import file
									Each column from the file should be listed with the approriate column
									name from the target table. This parameter also defines
									the order in which those columns appear in the file.
									If the file does not contain a header line or the header line does not
									contain the names of the columns in the database (or has different names),
									this parameter has to be supplied. If a column from the input
									file has no match in the target table, then it should be specified with
									the name $wb_skip$. You can also specify the $wb_skip$ flag for
									columns which are present but that you want to exclude from the
									import.
								</para>
								<para>
									This parameter is ignored when the <literal>-sourcedir</literal>
									parameter is used.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-importColumns</entry>
							<entry>
								<para>
									Defines the columns that should be imported. If all
									columns from the input file should be imported (the default), then
									this parameter can be ommited. If only certain columns should be
									imported then the list of columns can be specified here. The column
									names should match the names provided with the -filecolumns switch.
									The same result can be achieved by providing the columns
									that should be excluded as <literal>$wb_skip$</literal> columns
									in the <literal>-filecolumns</literal> switch. Which one you choose
									is mainly a matter of taste. Listing all columns and excluding
									some using <literal>-importcolumns</literal> might be more readable
									because the structure of the file is still "visible" in the
									<literal>-filecolumns</literal> switch.
								</para>
								<para>
									This parameter is ignored when the <literal>-sourcedir</literal>
									parameter is used.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-delimiter</entry>
							<entry>
								<para>
									Define the character which separates columns in one line. Records are always
									separated by newlines (either CR/LF or only a LF character).
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-dateFormat</entry>
							<entry>
								<para>The <link linkend="options-date-format">format</link> for date columns.</para>
							</entry>
						</row>
						
						<row>
							<entry>-timestampFormat</entry>
							<entry>
								<para>
									The <link linkend="options-date-format">format</link> for datetime (or timestamp) columns in the input file.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-quoteChar</entry>
							<entry>
								<para>
									The character which was used to quote values where the delimiter is contained.
									This parameter has no default value. Thus if this is not specified, no quote checking 
									will take place. If you use <literal>-multiLine=true</literal> you <emphasis role="bold">have</emphasis>
									to specify a quote character in order for this to work properly.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-multiLine</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									Enable support for records spanning more than one line in the input file. 
									These records have to be quoted, otherwise they will
									not be recognized.
								</para>
								<para>
									If you create your exports with the <link linkend="command-export">WbExport</link> command, 
									it is recommended to encode special characters using the <literal>-escapetext</literal>
									switch rather then using multi-line records.
								</para>
								<para>The default value for this parameter can be controlled
									in the <link linkend="import-text-multiline">settings file</link> 
									and it will be displayed if you run <literal>WbImport</literal> without any parameters.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-decimal</entry>
							<entry>The decimal symbol to be used for numbers. The default is a dot</entry>
						</row>
						
						<row>
							<entry>-header</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									If set to true, indicates that the file contains a header
									line with the column names for the target table. This will also ignore
									the data from the first line of the file. If the column names
									to be imported are defined using the <literal>-filecolumns</literal> 
									or the <literal>-importcolumns</literal> switch,
									this parameter has to be set to true nevertheless, otherwise the first row
									would be treated as a regular data row.
								</para>
								<para>
									This parameter is always set to true when the <literal>-sourcedir</literal>
									parameter is used.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-decode</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									This controls the decoding of escaped characters. If the
									export file was e.g. written with <link linkend="text-escape-switch">escaping enabled</link>
									then you need to set <literal>-decode=true</literal> in order to interpret string sequences
									like \t, \n or escaped Unicode characters properly. This is not enabled by default
									because applying the necessary checks has an impact on the performance.
								</para>
							</entry>
						</row>
						<row>
							<entry>-columnFilter</entry>
							<entry>
								<para>
									This defines a filter on column level that selects only certain rows
									from the input file to be sent to the database. The filter has to be
									define <literal>as column1="regex",column2="regex"</literal>
								</para>
								<para>If more then one column is listed, then all expressions must match
									in order for the input row to be processed. The expressions to be applied to
									the input value are regular expressions.
								</para>
								<para>
									This parameter is ignored when the <literal>-sourcedir</literal>
									parameter is used.
								</para>
							</entry>
						</row>
						<row>
							<entry>-lineFilter</entry>
							<entry>
								<para>
									To define a filter on the level of the input row (rather than
									for each column individually) you can define a regular expression
									that is applied to the whole input row. As the regular expressioin
									will be applied to the row as it is retrieved from the input file, 
									the column delimiter(s) have to be taken into account when defining 
									the regular expression.
								</para>
							</entry>
						</row>
						<row>
							<entry>-emptyStringIsNull</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									Controls whether input values for character type columns 
									with a length of zero are treated as <literal>NULL</literal> (value <literal>true</literal>)
									or as an empty string. 
								</para>
								<para>
									Note that, input values for non character columns (such as numbers or date columns) that are 
									empty or consist only of whitespace will always be treated as <literal>NULL</literal>.
								</para>
							</entry>
						</row>
						<row>
							<entry>-blobIsFilename</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									When exporting tables that have BLOB columns using <link linkend="command-export">WbExport</link>
									into text files, each BLOB will be written into a separate file. The actual column 
									data of the text file will contain the file name of the external file. 
									When importing text files that do not reference external files
									into tables with BLOB columns setting this paramter to false, will send the content 
									of the BLOB column "as is" to the DBMS. This will of course only work
									if the JDBC driver can handle the data that in the BLOB columns of the 
									text file. The default for this parameter is <literal>true</literal>
								</para>
							</entry>
						</row>

						<row>
							<entry>-clobIsFilename</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									When exporting tables that have CLOB columns using <link linkend="command-export">WbExport</link>
									and the parameter <literal>-clobAsFile=true</literal> the generated text file
									will not contain the actual CLOB contents, but the a filename indicating the 
									file in which the CLOB content is stored. 
									In this case <literal>-clobIsFilename=true</literal> has to be specified in 
									order to read the CLOB contents from the external files. The CLOB files
									will be read using the encoding specified with the <literal>-encoding</literal>
									parameter.
								</para>
							</entry>
						</row>
						
					</tbody>
				</tgroup>
			</informaltable>
			
     <para>Examples:</para>
      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,birthday
         -dateformat="yyyy-MM-dd";</programlisting>

		 <para>
			 This imports a file with three columns into a table named person. The
			 first column in the file is <literal>lastname</literal>, the second column
			 is <literal>firstname</literal> and the third column is <literal>birhtday</literal>.
			 Values in date columns are formated as yyyy-MM-dd
		 </para>

      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,$wb_skip$,birthday
         -dateformat="yyyy-MM-dd";</programlisting>

			 <para>
				 This will import a file with four columns. The third column in the file
				 does not have a corresponding column in the table <literal>person</literal>
				 so its specified as <literal>$wb_skip$</literal> and will not be imported.
			 </para>
				 
      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,phone,birthday
         -importcolumns=lastname,firstname;</programlisting>

			 <para>
				 This will import a file with four columns where all columns
				 exist in the target table. Only <literal>lastname</literal> and
				 <literal>firstname</literal> will be imported. The same effect could
				 be achieved by specifying $wb_skip$ for the last two columns and leaving
				 out the -importcolumns switch. Using -importcolumns is a bit more readable
				 because you can still see the structure of the input file. The
				 version with <literal>$wb_skip$</literal> is mandatory if the input file
				 contains columns that do not exist in the target table.
			 </para>

			<para>If you want to import certain rows from the input file, you can
			 use regular expressions:
			</para>
			 
			<programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,birthday
         -columnfilter=lastname="^Bee.*",firstname="^Za.*"
         -dateformat="yyyy-MM-dd";</programlisting>
				 
			<para>
				The above statement will import only rows where the column <literal>lastname</literal>
				contains values that start with <literal>Bee</literal> and the column <literal>firstname</literal>
				contains values that start with <literal>Za</literal>. So <literal>Zaphod Beeblebrox</literal>
				would be imported, <literal>Arthur Beeblebrox</literal> would not be imported.
			</para>
				 
			<para>
				If you want to learn more about regular expressions, please have a look
				at <ulink url="http://www.regular-expressions.info/"/>
			</para>
		 
			<para>
				If you want to limit the rows that are updated but cannot filter them
				from the input file using <literal>-columnfilter</literal> or <literal>-linefilter</literal>,
				use the <literal>-updatewhere</literal> parameter:
			</para>
			
      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=id,lastname,firstname,birthday
         -keycolumns=id
         -mode=update
         -updatewhere="source &lt;&gt; 'manual'"</programlisting>
				 
			<para>
				This will update the table <literal>PERSON</literal>. The generated <literal>UPDATE</literal>
				statement would normally be: <literal>UPDATE person SET lastname=?, firstname=?, birthday=? WHERE id=?</literal>.
				The table contains entries that are maintained manually (identified by the value 'manual' in
				the column <literal>source</literal>) and should not be updated by &wb-productname;. By specifying
				the <literal>-updatewhere</literal> parameter, the above <literal>UPDATE</literal> statement will
				be extended to <literal>WHERE id=? AND (source &lt;&gt; 'manual')</literal>. Thus skipping
				records that are flagged as manual even if they are contained in the input file.
			</para>
			<note>
				When importing data into integer columns, the values '<literal>false</literal>' and '<literal>true</literal>'
				will silently be converted to 0 (numeric zero) and 1 (one) during an import. This is necessary
				when importing files created from a database system that supports the boolean datatype (e.g. PostgreSQL) 
				into a database system where you have to use a numeric datatype for these columns (e.g. Oracle).
			</note>
		</section>

		<section id="import-xml-parameters">
			<title>Parameters for the type XML</title>

			<para>
				The XML import only works with files generated by the <link linkend="command-export">WbExport</link>
				command.
			</para>
				
        <informaltable frame="all">
          <tgroup cols="2"  align="left">
            <colspec colname="c1" colwidth="4cm" />
            <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody valign="top">
						
              <row>
                <entry>-verboseXML</entry>
                <entry>
									<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
									<para>
										If the XML was generated with <literal>-verboseXML=false</literal>
										then this needs to be specified also when importing the file.
										Beginning with build 78, the &wb-productname; writes the information
										about the used tags into the meta information. So it is no
										longer necessary to specify whether -verboseXML was true when
										creating the XML file.
									</para>
                </entry>
              </row>
							
              <row>
                <entry>-sourceDir</entry>
                <entry>
									<para>Specify a director which contains the XML files.
										All files in that directory ending with ".xml"
										(lowercase!) will be processed.
										The table into which the data is imported is read
										from the XML file, also the columns to be imported. The parameters
										<literal>-keycolumns</literal>, <literal>-table</literal> and
										<literal>-file</literal> are ignored if this parameter is specified.
										If XML files are used that are generated with a version prior to
										build 78, then all files need to use either the long or short
										tag format and the <literal>-verboseXML=false</literal> parameter has
										to be specified if the short format was used.
									</para>
									<para>
										When importing several files at once, the files will be
										imported into the tables specified in the XML files. You cannot
										specify a different table (apart from editing the XML file
										before starting the import).
									</para>
                </entry>
              </row>
							
							<row>
								<entry>-importColumns</entry>
								<entry>
									<para>
										Defines the columns that should be imported. If all
										columns from the input file should be imported (the default), then
										this parameter can be ommited. When specified, the columns have to match
										the column names available in the XML file.
									</para>
								</entry>
							</row>
							
						</tbody>
          </tgroup>
        </informaltable>
    </section>

    <section id="import-update-mode">
      <title>Update mode</title>
      <para>The <literal>-mode</literal> parameter controls the way the data is sent
        to the database. The default is <literal>INSERT</literal>. &wb-productname; will
        generate an <literal>INSERT</literal> statement for each record. If the <literal>INSERT</literal>
        fails no further processing takes place for that record.
      </para>
      <para>If <literal>-mode</literal> is set to <literal>UPDATE</literal>, &wb-productname; will
        generate an <literal>UPDATE</literal> statement for each row. In order for this to work,
        the table needs to have a primary key defined, and all columns of the primary key need to
        be present in the import file. Otherwise the generated <literal>UPDATE</literal> statement
        will modify rows that should not be modified. This can be used to update existing
        data in the database based on the data from the export file.
      </para>
      <para>To either update or insert data into the table, both keywords can be specified
        for the <literal>-mode</literal> parameter. The order in which they appear as the parameter
        value, defines the order in which the respective statements are sent to the database. If the first
        statement fails, the second will be executed. For <literal>-mode=insert,update</literal> to
        work properly a primary or unique key has to be defined on the table. &wb-productname;
        will catch any exception (=error) when inserting a record, then it will try updating
        the record, based on the specified keycolumns.
        The <literal>-mode=update,insert</literal> works the other way. First &wb-productname;
        will try to update the record based on the primary keys. If the DBMS signals that no rows
        have been updated, it is assumed that the row does not exist and the record will be inserted
        into the table. This mode is recommended when no primary or unique key is defined on the table,
        and an <literal>INSERT</literal> would always succeed.
      </para>
      <para>The keycolumns defined with the <literal>-keycolumns</literal> parameter don't
      have to match the real primary key, but they should identify one row uniquely.
      </para>
     <para>You cannot use the update mode, if you select <emphasis role="bold">only</emphasis> key columns.
     The values from the source are used to build up the <literal>WHERE</literal> clause for the
     <literal>UPDATE</literal> statement. If ony key columns are defined, then there would be nothing to
     update.
      </para>

      <para>
        For maximum performance, choose the update strategy that will result in a succssful
        first statement more often. As a rule of thumb:
        <itemizedlist>
          <listitem>Use <literal>-mode=insert,update</literal>, if you expect more rows to be inserted then updated.</listitem>
          <listitem>Use <literal>-mode=update,insert</literal>, if you expect more rows to be updated then inserted.</listitem>
        </itemizedlist>
      </para>
    </section>

  </section>

    <section id="command-copy">
      <title>Copy one database to another - WbCopy</title>

		<para>
			The <literal>WbCopy</literal> is essentially the command line version of the
			the <link linkend="data-pumper">DataPumper</link>. For a more detailed explanation
			of the copy process, please refer to that section. It bascially chains a WbExport and a
			<literal>WbImport</literal> statement without the need of an intermediate data file.
			The <literal>WbCopy</literal> command requires that a connection to the source and target
			database can be made at the same time.
		</para>

      <section id="wbcopy-general-parameters">

        <title>General parameters for the <literal>WbCopy</literal> command.</title>
        <informaltable frame="all">
          <tgroup cols="2"  align="left">
            <colspec colname="c1" colwidth="4cm" />
            <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>

            <tbody valign="top">
              <row>
                <entry>-sourceProfile</entry>
                <entry>
									<para>
										The name of the connection profile to use as the source connection.
										If -sourceprofile is not specified, the current connection is used as the source.
									</para>
									<para>
										If the profile name contains spaces or dashes, it has to be quoted.
									</para>
                </entry>
              </row>
							
              <row>
                <entry>-sourceGroup</entry>
                <entry>
									<para>
										If the name of your source profile is not unique across 
										all profiles, you will need to specify the group in which the profile 
										is located with this parameter.
									</para>
									<para>
										If the group name contains spaces or dashes, it has to be quoted.
									</para>
                </entry>
              </row>
							
              <row>
                <entry>-targetProfile</entry>
                <entry>
									<para>
										The name of the connection profile to use as the target connection. If
										<literal>-targetprofile</literal> is not specified, the current connection is used as the target.
									</para>
									<para>
										If the profile name contains spaces or dashes, it has to be quoted.
									</para>
                </entry>
              </row>
							
              <row>
                <entry>-targetGroup</entry>
                <entry>
									<para>
										If the name of your target profile is not unique across 
										all profiles, you will need to specify the group in which the profile 
										is located with this parameter.
									</para>
									<para>
										If the group name contains spaces or dashes, it has to be quoted.
									</para>
                </entry>
              </row>
							
              <row>
                <entry>-commitEvery</entry>
                <entry>
									The number of rows after which a commit is sent to the target database. This parameter
									is ignored if JDBC batching (<literal>-batchSize</literal>) is used.
								</entry>
              </row>
							
              <row>
                <entry>-deleteTarget</entry>
                <entry>
									<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
									<para>
										If this parameter is set to true, all rows are deleted from the
										target table before copying the data.
									</para>
                </entry>
              </row>
							
              <row>
                <entry>-mode</entry>
                <entry>
									<para>
										Defines how the data should be sent to the database. Possible
										values are <literal>INSERT</literal>, <literal>UPDATE</literal>,
										'<literal>INSERT,UPDATE</literal>' and '<literal>UPDATE,INSERT</literal>'. Please
										refer to the description of the <link linkend="command-import">WbImport</link> 
										command for details on.
									</para>
                </entry>
              </row>
							
              <row>
                <entry>-keyColumns</entry>
                <entry>
									<para>
										Defines the key columns for the target table. This parameter
										is only necessary if import is running in <literal>UPDATE</literal> mode.
									</para>
                </entry>
              </row>
							
							<row>
								<entry>-batchSize</entry>
								<entry>
									<para>
										Enable the use of the JDBC batch update feature, by setting the size
										of the batch queue. Any value greater than 1 will enable batch modee. If the
										JDBC driver supports this, the INSERT (or UPDATE) performance can be increased.
									</para>
									<para>
										This parameter will be ignored if the driver does not support batch updates or if
										the mode is not UPDATE or INSERT (i.e. if <literal>-mode=update,insert</literal>
										or <literal>-mode=insert,update</literal> is used).
									</para>
								</entry>
							</row>
							
							<row>
								<entry>-commitBatch</entry>
								<entry>
									<para>Valid values: <literal>true</literal>, <literal>false</literal></para>
									<para>When using the <literal>-batchSiez</literal> parameter, the 
										<literal>-commitEvery</literal> is ignored (as not all JDBC drivers
										support a <literal>COMMIT</literal> inside a JDBC batch operation. When 
										using <literal>-commitBatch=true</literal> &wb-productname; will send a 
										<literal>COMMIT</literal> to the database server after each JDBC 
										batch is sent to the server.
									</para>
								</entry>
							</row>
							
							<row>
								<entry>-continueOnError</entry>
								<entry>
									<para>
										Defines the behaviour if an error occurs in one of the statements.
										If this is set to <literal>true</literal> the copy process will continue
										even if one statement fails. If set to <literal>false</literal> the copy process
										will be halted on the first error. The default value is <literal>false</literal>.
									</para>
									<para>
										Note that for some DBMS <literal>continueOnError</literal> will not work. PostgreSQL
										will not execute any further commands if the current transactions had an error. 
									</para>
								</entry>
							</row>
							
            </tbody>
          </tgroup>
        </informaltable>
      </section>

      <section id="wbcopy-single-table">
        <title>Copying data from a single table.</title>
        <informaltable frame="all">
          <tgroup cols="2"  align="left">
            <colspec colname="c1" colwidth="4cm" />
            <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody valign="top">
              <row>
                <entry>-sourceTable</entry>
                <entry>The name of the table to be copied.</entry>
              </row>
              <row>
                <entry>-sourceWhere</entry>
                <entry>A <literal>WHERE</literal> condition that is applied to the source table.</entry>
              </row>
              <row>
                <entry>-targetTable</entry>
                <entry>The name of the table into which the data should be written.</entry>
              </row>
              <row>
                <entry>-createTarget</entry>
                <entry>If this parameter is set to <literal>true</literal> the target table
                will be created, if it doesn't exist. 
								Valid values are <literal>true</literal> or <literal>false</literal>.
                </entry>
              </row>
              <row>
                <entry>-dropTarget</entry>
                <entry>If this parameter is set to <literal>true</literal> the target table
                will be dropped before it is create. This parameter is ignored if <literal>-createtarget=true</literal>
								is specified.
                </entry>
              </row>
              <row>
                <entry>-columns</entry>
                <entry>
                  <para>Defines the columns to be copied. If this parameter is not specified, then
                  all matching columns are copied from source to target. Matching
                  is done on name <emphasis role="bold">and</emphasis> data type. You
									can either specify a list of columns or a column mapping.
                  </para>
                  <para>When supplying a list of columns, the data from
                  each column in the source table will be copied into the corresponding (i.e. one
									with the same name) column in the target table.
                  If <literal>-createtarget=true</literal>, then
                  the list also defines the columns of the target table. The names have to be separated
                  by comma: <literal>-columns=firstname, lastname, zipcode</literal>
                  </para>
                  <para>
                  A column mapping defines which column from the source table maps to which column
									of the target table (if the column names do not match)
									If <literal>-createtable=true</literal> then the
                  target table will be created from the specified target names:
                  <literal>-columns=firstname/surname, lastname/name, zipcode/zip</literal> Will copy the column
                  <literal>firstname</literal> from the source table to a column named <literal>surname</literal>
                  in the target table, and so on.
                  </para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </section>

      <section id="command-copy-query">
        <title>Copying data based on a SQL query</title>
        <informaltable frame="all">
          <tgroup cols="2"  align="left">
            <colspec colname="c1" colwidth="4cm" />
            <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>-sourcequery</entry>
                <entry>The SQL query to be used as the source data (instead of a table).</entry>
              </row>
              <row>
                <entry>-columns</entry>
                <entry>The list of columns of the target table, in the order
                in which they appear in the source table.</entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </section>

      <section id="copy-update-mode">
        <title>Update mode</title>
        <para>The <literal>WbCopy</literal> command understands the same update mode
        parameter as the <literal>WbImport</literal> command. For a discussion on
        the different update modes, please refer to the <link linkend="import-update-mode">WbImport</link>
        command.</para>
      </section>

      <section id="copy-examples">
        <title>Examples:</title>
        <para>Copy all columns from one table to another table with the same columns:</para>
        <programlisting>WbCopy -sourceprofile=ProfileA
       -targerprofile=ProfileB
       -sourcetable=the_table
       -targettable=the_other_table;</programlisting>

        <para>Copy all columns from one table to another table with the same columns, but
              only certain rows.</para>
        <programlisting>WbCopy -sourceprofile=ProfileA
       -targerprofile=ProfileB
       -sourcetable=the_table
       -sourcewhere="lastname LIKE 'D%'
       -targettable=the_other_table;</programlisting>

        <para>
					Copy only selected columns to a table with different column names. Before the
					copy is started all rows are deleted from the target table:
        </para>
        <programlisting>WbCopy -sourceprofile=ProfileA
       -targerprofile=ProfileB
       -sourcetable=person
       -targettable=contact
       -deletetarget=true
       -columns=firstname/surname, lastname/name, birthday/bday;</programlisting>

       <para>
				 If you use this way to map columns, please make sure that you
				 don't use the forward slash as the <link linkend="options-alternate-delimiter">alternate delimiter</link>.
				 This can be achieved by either specifying a different character sequence or making sure
				 that - if you use the forward slash - the current script does not end with it, as
				 this turns on the usage of the alternate delimiter. The above example would work even if
				 the forward slash was used as the alternate delimiter, because the whole command is
				 terminated with a semicolon, which disables the usage of the alternate delimiter.
       </para>

        <para>
					Copy data based on a SQL query, matching the columns
					from the query to the corresponding columns from the target table:
        </para>

        <programlisting>WbCopy -sourceprofile=ProfileA
       -targerprofile=ProfileB
       -sourcequery="SELECT firstname, lastname, birthday FROM person"
       -targettable=contact
       -deletetarget=true
       -columns=surname, name, bday;</programlisting>
       <para>The order in the <literal>-columns</literal> parameter <emphasis role="bold">must</emphasis>
       match the order in the <literal>SELECT</literal> statement!</para>
     </section>

    </section>

    <section id="command-selectblob">
      <title>Extracting BLOB content - WbSelectBlob</title>
      <para>To save the contents of a <literal>BLOB</literal> or <literal>CLOB</literal> column
        into an external file the <literal>WbSelectBlob</literal> command can be used. Most DBMS
        support reading of <literal>CLOB</literal> (character data) columns directly, so depending
        on your DBMS (and JDBC driver) this command might only be needed for binary data.
      </para>
      <para>The syntax is very similar to the regular <literal>SELECT</literal> statement, an additional
        <literal>INTO</literal> keyword specifies the name of the external file into which the
        data should be written:
      </para>
      <programlisting>WbSelectBlob blob_column
INTO c:/temp/image.bmp
FROM theTable
WHERE id=42;</programlisting>
            <para>Even if you specify more then one column in the column list, &wb-productname; will only
                use the first column. If the SELECT returns more then one row, then one 
								outputfile will be created for each row. Additional files will be created with 
								a counter indicating the row number from the result. In the above
								example, image.bmp, image_1.bmp, image_3.bmp and so on, would be created.
                If you want to export addtional columns together with the BLOB contents, please
                use the <link linkend="command-export">WbExport</link> together with the XML format.
            </para>
            <note>
                You can fully manipulate (save, view, upload) the contents of BLOB columns in a result set.
                Please refer to <xref linkend="blob-support"/> for details.
            </note>
    </section>


    <section id="command-schema-report">
      <title>Create a report of the database objects - WbReport</title>

      <para>Creates an XML report of selected tables. This report could be used
      to generate an HTML documentation of the database (e.g. using the <link linkend="command-xslt">XSLT</link>
      command). This report can also be generated from within the <link linkend="dbexplorer">Database Object Explorer</link>
      </para>
      <para>
        The resulting XML file can  be transformed into a HTML documentation of your database schema.
        Sample stylesheets can be downloaded from   <ulink url="http://www.sql-workbench.net/xstl.html"/>.
        If you have XSLT stylsheets that you would like to share, please send them to
        <email>support@sql-workbench.net</email>.
      </para>

      <para>Using this command you can reverse engineer an existing database. The XML file
      can then be used to generate a HTML documentation of the database or to be transformed
      into a format that is supported by your design tool.</para>
            <para>To see table and column comments with an Oracle database, you need to
            <link linkend="oracle-enable-remarks">enable remarks reporting</link> for the JDBC
            driver in order to see the comments.</para>

      <para>The command supports the following parameters:</para>

      <informaltable frame="all">
        <tgroup cols="2" align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>

          <tbody valign="top">
            <row>
              <entry>-file</entry>
              <entry>The filename of the output file.</entry>
            </row>
            <row>
                <entry>-tables</entry>
                <entry>A (comma separated) list of tables to report. Default is
                all tables. If this parameter is specified <literal>-schemas</literal> is ignored.
                If you want to generate the report on tables from different users/schemas you have
                to use fully qualified names in the list (e.g. <literal>-tables=MY_USER.TABLE1,OTHER_USER.TABLE2</literal>)
                You can also specify wildcards in the table name: <literal>-table=CONTRACT_%</literal> will create
                an XML report for all tables that start with <literal>CONTRACT_</literal>
                </entry>
            </row>
            <row>
                <entry>-schemas</entry>
                <entry>A (comma separated) list of schemas to generate the report from.
                For each user/schema all tables are included in the report. e.g.
                <literal>-schemas=MY_USER,OTHER_USER</literal> would generate a report
                for all tables in the schemas <literal>MY_USER</literal> and <literal>OTHER_USER</literal>.
                </entry>
            </row>
            <row>
                <entry>-namespace</entry>
                <entry>The namespace to be used for the XML tags. By default no
                namespace is used. If you supply a value for this e.g. <literal>wb</literal> the tag <literal>&lt;schema-report&gt;
                </literal> would be written as <literal>&lt;wb:schema-report&gt;</literal>
                </entry>
            </row>
            <row>
                <entry>-includetables</entry>
                <entry>Control the output of table information for the report. The default is
                          <literal>true</literal>. Valid values are <literal>true</literal>, <literal>false</literal>.
                </entry>
            </row>
            <row>
                <entry>-includeprocedures</entry>
                <entry>Control the output of stored procedure information for the report. The default is
                <literal>false</literal>. Valid values are <literal>true</literal>, <literal>false</literal>.
                </entry>
            </row>
            <row>
                <entry>-format</entry>
                <entry>The format of the outputfile. The default is the &wb-productname;
                specific XML format. Using <literal>-format=dbdesigner</literal> you can generate
                an XML file suitable to be opened with DbDesigner4
                </entry>
            </row>
          </tbody>
        </tgroup>
     </informaltable>
   </section>

   <section id="command-schema-diff">
    <title>Compare two database schemas - WbSchemaDiff</title>
    <para>The <literal>WbSchemaDiff</literal> analyzes two schemas (or a list of tables)
    and outputs the differences between those schemas as an XML file. The XML file
    describes the changes that need to be applied to the target schema to have
    the same structure as the reference schema, e.g. modify column definitions,
    remove or add tables, remove or add indexes.
    </para>
    <para>The output is intended to be transformed using XSLT (e.g. with the
    <link linkend="command-xslt">XSLT Command</link>).
        Sample XSLT transformations
    can be found on the <ulink url="http://www.sql-workbench.net/xslt.html">&wb-productname; homepage</ulink>
    </para>
      <para>The command supports the following parameters:</para>

      <informaltable frame="all">
				<tgroup cols="2" align="left">
					<colspec colname="c1" colwidth="4cm" />
					<colspec colname="c2" />
					<thead>
						<row>
							<entry>Parameter</entry>
							<entry>Description</entry>
						</row>
					</thead>

					<tbody valign="top">
						<row>
							<entry>-referenceProfile</entry>
							<entry>The name of the connection profile for the reference
								connection. If this is not specified, then the current connection is
							used.</entry>
						</row>
						<row>
							<entry>-referenceGroup</entry>
							<entry>If the name of your reference profile is not unique across 
								all profiles, you will need to specify the group in which the profile 
								is located with this parameter.
							</entry>
						</row>
						<row>
							<entry>-targetProfile</entry>
							<entry>
								<para>
									The name of the connection profile for the target
									connection (the one that needs to be migrated). If this is not
									specified, then the current connection is used.
								</para>
								<para>
									If you use the current connection for reference and target,
									then you should prefix the table names with schema/user or
									use the <literal>-referenceschema</literal> and
									<literal>-targetschema</literal> parameters.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-targetGroup</entry>
							<entry>If the name of your target profile is not unique across 
								all profiles, you will need to specify the group in which the profile 
								is located with this parameter.
							</entry>
						</row>
						
						<row>
							<entry>-file</entry>
							<entry>The filename of the output file. If this
							is not supplied the output will be written to the message area</entry>
						</row>
						
						<row>
							<entry>-referenceTables</entry>
							<entry>A (comma separated) list of tables that are the reference
								tables, to be checked.
							</entry>
						</row>
						
						<row>
							<entry>-targetTables</entry>
							<entry>
								<para>
									A (comma separated) list of tables in the target
									connection to be compared to the source tables. The tables
									are "matched" by their position in the list. The first table in the
									<literal>-referenceTables</literal> parameter is compared to the
									first table in the <literal>-targetTables</literal> parameter, and so
									on. Using this parameter you can compare tables that do not have the
									same name.
								</para>
								<para>If you omit this parameter, then all tables from the
									target connection with the same names as those listed in
									<literal>-referenceTables</literal> are compared.
								</para>
								<para>If you omit both parameters, then all tables that the
									user can access are retrieved from the source connection
									and compared to the tables with the same name in the target
									connection.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-referenceSchema</entry>
							<entry>
								Compare all tables from the specified schema (user)
							</entry>
						</row>
						
						<row>
							<entry>-targetSchema</entry>
							<entry>
								A schema in the target connection to be compared to the tables from the reference schema.
							</entry>
						</row>
						
						<row>
							<entry>-namespace</entry>
							<entry>The namespace to be used for the XML tags. By default no
								namespace is used. If you supply a value for this e.g. <literal>wb</literal> the tag <literal>&lt;schema-report&gt;
								</literal> would be written as <literal>&lt;wb:modify-table&gt;</literal>
							</entry>
						</row>
						
						<row>
							<entry>-encoding</entry>
							<entry>The encoding to be used for the XML file. The default is UTF-8</entry>
						</row>
						
						<row>
							<entry>-includePrimaryKeys</entry>
							<entry>Select whether primary key constraint definitions should be compared as well.
								The default is <literal>true</literal>.
								Valid values are <literal>true</literal> or <literal>false</literal>.
							</entry>
						</row>
						
						<row>
							<entry>-includeForeignKeys</entry>
							<entry>Select whether foreign key constraint definitions should be compared as well.
								The default is <literal>true</literal>.
								Valid values are <literal>true</literal> or <literal>false</literal>.
							</entry>
						</row>
						
						<row>
							<entry>-includeConstraints</entry>
							<entry>
								<para>
									Select whether table and column (check) constraints
									should be compared as well. &wb-productname; compares the constraint
									definition (SQL) as stored in the database. When comparing schemas from
									different DBMS systems this will not return the desired results.
								</para>
								<para>
									The default is to not compare table constraints (<literal>false</literal>)
									Valid values are <literal>true</literal> or <literal>false</literal>.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-includeViews</entry>
							<entry>
								<para>
									Select whether views should also be compared. When comparing
									views, the source as it is stored in the DBMS is compared. This comparison
									is case-sensitiv, which means <literal>SELECT * FROM foo;</literal> will be
									reported as a difference to <literal>select * from foo;</literal> even
									if they are logically the same. A comparison across different DBMS will also not
									work properly!
								</para>
								<para>The default is <literal>true</literal>
									Valid values are <literal>true</literal> or <literal>false</literal>.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-includeProcs</entry>
							<entry>
								<para>
									Select whether stored procedures should also be compared. When comparing
									procedures the source as it is stored in the DBMS is compared. This comparison
									is case-sensitiv. A comparison across different DBMS will also not work!
								</para>
								<para>The default is <literal>false</literal>
									Valid values are <literal>true</literal> or <literal>false</literal>.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-includeIndex</entry>
							<entry>
								Select whether indexes should be compared as well.  The default
								is to not compare index definitions.
								Valid values are <literal>true</literal> or <literal>false</literal>.
							</entry>
						</row>
						
						<row>
							<entry>-useJdbcTypes</entry>
							<entry>
								<para>
									Define whether to compare the DBMS specific data types, or 
									the JDBC data type returned by the driver. When comparing 
									tables from two different DBMS it is recommended to use
									<literal>-useJdbcType=true</literal> as this will make the 
									comparison a bit more DBMS-independent. When comparing e.g. 
									Oracle vs. PostgreSQL a column defined as 
									<literal>VARCHAR2(100)</literal> in Oracle would be reported as beeing different
									to a <literal>VARCHAR(100)</literal> column in PostgreSQL which is not really true
									As both drivers ropert the column as java.sql.Types.VARCHAR, 
									they would be considered as identical when using <literal>-useJdbcType=true</literal>.
								</para>
								<para>
									Valid values are <literal>true</literal> or <literal>false</literal>.
								</para>
							</entry>
						</row>
					</tbody>
				</tgroup>
      </informaltable>

   </section>

  <section id="command-xslt">
    <title>Run an XSLT transformation - WbXslt</title>

    <para>Transforms an XML file via a XSLT stylesheet. This can be used to format
    XML input files into the correct format for &wb-productname; or to transform
    the output files that are generated by the various &wb-productname; commands.</para>
    <para>Parameters for the XSLT command:</para>
      <informaltable frame="all">
        <tgroup cols="2"  align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
          <thead>
            <row>
              <entry>Parameter</entry>
              <entry>Description</entry>
            </row>
          </thead>

          <tbody valign="top">
            <row>
              <entry>-inputfile</entry>
              <entry>The name of the XML source file.</entry>
            </row>
            <row>
              <entry>-xsltoutput</entry>
              <entry>The name of the generated output file.</entry>
            </row>
            <row>
              <entry>-stylesheet</entry>
              <entry>The name of the XSLT stylesheet to be used.</entry>
            </row>
          </tbody>
        </tgroup>
      </informaltable>
  </section>

    <section id="command-vardef">
      <title>Define a script variable - WbVarDef</title>

      <para>This defines an internal variable which is used for variable substitution during
      SQL execution. Details can be found in the chapter <xref linkend="using-variables"/>.
      </para>
      <para>The syntax for defining a variable is: <literal>WbVarDef variable=value</literal></para>
      <para>The variable definition can also be read from a file. The file should list
      each variable definition on one line (this is the format of a normal Java properties
      file). Lines beginning with a <literal>#</literal> sign are ignored.
      The syntax is <literal>WBVARDEF -file=&lt;filename&gt;</literal>
      </para>
      <para>You can also specify a file when starting &wb-productname; with the
      parameter <literal>-vardef=&lt;filename&gt;</literal>.
      For details see see <link linkend="cmdline-vardef">Reading variables from a file</link>.
      </para>
    </section>

    <section id="command-vardelete">
      <title>Delete a script variable - WbVarDelete</title>

      <para>This removes an internal variable from the variable list.
       Details can be found in the chapter <xref linkend="using-variables"/>.
      </para>
    </section>

    <section id="command-varlist">
      <title>Show defined script variables - WbVarList</title>

      <para>This list all defined variables from the variable list.
       Details can be found in the chapter <xref linkend="using-variables"/>.
      </para>
    </section>

    <section id="command-wbinclude">
      <title>Execute a SQL script - WbInclude (@)</title>
      <para>
         With the <literal>WbInclude</literal> command you run SQL scripts without
         actually loading them into the editor, or call other scripts from within
         a script. The format of the command is <literal>WbInclude filename;</literal>.
         For DBMS other then MS SQL, the command can be abbreviated using the @ sign: <literal>@filename;</literal>
         is equivalent to <literal>WbInclude filename;</literal>.
         The script that is run in this way may also include other scripts.
      </para>
      <para>
         The reason for excluding MS SQL is, that when creating stored procedures in MS SQL, the procedure
         parameters are identified using the @ sign, thus &wb-productname; would interpret the lines
         with the variable definition as the WbInclude command. If you want to use the @ command
         with MS SQL, you can <link linkend="options-enable-shortinclude">configure</link> this in your
         <literal>workbench.settings</literal> configuration file.
      </para>
			<note>
				If the included SQL script contains <literal>SELECT</literal> queries, the result
				of those queries will <emphasis role="bold">not</emphasis> be displayed in the GUI
			</note>
      <para>The long version of the command accepts additional parameters.
        When using the long version, the filename needs to be passed as a parameter as well.
      </para>
      <para>
          Only files up to a <link linkend="options-max-script-size">certain size</link> will be read into memory. Files exceeding
          this size will be processes statement by statement. In this case the automatic
          detection of the <link linkend="alternate-delimiter-usage">alternate delimiter</link> will
          not work. If your scripts exceed the maximum size and do use the alternate delimiter
          you will have to use the "long" version so that you can specify the actual
          delimiter used in your script.
      </para>
      <para>The command supports the following parameters:</para>

      <informaltable frame="all">
        <tgroup cols="2" align="left">
          <colspec colname="c1" colwidth="4cm" />
          <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>

          <tbody valign="top">
            <row>
              <entry>-file</entry>
              <entry>The filename of the file to be included.</entry>
            </row>
						
            <row>
                <entry>-continueOnError</entry>
                <entry>
									Defines the behaviour if an error occurs in one of the statements.
									If this is set to <literal>true</literal> then script execution will continue
									even if one statement fails. If set to <literal>false</literal> script execution
									will be halted on the first error. The default value is <literal>false</literal>
                </entry>
            </row>
						
            <row>
                <entry>-delimiter</entry>
                <entry>
									Specify the delimiter that is used in the script. This defaults 
									to <literal>;</literal>. If you want to define a delimiter that
									will only be recognized when beeing on a single line, append <literal>;nl</literal>
									to the value, e.g.: <literal>-delimiter=/;nl</literal>
                </entry>
            </row>
						
            <row>
                <entry>-encoding</entry>
                <entry>Specify the encoding of the input file.</entry>
            </row>
						
          </tbody>
        </tgroup>
      </informaltable>

      <para>Execute <literal>my_script.sql</literal></para>
      <programlisting>@my_script.sql;</programlisting>
      <para>Execute <literal>my_script.sql</literal> but abort on the first error</para>
      <programlisting>wbinclude -file="my_script.sql" -continueOnError=false;</programlisting>
    </section>

    <section id="command-define-pk">
      <title>Define primary key columns - WbDefinePK</title>
      <para>
				To be able to directly edit data in the result set (grid) &wb-productname; needs
				a primary key on the underlying table. In some cases these primary keys are not present or
				cannot be retrieved from the database (e.g. when using updateable views).
				To still be able to automatically update a result based on those tables (without always
				manually defining the primary key) you can manually define a primary
				key using the <literal>WbDefinePk</literal> command.
      </para>
      <para>
				Assuming you have an updateable view called <literal>v_person</literal> where
				the primary key is the column <literal>person_id</literal>. When you simply do a
				<literal>SELECT * FROM v_person</literal>, &wb-productname; will prompt you for the
				primary key when you try to save changes to the data. If you run
      </para>

      <programlisting>WbDefinePk v_person=person_id</programlisting>
      <para>
				before retrieving the result, &wb-productname; will automatically
				use the <literal>person_id</literal> as the primary key (just as if this
				information had been retrieved from the database).
      </para>
			<para>To delete a definition simply call the command with an empty column list:</para>
			<programlisting>WbDefinePk v_person=</programlisting>
			<para>
				If you want to define certain mappings permanently, this can be done using
				a mapping file that is specified in the <link linkend="options-pkmapping">configuration file</link>.
				The file specified has to be a text file with each line containing one
				primary key definition in the same format as passed to this command. The global mapping will
				automatically be saved when you exit the application if a filename has been defined.
				If no file is defined, then all PK mappings that you define are lost when
				exiting the application (unless you explicitely save them using
				<link linkend="command-save-pkmap">WbSavePkMap</link>
			</para>

      <programlisting>v_person=person_id
v_data=id1,id2</programlisting>

      <para>
				will define a primary key for the view <literal>v_person</literal> and one for
				the view <literal>v_data</literal>. The definitions stored in that file can
				be overwritten using the <literal>WbDefinePk</literal> command, but those changes
				won't be saved to the file. This file will be read for all database connections and
				is not profile specific. If you have conflicting primary key definitions for
				different databases, you'll need to execute the <literal>WbDefinePk</literal> command
				each time, rather then specifying the keys in the mapping file.
      </para>
			
      <para>
				When you define the key columns for a table through the GUI, you have the option
				to remember the defined mapping. If this option is checked, then that mapping
				will be added to the global map (just as if you had executed <literal>WbDefinePk</literal>
				manually.
      </para>
      <note>
				The mappings will be stored with lowercase table names internally, regardless how you specify them.
      </note>

    </section>

    <section id="command-list-pk">
      <title>List defined primary key columns - WbListPKDef</title>
      <para>To view the currently defined primary keys, execute the command
      <literal>WbListPkDef</literal>.</para>
    </section>

    <section id="command-load-pkmap">
      <title>Load primary key mappings - WbLoadPKMap</title>
      <para>
        To load the additional primary key definitions from a file, you can
        use the the <literal>WbLoadPKMap</literal> command. If a filename is defined
        in the <link linkend="options-pkmapping">configuration file</link> then that
        file is loaded. Alternatively if no file is configured, or if you want to
        load a different file, you can specify the filename using the <literal>-file</literal>
        parameter.
      </para>
    </section>

    <section id="command-save-pkmap">
      <title>Save primary key mappings - WbSavePKMap</title>
      <para>
        To save the current primary key definitions to a file, you can
        use the the <literal>WbSavePKMap</literal> command. If a filename is defined
        in the <link linkend="options-pkmapping">configuration file</link> then the
        definition is stored in that file. Alternatively if no file is configured, or if you want to
        store the current mapping into a different file, you can specify the filename
        using the <literal>-file</literal> parameter.
      </para>
    </section>

    <section id="command-enableout" xreflabel="ENABLEOUT">
      <title>Enable Oracle's DBMS_OUTPUT package - ENABLEOUT</title>

      <para>
				This command enables the <literal>DBMS_OUTPUT</literal> package when connected to
				an Oracle database. On other systems this command does nothing. After
				the <literal>DBMS_OUTPUT</literal> package is enabled, any message written with
				dbms_output.put_line() are displayed in the message pane after
				executing a SQL statement. It is equivalent to calling the
				dbms_output.enable() procedure.
      </para>

      <para>
				The <literal>DBMS_OUTPUT</literal> package can be enabled automatically when a
				connection is established. See <xref linkend="options-enable-out"/>
      </para>
			
			<note>
				Due to a bug in Oracle's JDBC driver, you cannot retrieve columns with 
				the <literal>LONG</literal> or <literal>LONG RAW</literal> data type if the <literal>DBMS_OUTPUT</literal> 
				package is enabled. 
				In order to be able to display these columns support for <literal>DBMS_OUTPUT</literal> has
				to be switched off. 
			</note>
			
    </section>

    <section id="command-disableout">
      <title>Disable Oracle's DBMS_OUTPUT package - DISABLEOUT</title>

      <para>
				This disables the <literal>DBMS_OUTPUT</literal> package for an Oracle database.
				This is equivalent to calling dbms_output.disable() procedure.
      </para>
			
      <para>
				The <literal>DBMS_OUTPUT</literal> package can be disabled by default.
				See <xref linkend="options-enable-out"/>
      </para>
			
    </section>

    <section id="command-wbfeedback">
        <title>Control feedback messages - WbFeedback</title>
        <para>
            Normally &wb-productname; prints the results for each statement
            into the message panel. As this feedback can slow down the execution
            of large scripts, you can disable the feedback using the <literal>WbFeedback</literal>
            command. When <literal>WbFeedback OFF</literal> is executed, only a summary of the
            number of executed statements will be displayed, once the script execution has
            finished. This is the same behaviour as selecting "Consolidate script log" in the
            options window. The only difference is, that the setting through <literal>WbFeedback</literal>
            is temporary and does not affect the global setting.
        </para>
    </section>

		<section id="command-desc">
			<title>Show table structure - DESCRIBE</title>
			
			<para>Describe shows the definition of the given table. It can be
			abbreviated with DESC. The command expects the table name as a parameter.</para>
			<programlisting>DESC person;</programlisting>
			<para>If you want to show the structure of a table from a different user, you need
			to prefix the table name with the desired user</para>
			<programlisting>DESCRIBE otheruser.person;</programlisting>
		</section>
		
		<section id="command-set">
			<title>Setting connection properties - SET</title>
			<para>
				The <literal>SET</literal> command is available to enable you to run SQL scripts that are 
				designed to run with Oracle's SQL*Plus utility inside &wb-productname; as well.
				Most of the parameters of the <literal>SET</literal> are only valid inside 
				SQL*Plus, and thus for Oracle any error message resulting from executing a <literal>SET</literal>
				command will only be logged as a warning. For all other DBMS the command is passed
				directly to the server, except for the parameters described in this chapter (because
				they have an equivalent JDBC call that will be executed instead).
			</para>
			
			<section id="command-set-feedback">
				<title>FEEEDBACK</title>
				<para>
					<literal>SET feedback ON/OFF</literal> is equivalent to the <link linkend="command-wbfeedback">WbFeedback</link>
					command, but mimics the syntax of Oracle's SQL*Plus utility.
				</para>
			</section>
			
			<section id="command-set-serveroutput">
				<title>SERVEROUTPUT</title>
				<para>
					<literal>SET serveroutput on</literal> is equivalent to the <link linkend="command-enableout">ENABLEOUT</link>
					command and <literal>SET serveroutput off</literal> is equivalent to <link linkend="command-disableout">DISABLEOUT</link> command.
				</para>
			</section>
			
			<section id="command-set-autocommit">
				<title>AUTOCOMMIT</title>
				<para>
					With the command <literal>SET autocommit ON/OFF</literal> autocommit can be turned on or 
					off for the current connection. This is equivalent to setting the autocommit property
					in the <link linkend="profile-jdbc-properties">connection profile</link> or toggling 
					the state of the 
					<menuchoice><guimenu>SQL</guimenu><guimenuitem>Autocommit</guimenuitem></menuchoice>
					menu item.
				</para>
			</section>
			
		</section>

  <section id="command-list">
    <title>List tables - WbList</title>

    <para>This command lists all available tables (including views and
      synonyms). This output is equivalent to the left part of the Database
      Object Explorer&#39;s Table tab.
    </para>
  </section>

  <section id="command-listprocs">
    <title>List stored procedures - WbListProcs</title>

    <para>This command will list all stored procedures available to the
    current user. The output of this command is equivalent to the Database
    Explorer&apos;s Procedure tab.</para>
  </section>

  <section id="command-listcat">
    <title>List catalogs - WbListCat</title>

    <para>Lists the available catalogs or databases. The output of this
    command depends on the underlying JDBC driver and DBMS. For MS SQL
    Server this lists the available databases (which then could be changed
    by USE &#60;dbname&#62;)</para>

    <para>For Oracle this command returns nothing (as Oracle does not
    implement the concept of catalogs)</para>
    <para>This command calls the JDBC driver&apos;s <literal>getCatalogs()</literal> method and will
    return its result. If on your database system this command does not display
    a list, it is most likely that your DBMS does not support catalogs (e.g. Oracle)
    or the driver does not implement this feature.
    </para>
  </section>

</section>