<section id="command-import">
		<title>Import data - WbImport</title>
		<para>The WbImport command can be used to import data from text or
			XML files into a table in the database. WbImport can read the XML files generated by the
			<link linkend="command-export">WbExport</link> command&apos;s XML format. It can
			also read text files created by the WbExport command that escape non-printable
			characters.
		</para>
		<para>During the import of text files, empty lines (i.e. lines which only
			contain whitespace) will be silently ignored. The text import does not support records
			spanning multiple lines in the input file. If the input file is created using
			WbExport then it is recommended to use the <literal>-escapetext</literal> switch
			to escape non-printable characters which could break text import.
		</para>
		<para>The <link linkend="data-pumper">DataPumper</link> can also be used to import text files
			into a database table, though it does not offer all of the possibilities as the
			<literal>WbImport</literal> command.
		</para>
		<para>
			Archives created with the <literal>WbExport</literal> command using the 
			<literal>-compress=true</literal> parameter can be imported using <literal>WbImport</literal>
			command. You simply need to specifiy the archive file created by <literal>WbExport</literal>, and 
			<literal>WbImport</literal> will automatically detect the archive. For an example on creating 
			and importing compressed exports, please refer to <link linkend="export-compress">compressing export files</link>
		</para>
		
		<para>The WbImport command has the following syntax</para>
		<informaltable frame="all">
			<tgroup cols="2" align="left">
				<colspec colname="c1" colwidth="4cm" />
				<colspec colname="c2"/>
				<thead>
					<row>
						<entry>Parameter</entry>
						<entry>Description</entry>
					</row>
				</thead>
				<tbody valign="top">
					<row>
						<entry>-type</entry>
						<entry>
							<para>Possible values: <literal>xml</literal>, <literal>text</literal></para>
							<para>Defines the type of the input file</para>
						</entry>
					</row>
					<row>
						<entry>-file</entry>
						<entry>
							<para>
								Defines the full name of the input file. Alternatively
								you can also specify a directory (using <literal>-sourcedir</literal>)
								from which all files are imported.
							</para>
						</entry>
					</row>
					<row>
						<entry>-sourcedir</entry>
						<entry>
							<para>
								Defines a directory which contains import files. All
								files from that directory will be imported. If this switch is used
								with text files, then it is assumed that each filename (without the extension)
								defines the target table.
							</para>
						</entry>
					</row>
					<row>
						<entry>-extension</entry>
						<entry>
							<para>
								When using the <literal>-sourcedir</literal> switch, the
								extension for the files can be defined. All files ending with the supplied
								value will be processed. (e.g. <literal>-extension=csv</literal>).
								The extension given is case-sensitiv (i.e. <literal>TXT</literal> is something
								different than <literal>txt</literal>
							</para>
						</entry>
					</row>
					<row>
						<entry>-commitEvery</entry>
						<entry>
							<para>
                A numeric value that defines the number of rows after which a <literal>COMMIT</literal>
								is sent to the DBMS. If this parameter is not passed (or a value of zero or lower), 
								then &wb-productname; will commit when all rows have been imported. When using batch execution 
								it is recommended to commit the batch using the <literal>-commitBatch</literal> parameter.
							</para>
						</entry>
					</row>
					<row>
						<entry>-mode</entry>
						<entry>
								<para>Defines how the data should be sent to the database. Possible
								values are '<literal>INSERT</literal>', '<literal>UPDATE</literal>',
								'<literal>INSERT,UPDATE</literal>' and '<literal>UPDATE,INSERT</literal>'
								For details please refer to the <link linkend="import-update-mode">update mode</link>
								explanation.
							</para>
						</entry>
					</row>
					<row>
						<entry>-continueOnError</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>This parameter controls the behaviour when errors occur during
								the import. The default is <literal>true</literal>, meaning that the import
								will continue even if an error occurs during file parsing or updating the database.
								Set this parameter to <literal>false</literal> if you want to stop the import as soon as an error occurs.
						</para>
						<para>
							The default value for this parameter can be controlled in the <link linkend="import-continue-default">settings file</link>
							and it will be displayed if you run <literal>WbImport</literal> without any parameters.
						</para>
						</entry>
					</row>

					<row>
						<entry>-keyColumns</entry>
						<entry>
							<para>
								Defines the key columns for the target table. This parameter
								is only necessary if import is running in <literal>UPDATE</literal> mode.
							</para>
							<para>
								This parameter is ignored if files are imported using the <literal>-sourcedir</literal>
								parameter
							</para>
						</entry>
					</row>
					
					<row>
						<entry>-table</entry>
						<entry>
							<para>Defines the table into which the data should be imported</para>
							<para>
								This parameter is ignored, if the files are imported using the
								<literal>-sourcedir</literal> parameter
							</para>
						</entry>
					</row>
					
					<row>
						<entry>-schema</entry>
						<entry>
							Defines the schema into which the data should be imported. This
							is necessary for DBMS that support schemas, and you want to import
							the data into a different schema, then the current one.
						</entry>
					</row>
					
					<row>
						<entry>-encoding</entry>
						<entry>Defines the encoding of the input file (and possible CLOB files)</entry>
					</row>
					
					<row>
						<entry>-deleteTarget</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								If this parameter is set to true, data from the target table will
								be deleted (using <literal>DELETE FROM ...</literal>) before the import is started.
							</para>
						</entry>
					</row>

					<row>
						<entry>-truncateTable</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								This is essentially the same as <literal>-deleteTarget</literal>, but will 
								use the command <literal>TRUNCATE</literal> to delete the contents of the 
								table. For those DBMS that support this command, deleting rows 
								is usually faster compared to the <literal>DELETE</literal> command, but
								it cannot be rolled back.
							</para>
						</entry>
					</row>
					
					<row>
						<entry>-batchSize</entry>
						<entry>
							<para>
								A numeric value that defines the size of the batch queue. 
								Any value greater than 1 will enable batch mode. If the
								JDBC driver supports this, the INSERT (or UPDATE) performance can be increased
								drastically.
							</para>
							<para>
								This parameter will be ignored if the driver does not support batch updates or if
								the mode is not <literal>UPDATE</literal> or <literal>INSERT</literal> 
								(i.e. if <literal>-mode=update,insert</literal> or <literal>-mode=insert,update</literal> is used).
							</para>
						</entry>
					</row>
					
					<row>
						<entry>-commitBatch</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								If using batch execution (by specifying a batch size using the <literal>-batchSize</literal>
								parameter) each batch will be committed when this parameter is set to <literal>true</literal>.
								This is slightly different to using <literal>-commitEvery</literal> with the value of the 
								<literal>-batchSize</literal> parameter. The latter one will add a COMMIT statement to 
								the batch queue, rather than calling the JDBC commit() method. Some drivers 
								do not allow to add different statements in a batch queue. So, if a frequent 
								<literal>COMMIT</literal> is needed, this parameter should be used.
							</para>
							<para>
								When you specify <literal>-commitBatch</literal> the parameter 
								<literal>-commitEvery</literal> will be ignored. If no batch size 
								is given, then <literal>-commitBatch</literal> will be ignored.
							</para>
						</entry>
					</row>
					
					<row>
						<entry>-updateWhere</entry>
						<entry>
							<para>
								When using <link linkend="import-update-mode">update mode</link>
								an additional <literal>WHERE</literal> clause can be specified to limit
								the rows that are updated. The value of the <literal>-updatewhere</literal>
								parameter will be added to the generated <literal>UPDATE</literal> statement.
								If the value starts with the keyword <literal>AND</literal> or <literal>OR</literal>
								the value will be added without further changes, otherwise the value
								will be added as an <literal>AND</literal> clause enclosed in brackets.
								This parameter will be ignored if update mode is not active.
							</para>
						</entry>
					</row>
					
					<row>
						<entry>-startRow</entry>
						<entry>
							A numeric value to define the first row to be imported. Any row before the
							specified row will be ignored. The header row is not counted 
							to determine the row number. For a text file with a header 
							row, the pysical line 2 is row 1 (one) for this parameter.
						</entry>
					</row>
					
					<row>
						<entry>-endRow</entry>
						<entry>
							A numeric value to define the last row to be imported. The import
							will be stopped after this row has been imported. When you 
							specify <literal>-startRow=10</literal> and <literal>-endRow=20</literal>
							11 rows will be imported (i.e. rows 10 to 20). If this is a text file
							import with a header row, this would correspond to the physical lines
							11 to 21 in the input file as the header row is not counted.
						</entry>
					</row>

					<row>
						<entry>-badFile</entry>
						<entry>
							<para>If <literal>-continueOnError=true</literal> is used, you can specify a file
								to which rejected rows are written. If the provided filename denotes a directory
								a file with the name of the import table will be created in that directory. 
								When doing multi-table inserts you <emphasis role="bold">have</emphasis> to
								specify a directory name.
							</para>
							<para>
								If a file with that name exists it will be deleted when the import
								for the table is started. The fill will not be created unless at least 
								one record is rejected during the import. The file will be created with 
								the same encoding as indicated for the input file(s).
							</para>
						</entry>
					</row>

					<row>
						<entry>-maxLength</entry>
						<entry>
							<para>
								With the parameter <literal>-maxLength</literal> you can truncate
								data for character (VARCHAR, CAHR) columns during import. This can be used to 
								import  data into columns that are not big enough (e.g. VARCHAR columns) to hold 
								all values from the input file and to ensure the import can finish
								without errors.
							</para>
							<para>
								The parameter defines the maximum length for certain columns as 
								using the following format: <literal>-maxLength='firstname=30,lastname=20'</literal>
								Where firstname and lastname are columns from the target table. The above
								example will limit the values for the column firstname to 30 characters
								and the values for the column lastname to 20 characters. If a non-character
								column is specified this is ignored. Note that you <emphasis role="bold">have</emphasis>
								quote the parameter's value in order to be able to use the "embedded" equals sign.
							</para>
						</entry>
					</row>

					
				</tbody>
			</tgroup>
		</informaltable>
		
		<section id="import-text-parameters">
      <title>Parameters for the type TEXT</title>

			<informaltable frame="all">
				<tgroup cols="2"  align="left">
					<colspec colname="c1" colwidth="4cm" />
					<colspec colname="c2" />
					<thead>
						<row>
							<entry>Parameter</entry>
							<entry>Description</entry>
						</row>
					</thead>
					
					<tbody valign="top">
						
						<row>
							<entry>-fileColumns</entry>
							<entry>
								<para>
									A comma separated list of the table columns in the import file
									Each column from the file should be listed with the approriate column
									name from the target table. This parameter also defines
									the order in which those columns appear in the file.
									If the file does not contain a header line or the header line does not
									contain the names of the columns in the database (or has different names),
									this parameter has to be supplied. If a column from the input
									file has no match in the target table, then it should be specified with
									the name $wb_skip$. You can also specify the $wb_skip$ flag for
									columns which are present but that you want to exclude from the
									import.
								</para>
								<para>
									This parameter is ignored when the <literal>-sourceDir</literal>
									parameter is used.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-importColumns</entry>
							<entry>
								<para>
									Defines the columns that should be imported. If all
									columns from the input file should be imported (the default), then
									this parameter can be ommited. If only certain columns should be
									imported then the list of columns can be specified here. The column
									names should match the names provided with the -filecolumns switch.
									The same result can be achieved by providing the columns
									that should be excluded as <literal>$wb_skip$</literal> columns
									in the <literal>-filecolumns</literal> switch. Which one you choose
									is mainly a matter of taste. Listing all columns and excluding
									some using <literal>-importcolumns</literal> might be more readable
									because the structure of the file is still "visible" in the
									<literal>-filecolumns</literal> switch.
								</para>
								<para>
									This parameter is ignored when the <literal>-sourcedir</literal>
									parameter is used.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-delimiter</entry>
							<entry>
								<para>
									Define the character which separates columns in one line. 
									Records are always separated by newlines (either CR/LF or a 
									single a LF character) unless <literal>-multiLine=true</literal> is specified
								</para>
								<para>Default value: \t (a tab character)</para>
							</entry>
						</row>
						
						<row>
							<entry>-dateFormat</entry>
							<entry>
								<para>The <link linkend="options-date-format">format</link> for date columns.</para>
							</entry>
						</row>
						
						<row>
							<entry>-timestampFormat</entry>
							<entry>
								<para>
									The <link linkend="options-date-format">format</link> for datetime (or timestamp) columns in the input file.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-quoteChar</entry>
							<entry>
								<para>
									The character which was used to quote values where the delimiter is contained.
									This parameter has no default value. Thus if this is not specified, no quote checking 
									will take place. If you use <literal>-multiLine=true</literal> you <emphasis role="bold">have</emphasis>
									to specify a quote character in order for this to work properly.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-multiLine</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									Enable support for records spanning more than one line in the input file. 
									These records have to be quoted, otherwise they will
									not be recognized.
								</para>
								<para>
									If you create your exports with the <link linkend="command-export">WbExport</link> command, 
									it is recommended to encode special characters using the <literal>-escapetext</literal>
									switch rather then using multi-line records.
								</para>
								<para>The default value for this parameter can be controlled
									in the <link linkend="import-text-multiline">settings file</link> 
									and it will be displayed if you run <literal>WbImport</literal> without any parameters.
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-decimal</entry>
							<entry>The decimal symbol to be used for numbers. The default is a dot</entry>
						</row>
						
						<row>
							<entry>-header</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									If set to true, indicates that the file contains a header
									line with the column names for the target table. This will also ignore
									the data from the first line of the file. If the column names
									to be imported are defined using the <literal>-filecolumns</literal> 
									or the <literal>-importcolumns</literal> switch,
									this parameter has to be set to true nevertheless, otherwise the first row
									would be treated as a regular data row.
								</para>
								<para>
									This parameter is always set to true when the <literal>-sourcedir</literal>
									parameter is used.
								</para>
								<para>
									The default value for this option can be changed in the <link linkend="export-text-header-default">
									settings file</link> and it will be displayed if you run <literal>WbImport</literal> 
                  without any parameters. It defaults to <literal>true</literal>
								</para>
							</entry>
						</row>
						
						<row>
							<entry>-decode</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									This controls the decoding of escaped characters. If the
									export file was e.g. written with <link linkend="text-escape-switch">escaping enabled</link>
									then you need to set <literal>-decode=true</literal> in order to interpret string sequences
									like \t, \n or escaped Unicode characters properly. This is not enabled by default
									because applying the necessary checks has an impact on the performance.
								</para>
							</entry>
						</row>
						<row>
							<entry>-columnFilter</entry>
							<entry>
								<para>
									This defines a filter on column level that selects only certain rows
									from the input file to be sent to the database. The filter has to be
									define <literal>as column1="regex",column2="regex"</literal>
								</para>
								<para>If more then one column is listed, then all expressions must match
									in order for the input row to be processed. The expressions to be applied to
									the input value are regular expressions.
								</para>
								<para>
									This parameter is ignored when the <literal>-sourcedir</literal>
									parameter is used.
								</para>
							</entry>
						</row>
						<row>
							<entry>-lineFilter</entry>
							<entry>
								<para>
									To define a filter on the level of the input row (rather than
									for each column individually) you can define a regular expression
									that is applied to the whole input row. As the regular expressioin
									will be applied to the row as it is retrieved from the input file, 
									the column delimiter(s) have to be taken into account when defining 
									the regular expression.
								</para>
							</entry>
						</row>
						<row>
							<entry>-emptyStringIsNull</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									Controls whether input values for character type columns 
									with a length of zero are treated as <literal>NULL</literal> (value <literal>true</literal>)
									or as an empty string. 
								</para>
								<para>
									The default value for this parameter is <literal>true</literal>
								</para>
								<para>
									Note that, input values for non character columns (such as numbers or date columns) that are 
									empty or consist only of whitespace will always be treated as <literal>NULL</literal>.
								</para>
							</entry>
						</row>
						<row>
							<entry>-blobIsFilename</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									When exporting tables that have BLOB columns using <link linkend="command-export">WbExport</link>
									into text files, each BLOB will be written into a separate file. The actual column 
									data of the text file will contain the file name of the external file. 
									When importing text files that do not reference external files
									into tables with BLOB columns setting this paramter to false, will send the content 
									of the BLOB column "as is" to the DBMS. This will of course only work
									if the JDBC driver can handle the data that in the BLOB columns of the 
									text file. The default for this parameter is <literal>true</literal>
								</para>
							</entry>
						</row>

						<row>
							<entry>-clobIsFilename</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									When exporting tables that have CLOB columns using <link linkend="command-export">WbExport</link>
									and the parameter <literal>-clobAsFile=true</literal> the generated text file
									will not contain the actual CLOB contents, but the a filename indicating the 
									file in which the CLOB content is stored. 
									In this case <literal>-clobIsFilename=true</literal> has to be specified in 
									order to read the CLOB contents from the external files. The CLOB files
									will be read using the encoding specified with the <literal>-encoding</literal>
									parameter.
								</para>
							</entry>
						</row>
						
					</tbody>
				</tgroup>
			</informaltable>
			
     <para>Examples:</para>
      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,birthday
         -dateformat="yyyy-MM-dd";</programlisting>

		 <para>
			 This imports a file with three columns into a table named person. The
			 first column in the file is <literal>lastname</literal>, the second column
			 is <literal>firstname</literal> and the third column is <literal>birhtday</literal>.
			 Values in date columns are formated as yyyy-MM-dd
		 </para>

      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,$wb_skip$,birthday
         -dateformat="yyyy-MM-dd";</programlisting>

			 <para>
				 This will import a file with four columns. The third column in the file
				 does not have a corresponding column in the table <literal>person</literal>
				 so its specified as <literal>$wb_skip$</literal> and will not be imported.
			 </para>
				 
      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,phone,birthday
         -importcolumns=lastname,firstname;</programlisting>

			 <para>
				 This will import a file with four columns where all columns
				 exist in the target table. Only <literal>lastname</literal> and
				 <literal>firstname</literal> will be imported. The same effect could
				 be achieved by specifying $wb_skip$ for the last two columns and leaving
				 out the -importcolumns switch. Using -importcolumns is a bit more readable
				 because you can still see the structure of the input file. The
				 version with <literal>$wb_skip$</literal> is mandatory if the input file
				 contains columns that do not exist in the target table.
			 </para>

			<para>If you want to import certain rows from the input file, you can
			 use regular expressions:
			</para>
			 
			<programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,birthday
         -columnfilter=lastname="^Bee.*",firstname="^Za.*"
         -dateformat="yyyy-MM-dd";</programlisting>
				 
			<para>
				The above statement will import only rows where the column <literal>lastname</literal>
				contains values that start with <literal>Bee</literal> and the column <literal>firstname</literal>
				contains values that start with <literal>Za</literal>. So <literal>Zaphod Beeblebrox</literal>
				would be imported, <literal>Arthur Beeblebrox</literal> would not be imported.
			</para>
				 
			<para>
				If you want to learn more about regular expressions, please have a look
				at <ulink url="http://www.regular-expressions.info/"/>
			</para>
		 
			<para>
				If you want to limit the rows that are updated but cannot filter them
				from the input file using <literal>-columnfilter</literal> or <literal>-linefilter</literal>,
				use the <literal>-updatewhere</literal> parameter:
			</para>
			
      <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=id,lastname,firstname,birthday
         -keycolumns=id
         -mode=update
         -updatewhere="source &lt;&gt; 'manual'"</programlisting>
				 
			<para>
				This will update the table <literal>PERSON</literal>. The generated <literal>UPDATE</literal>
				statement would normally be: <literal>UPDATE person SET lastname=?, firstname=?, birthday=? WHERE id=?</literal>.
				The table contains entries that are maintained manually (identified by the value 'manual' in
				the column <literal>source</literal>) and should not be updated by &wb-productname;. By specifying
				the <literal>-updatewhere</literal> parameter, the above <literal>UPDATE</literal> statement will
				be extended to <literal>WHERE id=? AND (source &lt;&gt; 'manual')</literal>. Thus skipping
				records that are flagged as manual even if they are contained in the input file.
			</para>
			<note>
				When importing data into integer columns, the values '<literal>false</literal>' and '<literal>true</literal>'
				will silently be converted to 0 (numeric zero) and 1 (one) during an import. This is necessary
				when importing files created from a database system that supports the boolean datatype (e.g. PostgreSQL) 
				into a database system where you have to use a numeric datatype for these columns (e.g. Oracle).
			</note>
		</section>

		<section id="import-xml-parameters">
			<title>Parameters for the type XML</title>

			<para>
				The XML import only works with files generated by the <link linkend="command-export">WbExport</link>
				command.
			</para>
				
        <informaltable frame="all">
          <tgroup cols="2"  align="left">
            <colspec colname="c1" colwidth="4cm" />
            <colspec colname="c2" />
            <thead>
              <row>
                <entry>Parameter</entry>
                <entry>Description</entry>
              </row>
            </thead>
            <tbody valign="top">
						
              <row>
                <entry>-verboseXML</entry>
                <entry>
									<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
									<para>
										If the XML was generated with <literal>-verboseXML=false</literal>
										then this needs to be specified also when importing the file.
										Beginning with build 78, the &wb-productname; writes the information
										about the used tags into the meta information. So it is no
										longer necessary to specify whether -verboseXML was true when
										creating the XML file.
									</para>
                </entry>
              </row>
							
              <row>
                <entry>-sourceDir</entry>
                <entry>
									<para>Specify a director which contains the XML files.
										All files in that directory ending with ".xml"
										(lowercase!) will be processed.
										The table into which the data is imported is read
										from the XML file, also the columns to be imported. The parameters
										<literal>-keycolumns</literal>, <literal>-table</literal> and
										<literal>-file</literal> are ignored if this parameter is specified.
										If XML files are used that are generated with a version prior to
										build 78, then all files need to use either the long or short
										tag format and the <literal>-verboseXML=false</literal> parameter has
										to be specified if the short format was used.
									</para>
									<para>
										When importing several files at once, the files will be
										imported into the tables specified in the XML files. You cannot
										specify a different table (apart from editing the XML file
										before starting the import).
									</para>
                </entry>
              </row>
							
							<row>
								<entry>-importColumns</entry>
								<entry>
									<para>
										Defines the columns that should be imported. If all
										columns from the input file should be imported (the default), then
										this parameter can be ommited. When specified, the columns have to match
										the column names available in the XML file.
									</para>
								</entry>
							</row>
							
						</tbody>
          </tgroup>
        </informaltable>
    </section>

    <section id="import-update-mode">
      <title>Update mode</title>
      <para>The <literal>-mode</literal> parameter controls the way the data is sent
        to the database. The default is <literal>INSERT</literal>. &wb-productname; will
        generate an <literal>INSERT</literal> statement for each record. If the <literal>INSERT</literal>
        fails no further processing takes place for that record.
      </para>
      <para>If <literal>-mode</literal> is set to <literal>UPDATE</literal>, &wb-productname; will
        generate an <literal>UPDATE</literal> statement for each row. In order for this to work,
        the table needs to have a primary key defined, and all columns of the primary key need to
        be present in the import file. Otherwise the generated <literal>UPDATE</literal> statement
        will modify rows that should not be modified. This can be used to update existing
        data in the database based on the data from the export file.
      </para>
      <para>To either update or insert data into the table, both keywords can be specified
        for the <literal>-mode</literal> parameter. The order in which they appear as the parameter
        value, defines the order in which the respective statements are sent to the database. If the first
        statement fails, the second will be executed. For <literal>-mode=insert,update</literal> to
        work properly a primary or unique key has to be defined on the table. &wb-productname;
        will catch any exception (=error) when inserting a record, then it will try updating
        the record, based on the specified keycolumns.
        The <literal>-mode=update,insert</literal> works the other way. First &wb-productname;
        will try to update the record based on the primary keys. If the DBMS signals that no rows
        have been updated, it is assumed that the row does not exist and the record will be inserted
        into the table. This mode is recommended when no primary or unique key is defined on the table,
        and an <literal>INSERT</literal> would always succeed.
      </para>
      <para>The keycolumns defined with the <literal>-keycolumns</literal> parameter don't
      have to match the real primary key, but they should identify one row uniquely.
      </para>
     <para>You cannot use the update mode, if you select <emphasis role="bold">only</emphasis> key columns.
     The values from the source are used to build up the <literal>WHERE</literal> clause for the
     <literal>UPDATE</literal> statement. If ony key columns are defined, then there would be nothing to
     update.
      </para>

      <para>
        For maximum performance, choose the update strategy that will result in a succssful
        first statement more often. As a rule of thumb:
        <itemizedlist>
          <listitem>Use <literal>-mode=insert,update</literal>, if you expect more rows to be inserted then updated.</listitem>
          <listitem>Use <literal>-mode=update,insert</literal>, if you expect more rows to be updated then inserted.</listitem>
        </itemizedlist>
      </para>
    </section>

  </section>