<section id="command-import">
	<title>Import data using WbImport</title>

  <indexterm><primary>Import</primary><secondary>flat files</secondary></indexterm>
  <indexterm><primary>Import</primary><secondary>csv</secondary></indexterm>
  <indexterm><primary>Import</primary><secondary>tab separated</secondary></indexterm>
  <indexterm><primary>Import</primary><secondary>XML</secondary></indexterm>
  <indexterm><primary>Import</primary><secondary>Excel</secondary></indexterm>
  <indexterm><primary>Import</primary><secondary>XSLT</secondary></indexterm>
  <indexterm><primary>Import</primary><secondary>OpenOffice</secondary></indexterm>

	<para>
    The <literal>WbImport</literal> command can be used to import data from text, XML or
    Spreadsheet (ODS, XLS, XLSX) files into a table of the database.
    WbImport can read the XML files generated by the <link linkend="command-export">WbExport</link> command&apos;s XML format.
    It can also read text files created by the WbExport command that escape non-printable
		characters.
	</para>

	<para>
		The <literal>WbImport</literal> command can be used like any other SQL command
		(such as <literal>UPDATE</literal> or <literal>INSERT</literal>), including scripts
		that are run in <link linkend="using-scripting">batch mode</link>.
	</para>

	<para>
		During the import of text files, empty lines (i.e. lines which only contain whitespace) will be
		silently ignored.
	</para>

	<para>
		<literal>WbImport</literal> recognizes certain "literals" to identify the current date or time
		when converting values from text files to the appropriate data type of the DBMS.
		Thus, input values like <literal>now</literal>, or <literal>current_timestamp</literal>
		for date or timestamp columns are converted correctly. For details on which "literals" are
		supported, please see the description about <link linkend="editing-date-keywords">editing data</link>.
	</para>

	<para>
		The <link linkend="data-pumper">DataPumper</link> can also be used to import text files
		into a database table, though it does not offer all of the possibilities from the
		<literal>WbImport</literal> command.
	</para>

	<para>
		Archives created with the <link linkend="command-export"><literal>WbExport</literal></link> command
		using the <literal>-compress=true</literal> parameter can be imported using <literal>WbImport</literal>
		command. You simply need to specifiy the archive file created by <literal>WbExport</literal>, and
		<literal>WbImport</literal> will automatically detect the archive. For an example to create
		and import compressed exports, please refer to <link linkend="export-compress">compressing export files</link>
	</para>

	<note>
		<para>
			If you use <literal>continueOnError=true</literal> and expect a substantial number of rows to fail,
			it is highly recommended to also use a "bad file" to log all rejected records. Otherwise the rejected
			records are stored in memory (until the import finishes) which may lead to an out of memory error.
		</para>
	</note>

  <section id="spreadsheet-import">
    <title>Importing spreadsheet files</title>
    <para>
      In order to import Microsoft Excel (XSL, XSLT) or OpenOffice Calc (ODS) files, additional libraries are needed.
      For Excel <link linkend="download-poi-addon">the same libraries</link> are needed as for exporting those formats. For OpenOffice
      additional libraries are needed. All needed libraries are included in the download bundle named <literal>with-office-libs.zip</literal>
      If you did not download that bundle, you can download the libraries needed for OpenOffice from here: <ulink url="http://www.sql-workbench.net/odf-add-on.zip"/>.
    </para>

    <para>
      You can tell if the needed libraries are installed if you invoke the <link linkend="command-completion">auto-completion</link>
      after typing the <literal>-type=</literal> parameter. If the types XLS or ODS are presented in the drop down, the libraries installed.
    </para>

    <para>
      The Excel import supports XLS and XLSX, it does <emphasis role="bold">not</emphasis> support the "SpreadsheetML" format.
    </para>

    <important>
      <para>
        To import XLS or XLSX files, the entire file needs to be read into memory. When importing
        large files this will require a substantial amount of memory.
      </para>
    </important>

  </section>

	<section id="import-general-parameters">
		<title>General parameters</title>

    <indexterm><primary>Import</primary><secondary>parameters</secondary></indexterm>
		<para>The WbImport command has the following syntax</para>
		<informaltable frame="all">
			<tgroup cols="2" align="left">
				<colspec colname="c1" colwidth="4cm" />
				<colspec colname="c2"/>
				<thead>
					<row>
						<entry>Parameter</entry>
						<entry>Description</entry>
					</row>
				</thead>
				<tbody valign="top">
					<row>
						<entry id="import-type">-type</entry>
						<entry>
							<para>Possible values: <literal>xml</literal>, <literal>text</literal>, <literal>ods</literal>, <literal>xls</literal></para>
							<para>
                  Defines the type of the input file. This is only needed if the input file has a non-standard file extensions.
                  If this parameter is not specified, the import type is derived from the input file's extension.
              </para>
						</entry>
					</row>

					<row>
						<entry>-mode</entry>
						<entry>
								<para>
									Defines how the data should be sent to the database. Possible
									values are '<literal>INSERT</literal>', '<literal>UPDATE</literal>',
									'<literal>INSERT,UPDATE</literal>' and '<literal>UPDATE,INSERT</literal>'
									For details please refer to the <link linkend="import-update-mode">update mode</link>
									explanation.
							</para>
						</entry>
					</row>

					<row>
						<entry>-file</entry>
						<entry>
							<para>
								Defines the full name of the input file. Alternatively
								you can also specify a directory (using <literal>-sourcedir</literal>)
								from which all files are imported.
							</para>
						</entry>
					</row>

					<row>
						<entry>-table</entry>
						<entry>
							<para>Defines the table into which the data should be imported</para>
							<para>
								This parameter is ignored, if the files are imported using the
								<literal>-sourcedir</literal> parameter
							</para>
              <para>
                This parameter supports auto-completion.
              </para>
						</entry>
					</row>

					<row>
						<entry>-sourceDir</entry>
						<entry>
							<para>
								Defines a directory which contains import files. All
								files from that directory will be imported. If this switch is used with text files and no
								target table is specified, then it is assumed that each filename (without the extension)
								defines the target table. If a target table is specified using the <literal>-table</literal>
								parameter, then all files will be imported into the same table. The <literal>-deleteTarget</literal>
								will be ignored if multiple files are imported into a single table.
							</para>
						</entry>
					</row>

					<row>
						<entry>-extension</entry>
						<entry>
							<para>
								When using the <literal>-sourcedir</literal> switch, the
								extension for the files can be defined. All files ending with the supplied
								value will be processed. (e.g. <literal>-extension=csv</literal>).
								The extension given is case-sensitive (i.e. <literal>TXT</literal> is something
								different than <literal>txt</literal>
							</para>
						</entry>
					</row>

					<row>
						<entry>-ignoreOwner</entry>
						<entry>
							<para>
								If the file names imported with from the directory specified with
								-sourceDir contain the owner (schema) information, this owner (schema)
								information can be ignored using this parameter. Otherwise the files
								might be imported into a wrong schema, or the target tables will not be found.
							</para>
						</entry>
					</row>

					<row>
						<entry>-excludeFiles</entry>
						<entry>
							<para>
								Using -excludeFiles, files from the source directory (when using -sourceDir)
								can be excluded from the import. The value for this parameter is a comma
								separated list of partial names. Each file that contains at least one of the
								values supplied in this parameter is ignored. <literal>-excludeFiles=back,data</literal>
								will exclude any file that contains the value <literal>back</literal> or <literal>data</literal>
								in it, e.g.: <literal>backup</literal>, <literal>to_back</literal>, <literal>log_data_store</literal> etc.
							</para>
						</entry>
					</row>

					<row>
						<entry>-checkDependencies</entry>
						<entry>
							<para>
								When importing more than one file (using the <literal>-sourcedir</literal> switch),
								into tables with foreign key constraints, this switch can be used to
								import the files in the correct order (child tables first). When
								<literal>-checkDependencies=true</literal> is passed, &wb-productname; will
								check the foreign key dependencies for all tables. Note that this will
								not check dependencies in the data. This means that e.g. the data for a self-referencing
								table (parent/child) will not be order so that it can be imported. To import
								self-referencing tables, the foreign key constraint should be set to "initially deferred"
								in order to postpone evaluation of the constraint until commit time.
							</para>
						</entry>
					</row>

					<row>
						<entry>-commitEvery</entry>
						<entry>
							<para>
								If your DBMS neeeds frequent commits to improve performance and reduce locking
								on the import table you can control the number of rows after which a COMMIT is
								sent to the server.
							</para>
							<para>
								<literal>-commitEvery</literal>is numeric value that defines the number of rows
								after which a <literal>COMMIT</literal> is sent to the DBMS.
								If this parameter is not passed (or a value of zero or lower),
								then the import is run as a single transaction that is committed at the end.
							</para>
							<para>
								When using <link linkend="batch-import">batch import</link> and your DBMS requires
								frequent commits to improve import performance, the <literal>-commitBatch</literal>
								option should be used instead.
							</para>
							<para>
								You can turn off the use of a commit or rollback during import completely by using the option
								<literal>-transactionControl=false</literal>.
							</para>
							<para>
								Using <literal>-commitEvery</literal> means, that in case of an error
								the already imported rows cannot be rolled back, leaving the data in a potential
								invalid state.
							</para>
						</entry>
					</row>

					<row>
						<entry>-transactionControl</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								Controls if &wb-productname; handles the transaction for the import,
								or if the import must be committed (or rolled back) manually.
								If <literal>-transactionControl=false</literal> is specified, &wb-productname;
								will neither send a <literal>COMMIT</literal> nor a <literal>ROLLBACK</literal> at
								the end. This can be used when multiple files need to be imported in a single
								transaction. This can be combined with the <link linkend="script-success">cleanup</link>
								and <link linkend="script-failure">error</link> scripts in batch mode.
							</para>
						</entry>
					</row>

					<row>
						<entry>-continueOnError</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>This parameter controls the behavior when errors occur during
								the import. The default is <literal>true</literal>, meaning that the import
								will continue even if an error occurs during file parsing or updating the database.
								Set this parameter to <literal>false</literal> if you want to stop the import as soon as an error occurs.
						</para>
						<para>
							The default value for this parameter can be controlled in the <link linkend="import-continue-default">settings file</link>
							and it will be displayed if you run <literal>WbImport</literal> without any parameters.
						</para>
						<para>
              With PostgreSQL <literal>continueOnError</literal> will only work, if the use of
              savepoints is enabled using <literal>-useSavepoint=true</literal>.
						</para>
						</entry>
					</row>

					<row>
						<entry>-emptyFile</entry>
						<entry>
							<para>Possible values: <literal>ignore</literal>, <literal>warning</literal>, <literal>fail</literal></para>
							<para>
                This parameter controls the behavior when an empty file (i.e. with a length of zero bytes) is used
                for the input file. <literal>ignore</literal> means the file is ignored, no warning will be shown
                or written to the log file. <literal>warning</literal> means the file is ignored, but a warning
                will be shown and logged. With <literal>fail</literal> an empty file will be treated as an error
                unless <literal>-continueOnError=true</literal> is specified.
						</para>
						<para>
							The default value is <literal>fail</literal>
						</para>
						</entry>
					</row>

					<row>
						<entry>-useSavepoint</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								Controls if &wb-productname; guards every insert or update statement
                with a savepoint to recover from individual error during import,
                when <literal>continueOnError</literal> is set to true.
							</para>
              <para>
                Using a savepoint for each DML statement can drastically reduce the performance
                of the import.
              </para>
						</entry>
					</row>

					<row>
						<entry>-keyColumns</entry>
						<entry>
							<para>
								Defines the key columns for the target table. This parameter
								is only necessary if import is running in <literal>UPDATE</literal> mode.
							</para>
              <para>
                It is assumed that the values for the key columns will never be <literal>NULL</literal>.
              </para>
							<para>
								This parameter is ignored if files are imported using the <literal>-sourcedir</literal>
								parameter.
							</para>
						</entry>
					</row>

					<row>
						<entry>-ignoreIdentitiyColumns</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								Controls if identity or auto-increment columns will be included in the import.
							</para>
              <para>
                If this is used, the JDBC driver must correctly report the column to be excluded as an <emphasis>AUTOINCREMENT</emphasis>
                column. This can be verified in the table definition display of the DbExplorer.
                If the column is reported with <literal>YES</literal> for the <emphasis>AUTOINCREMENT</emphasis> property,
                then this column will be excluded during the import.
              </para>
						</entry>
					</row>

					<row>
						<entry>-schema</entry>
						<entry>
							Defines the schema into which the data should be imported. This
							is necessary for DBMS that support schemas, and you want to import
							the data into a different schema, then the current one.
						</entry>
					</row>

					<row>
						<entry id="import-encoding">-encoding</entry>
						<entry>
              <para>Defines the encoding of the input file (and possible CLOB files)</para>
              <para>
                If auto-completion is invoked for this parameter, it will show a list of encodings
                defined through the configuration property <literal>workbench.export.defaultencodings</literal>
                This is a comma-separated list that can be changed using
                <link linkend="command-setconfig"><literal>WbSetConfig</literal></link>
              </para>
            </entry>
					</row>

					<row>
						<entry>-deleteTarget</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								If this parameter is set to true, data from the target table will
								be deleted (using <literal>DELETE FROM ...</literal>) before the import is started.
								This parameter will only be used if <literal>-mode=insert</literal>
								is specified.
							</para>
              <para>
                This parameter is ignored for spreadsheet imports.
              </para>
						</entry>
					</row>

					<row>
						<entry>-truncateTable</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								This is essentially the same as <literal>-deleteTarget</literal>, but will
								use the command <literal>TRUNCATE</literal> to delete the contents of the
								table. For those DBMS that support this command, deleting rows
								is usually faster compared to the <literal>DELETE</literal> command, but
								it cannot be rolled back.
								This parameter will only be used if <literal>-mode=insert</literal>
								is specified.
							</para>
						</entry>
					</row>

					<row>
						<entry id="batch-import">-batchSize</entry>
						<entry>
							<para>
								A numeric value that defines the size of the batch queue.
								Any value greater than 1 will enable batch mode. If the
								JDBC driver supports this, the INSERT (or UPDATE) performance can be increased
								drastically.
							</para>
							<para>
								This parameter will be ignored if the driver does not support batch updates or if
								the mode is not <literal>UPDATE</literal> or <literal>INSERT</literal>
								(i.e. if <literal>-mode=update,insert</literal> or <literal>-mode=insert,update</literal> is used).
							</para>
						</entry>
					</row>

					<row>
						<entry>-commitBatch</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								If using batch execution (by specifying a batch size using the <literal>-batchSize</literal>
								parameter) each batch will be committed when this parameter is set to <literal>true</literal>.
								This is slightly different to using <literal>-commitEvery</literal> with the value of the
								<literal>-batchSize</literal> parameter. The latter one will add a COMMIT statement to
								the batch queue, rather than calling the JDBC commit() method. Some drivers
								do not allow to add different statements in a batch queue. So, if a frequent
								<literal>COMMIT</literal> is needed, this parameter should be used.
							</para>
							<para>
								When you specify <literal>-commitBatch</literal> the parameter
								<literal>-commitEvery</literal> will be ignored. If no batch size
								is given (using <literal>-batchSize</literal>, then <literal>-commitBatch</literal>
								will also be ignored.
							</para>
						</entry>
					</row>

					<row>
						<entry>-updateWhere</entry>
						<entry>
							<para>
								When using <link linkend="import-update-mode">update mode</link>
								an additional <literal>WHERE</literal> clause can be specified to limit
								the rows that are updated. The value of the <literal>-updatewhere</literal>
								parameter will be added to the generated <literal>UPDATE</literal> statement.
								If the value starts with the keyword <literal>AND</literal> or <literal>OR</literal>
								the value will be added without further changes, otherwise the value
								will be added as an <literal>AND</literal> clause enclosed in brackets.
								This parameter will be ignored if update mode is not active.
							</para>
						</entry>
					</row>

					<row>
						<entry>-startRow</entry>
						<entry>
							<para>
                A numeric value to define the first row to be imported. Any row before the
                specified row will be ignored. The header row is not counted
                to determine the row number. For a text file with a header
                row, the physical line 2 is row 1 (one) for this parameter.
              </para>
              <para>
                When importing text files, empty lines in the input file are silently ignored
                and do not add to the count of rows for this parameter. So if your input file
                has two lines to be ignored, then one empty line and then another line to be ignored,
                <literal>startRow</literal> must be set to 4.
              </para>
						</entry>
					</row>

					<row>
						<entry>-endRow</entry>
						<entry>
							A numeric value to define the last row to be imported. The import
							will be stopped after this row has been imported. When you
							specify <literal>-startRow=10</literal> and <literal>-endRow=20</literal>
							11 rows will be imported (i.e. rows 10 to 20). If this is a text file
							import with a header row, this would correspond to the physical lines
							11 to 21 in the input file as the header row is not counted.
						</entry>
					</row>

					<row>
						<entry>-columnFilter</entry>
						<entry>
							<para>
								This defines a filter on column level that selects only certain rows
								from the input file to be sent to the database. The filter has to be
								defined as <literal>column1="regex",column2="regex"</literal>.
								Only Rows matching all of the supplied regular expressions will
								be included by the import.
							</para>
							<para>
								This parameter is ignored when the <literal>-sourcedir</literal>
								parameter is used.
							</para>
						</entry>
					</row>


					<row>
						<entry>-badFile</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>If <literal>-continueOnError=true</literal> is used, you can specify a file
								to which rejected rows are written. If the provided filename denotes a directory
								a file with the name of the import table will be created in that directory.
								When doing multi-table inserts you <emphasis role="bold">have</emphasis> to
								specify a directory name.
							</para>
							<para>
								If a file with that name exists it will be deleted when the import
								for the table is started. The fill will not be created unless at least
								one record is rejected during the import. The file will be created with
								the same encoding as indicated for the input file(s).
							</para>
						</entry>
					</row>

					<row>
						<entry>-maxLength</entry>
						<entry>
							<para>
								With the parameter <literal>-maxLength</literal> you can truncate
								data for character columns (<literal>VARCHAR</literal>, <literal>CHAR</literal>)
								during import. This can be used to import data into columns that are not big
								enough (e.g. VARCHAR columns) to hold all values from the input file and to
								ensure the import can finish without errors.
							</para>
							<para>
								The parameter defines the maximum length for certain columns using the following
								format: <literal>-maxLength='firstname=30,lastname=20'</literal>
								Where firstname and lastname are columns from the target table. The above
								example will limit the values for the column firstname to 30 characters
								and the values for the column lastname to 20 characters. If a non-character
								column is specified this is ignored. Note that you <emphasis role="bold">have</emphasis>
								quote the parameter's value in order to be able to use the "embedded" equals sign.
							</para>
						</entry>
					</row>

					<row>
						<entry>-booleanToNumber</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								In case you are importing a boolean column (containing "true", "false")
                into a numeric column in the target DBMS, &wb-productname; will automatically
								convert the literal <literal>true</literal> to the numeric value 1 (one)
								and the literal <literal>false</literal> to the numeric value 0 (zero).
								If you do not want this automatic conversion, you have to
								specify <literal>-booleanToNumber=false</literal> for the import.
								The default values for the true/false literals can be overwritten
								with the -literalsFalse and -literalsTrue switches.
							</para>
              <para>
                To store different values than 0/1 in the target column, use the parameters
                <literal>-numericFalse</literal> and <literal>-numericTrue</literal>
              </para>
              <para>This parameter is ignored for spreadsheet imports</para>
						</entry>
					</row>

					<row>
						<entry>-numericFalse -numericTrue</entry>
						<entry>
              <para>
                These parameters control the conversion of boolean literals into numbers.
              </para>
              <para>
                If these parameters are used, any text input that is identified as a "false" literal, will be stored with the number specified
                with <literal>-numericFalse</literal>. Any text input that is identified as "true" will be stored as the number specified
                with <literal>-numericFalse</literal>.
              </para>
              <para>
                To use -1 for false and 1 for true, use the following parameters: <literal>-numericFalse='-1' -numericTrue='1'</literal>.
                Note that '-1' must be quoted due to the dash. If these parameters are used, <literal>-booleanToNumber</literal>
                will be assumed true implicitely.
              </para>
              <para>
                These parameters can be combined with <literal>-literalsFalse</literal> and <literal>-listeralsTrue</literal>.
              </para>
							<para>
								Please note:
								<itemizedlist>
									<listitem>
										<simpara>
											This conversion is only applied for "text" input values. Valid numbers in the input file will
                      <emphasis role="bold">not</emphasis> be converted to the values specified with
                      <literal>-numericFalse</literal> or <literal>-numericTrue</literal>. This means that you cannot change a <literal>0</literal> (zero)
                      in the input file into a <literal>-1</literal> in the target column.
										</simpara>
										</listitem>
								</itemizedlist>
							</para>
              <para>This parameter is ignored for spreadsheet imports</para>
            </entry>
          </row>
					<row>
						<entry>-literalsFalse -literalsTrue</entry>
						<entry>
              <para>
                These parameters control the conversion of boolean literals into boolean values.
              </para>
							<para>
								These two switches define the text values that represent the (boolean) values <literal>false</literal> and
								<literal>true</literal> in the input file. This conversion is applied when storing the data in a column
                that is of type <literal>boolean</literal> in the database.
							</para>
							<para>
								The value to these switches is a comma separated list of literals
								that should be treated as the specified value, e.g.:
								<literal>-literalsFalse='false,0' -literalsTrue='true,1'</literal>
								will define the most commonly used values for true/false.
							</para>
							<para>
								Please note:
								<itemizedlist>
									<listitem><simpara>The definition of the literals is case sensitive!</simpara></listitem>
									<listitem>
										<simpara>
											You always have to specify both switches, otherwise the definition will
											be ignored
										</simpara>
										</listitem>
								</itemizedlist>
							</para>
              <para>This parameter is ignored for spreadsheet imports</para>
						</entry>
					</row>

					<row>
						<entry>-constantValues</entry>
						<entry>
							<para>
								With this parameter you can supply constant values for one or more columns
								that will be used when inserting new rows into the database.
							</para>
							<para>
								The constant values will only be used when inserting rows (e.g. using <literal>-mode=insert</literal>)
							</para>
							<para>
								The format of the values is <literal>-constantValues="column1=value1,column2=value2"</literal>.
                The parameter can be repeated multiple times, to make quoting easier:
                <literal>-constantValues="column1=value1" -constantValues="column2=value2"</literal>
								The values will be converted by the same rules as the input values from the input	file. If
								the value for a character column is enclosed in single quotes, these will be removed from the
								value before sending it to the database. To include single quotes at the start or end of
								the input value you need to use two single quotes, e.g.<literal>-constantValues="name=''Quoted'',title='with space'"</literal>
								For the field <literal>name</literal> the value <literal>'Quoted'</literal> will be sent to the database.
								for the field <literal>title</literal> the value <literal>with space</literal> will be sent to the database.
							</para>
							<para>
								To specify a function call to be executed, enclose the function call in <literal>${...}</literal>,
								e.g. <literal>${mysequence.nextval}</literal> or <literal>${myfunc()}</literal>. The supplied
								function will be put into the <literal>VALUES</literal> part of the INSERT statement without
								further checking (after removing the ${ and } characters, of course). So make sure that the
								syntax is valid for your DBMS. If you do need to store a literal like <literal>${some.value}</literal>
								into the database, you need to quote it: <literal>-constantValues="varname='${some.value}'"</literal>.
							</para>
							<para>
                You can also specify a <literal>SELECT</literal> statement that retrieves information from the database
                based on values from the input file. This is useful when the input file contains e.g. values from a lookup
                table (but not the primary key from the lookup table).
							</para>
              <para>
                The syntax to specify a SELECT statement is similar to a function call:
                <literal>-constantValues="$@{SELECT type_id FROM type_definition WHERE type_name = $4"</literal> where <literal>$4</literal>
                references the fourth column from the input file. The first column is $1 (not $0).
              </para>
              <para>
                The parameter for the SELECT statement do not need to be quoted as internally a prepared statement is used. However
                the values in the input file must be convertible by the JDBC driver.
              </para>
              <para>
                Please refer to the examples for more details on the usage.
              </para>
						</entry>
					</row>

					<row>
						<entry>-insertSQL</entry>
						<entry>
							<para>
                Define the statement to be used for inserting rows.
              </para>
              <para>
                This can be used to use hints or customize the
                generated INSERT statement. The parameter may only contain the <literal>INSERT INTO</literal> part
                of the statement (i.e. <literal>INSERT INTO</literal> is the default if nothing is specified).
                This can be used to pass special hints to the database, e.g. to specify an append hint for Oracle:
             </para>
              <para>
                <note>
                  You have to quote the parameter value using single quotes, otherwise comments will be removed
                  from the SQL statement!
                </note>
              </para>
              <programlisting>-insertSQL='INSERT /*+ append */ INTO'</programlisting>
						</entry>
					</row>

          &table-statements;

					&progress-parameter;

				</tbody>
			</tgroup>
		</informaltable>

	</section>

	<section id="import-text-parameters">
		<title>Parameters for the type TEXT</title>

		<informaltable frame="all">
			<tgroup cols="2"  align="left">
				<colspec colname="c1" colwidth="4cm" />
				<colspec colname="c2" />
				<thead>
					<row>
						<entry>Parameter</entry>
						<entry>Description</entry>
					</row>
				</thead>

				<tbody valign="top">

					<row>
						<entry>-fileColumns</entry>
						<entry>
							<para>
								A comma separated list of the table columns in the import file
								Each column from the file should be listed with the appropriate column
								name from the target table. This parameter also defines
								the order in which those columns appear in the file.
								If the file does not contain a header line or the header line does not
								contain the names of the columns in the database (or has different names),
								this parameter has to be supplied. If a column from the input
								file has no match in the target table, then it should be specified with
                the name <literal>$wb_skip$</literal>. You can also specify the <literal>$wb_skip$</literal> flag for
								columns which are present but that you want to exclude from the
								import.
							</para>
							<para>
								This parameter is ignored when the <literal>-sourceDir</literal>
								parameter is used.
							</para>
						</entry>
					</row>

					<row>
						<entry>-importColumns</entry>
						<entry>
							<para>
								Defines the columns that should be imported. If all
								columns from the input file should be imported (the default), then
								this parameter can be ommited. If only certain columns should be
								imported then the list of columns can be specified here. The column
								names should match the names provided with the -filecolumns switch.
								The same result can be achieved by providing the columns
								that should be excluded as <literal>$wb_skip$</literal> columns
								in the <literal>-filecolumns</literal> switch. Which one you choose
								is mainly a matter of taste. Listing all columns and excluding
								some using <literal>-importcolumns</literal> might be more readable
								because the structure of the file is still "visible" in the
								<literal>-filecolumns</literal> switch.
							</para>
							<para>
								This parameter is ignored when the <literal>-sourcedir</literal>
								parameter is used.
							</para>
						</entry>
					</row>

					<row>
						<entry id="import-text-delimiter">-delimiter</entry>
						<entry>
							<para>
								Define the character which separates columns in one line.
								Records are always separated by newlines (either CR/LF or a
								single a LF character) unless <literal>-multiLine=true</literal> is specified
							</para>
							<para>Default value: \t (a tab character)</para>
						</entry>
					</row>

					<row>
						<entry>-columnWidths</entry>
						<entry>
							<para>
								In order to import files that do not have a delimiter but have a fixed
								width for each column, this parameters defines the width of each
								column in the input file. The value for this parameter is a
								comma separated list, where each element defines the width in characters for
								each column. If this parameter is given, the <literal>-delimiter</literal>
								parameter is ignored. The order of the columns in the input file must still
                be defined using the <literal>-fileColumns</literal> parameter.
							</para>
							<para>e.g.: <literal>-fileColumns=custid,actcode,regioncd,flag -columnWidths='custid=10,actcode=5,regioncd=3,flag=1'</literal></para>
							<para>
								Note that the whole list must be enclosed in quotes as the parameter
								value contains the equal sign.
							</para>
							<para>
								If you want to import only certain columns you have to use
								<literal>-fileColumns</literal> and <literal>-importColumns</literal>
								to select the columns to import. You cannot use <literal>$wb_skip$</literal>
								in the <literal>-fileColumns</literal> parameter with a fixed column width import.
							</para>
						</entry>
					</row>

					<row>
						<entry id="import-date-format">-dateFormat</entry>
						<entry>
							<para>The <link linkend="options-date-format">format</link> for date columns.</para>
						</entry>
					</row>
					<row>
						<entry id="import-timestamp-format">-timestampFormat</entry>
						<entry>
							<para>
								The <link linkend="options-date-format">format</link> for datetime (or timestamp) columns in the input file.
							</para>
						</entry>
					</row>

					<row>
						<entry>-illegalDateIsNull</entry>
						<entry>
							<para>
								If this is set to <literal>true</literal>, illegal dates (such as February, 31st) or malformed dates
                inside the input file will be treated as a null value.
							</para>
						</entry>
					</row>

					<row>
						<entry id="import-quote-char">-quoteChar</entry>
						<entry>
							<para>
								The character which was used to quote values where the delimiter is contained.
								This parameter has no default value. Thus if this is not specified, no quote checking
								will take place. If you use <literal>-multiLine=true</literal> you <emphasis role="bold">have</emphasis>
								to specify a quote character in order for this to work properly.
							</para>
						</entry>
					</row>

					<row>
						<entry>-quoteAlways</entry>

						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
                WbImport will always handled quoted values correctly, if a quote character is defined
                through -quoteChar.
							</para>
              <para>
                Using <literal>-quoteAlways=true</literal> enables the distinction between NULL values
                and empty strings in the import file, but only if <literal>-quoteAlways=true</literal>
                has also been used when running <link linkend="command-export">WbExport</link>.
                Remember to also use <literal>-emptyStringIsNull=false</literal>, as by default
                empty string values are treated as NULLs
              </para>
						</entry>
					</row>

					<row>
						<entry>-quoteCharEscaping</entry>
						<entry>
							<para>Possible values: <literal>none</literal>, <literal>escape</literal>, <literal>duplicate</literal></para>
							<para>
								Defines how quote characters that appear in the actual data
								are stored in the input file.
							</para>
							<para>
								You have to define a quote character in order for this option
								to have an effect. The character defined with the -quoteChar switch
								will then be imported according to the setting defined by this switch.
							</para>
							<para>
								If <literal>escape</literal> is specified, it is expected that a quote that
								is part of the data is preceded with a backslash,
								e.g. the input value <literal>here is a \" quote character</literal> will be imported
								as <literal>here is a " quote character</literal>
							</para>
							<para>
								If <literal>duplicate</literal> is specified, it is expected that the
								quote character is duplicated in the input data. This is similar to the
								handling of single quotes in SQL literals.
								The input value <literal>here is a "" quote character</literal> will be imported
								as <literal>here is a " quote character</literal>
							</para>
						</entry>
					</row>

					<row>
						<entry id="text-import-multiline">-multiLine</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								Enable support for records spanning more than one line in the input file.
								These records have to be quoted, otherwise they will
								not be recognized.
							</para>
							<para>
								If you create your exports with the <link linkend="command-export">WbExport</link> command,
								it is recommended to encode special characters using the <literal>-escapetext</literal>
								switch rather then using multi-line records.
							</para>
							<para>The default value for this parameter can be controlled
								in the <link linkend="import-text-multiline">settings file</link>
								and it will be displayed if you run <literal>WbImport</literal> without any parameters.
							</para>
						</entry>
					</row>

					<row>
						<entry id="text-import-decimal">-decimal</entry>
						<entry>The decimal symbol to be used for numbers. The default is a dot</entry>
					</row>

					<row>
						<entry id="text-import-header">-header</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								If set to true, indicates that the file contains a header
								line with the column names for the target table. This will also ignore
								the data from the first line of the file. If the column names
								to be imported are defined using the <literal>-filecolumns</literal>
								or the <literal>-importcolumns</literal> switch,
								this parameter has to be set to true nevertheless, otherwise the first row
								would be treated as a regular data row.
							</para>
							<para>
								This parameter is always set to true when the <literal>-sourcedir</literal>
								parameter is used.
							</para>
							<para>
								The default value for this option can be changed in the <link linkend="export-text-header-default">
								settings file</link> and it will be displayed if you run <literal>WbImport</literal>
								without any parameters. It defaults to <literal>true</literal>
							</para>
						</entry>
					</row>

					<row>
						<entry id="text-import-decode">-decode</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								This controls the decoding of escaped characters. If the
								export file was e.g. written with <link linkend="text-escape-switch">WbExport's escaping enabled</link>
								then you need to set <literal>-decode=true</literal> in order to interpret string sequences
								like \t, \n or escaped Unicode characters properly. This is not enabled by default
								because applying the necessary checks has an impact on the performance.
							</para>
						</entry>
					</row>

					<row>
						<entry>-lineFilter</entry>
						<entry>
							<para>
								This defines a filter on the level of the whole input row (rather than
								for each column individually). Only rows matching this regular expression will
								be included in the import.
							</para>
							<para>
								The complete content of the row from
								the input file will be used to check the regular expression.
								When defining the expression, remember that the (column) delimiter
								will be part of the input string of the expression.
							</para>
						</entry>
					</row>

					<row>
						<entry>-emptyStringIsNull</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								Controls whether input values for character type columns
								with a length of zero are treated as <literal>NULL</literal> (value <literal>true</literal>)
								or as an empty string.
							</para>
							<para>
								The default value for this parameter is <literal>true</literal>
							</para>
							<para>
								Note that, input values for non character columns (such as numbers or date columns) that are
								empty or consist only of whitespace will always be treated as <literal>NULL</literal>.
							</para>
						</entry>
					</row>

					<row>
						<entry>-nullString</entry>
						<entry>
							<para>
                Defines the string value that in the input file to denote a <literal>NULL</literal> value.
                The value of this is case-sensitive, so <literal>-nullString=NULL</literal> is
                different to <literal>-nullString=null</literal>
							</para>
						</entry>
					</row>

					<row>
						<entry>-trimValues</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								Controls whether leading and trailing whitespace are removed from the input values
								before they are stored in the database. When used in combination with
								<literal>-emptyStringIsNull=true</literal> this means that a column value that contains
								only whitespace will be stored as <literal>NULL</literal> in the database.
							</para>
							<para>
								The default value for this parameter can be controlled
								in the <link linkend="import-text-trimvalues">settings file</link>
								and it will be displayed if you run <literal>WbImport</literal> without any parameters.
							</para>
							<para>
								Note that, input values for non character columns (such as numbers or date columns) are
								always trimmed before converting them to their target datatype.
							</para>
						</entry>
					</row>

					<row>
						<entry>-blobIsFilename</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
              <para>
                This is a deprecated parameter. Please use <literal>-blobType</literal> instead.
              </para>
							<para>
								When exporting tables that have BLOB columns using <link linkend="command-export">WbExport</link>
								into text files, each BLOB will be written into a separate file. The actual column
								data of the text file will contain the file name of the external file.
								When importing text files that do not reference external files
								into tables with BLOB columns setting this parameter to false, will send the content
								of the BLOB column "as is" to the DBMS. This will of course only work
								if the JDBC driver can handle the data that in the BLOB columns of the
								text file. The default for this parameter is <literal>true</literal>
							</para>
              <para>
                This parameter is ignored, if <literal>-blobType</literal> is also specified.
              </para>
						</entry>
					</row>

					<row>
						<entry>-blobType</entry>
						<entry>
							<para>Possible values: <literal>file</literal>, <literal>ansi</literal>, <literal>base64</literal></para>
							<para>
                Specifies how BLOB data is stored in the input file. If <literal>file</literal> is specified,
                it is assumed that the column value contains a filename that in turn contains the real blob data. This is
                the default format when using <link linkend="command-export">WbExport</link>.
              </para>
              <para>
                For the other two type, <literal>WbImport</literal> assumes that the blob data is stored as
                encoded character data in the column.
							</para>
              <para>
                If this parameter is specified, <literal>-blobIsFilename</literal> is ignored.
              </para>
						</entry>
					</row>

					<row>
						<entry>-clobIsFilename</entry>
						<entry>
							<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
							<para>
								When exporting tables that have CLOB columns using <link linkend="command-export">WbExport</link>
								and the parameter <literal>-clobAsFile=true</literal> the generated text file
								will not contain the actual CLOB contents, but the a filename indicating the
								file in which the CLOB content is stored.
								In this case <literal>-clobIsFilename=true</literal> has to be specified in
								order to read the CLOB contents from the external files. The CLOB files
								will be read using the encoding specified with the <literal>-encoding</literal>
								parameter.
							</para>
						</entry>
					</row>

					<row>
						<entry id="import-pg-copy">-usePgCopy</entry>
						<entry>
              <para>This parameter has no value, its presence turns the feature on.</para>
              <para>
                If this parameter is specified, then the input file is sent to the PostgreSQL server
                using PostgreSQL's <ulink url="http://jdbc.postgresql.org/documentation/publicapi/org/postgresql/copy/CopyManager.html">JDBC support</ulink>
                for <ulink url="http://www.postgresql.org/docs/current/static/sql-copy.html">COPY</ulink>
             </para>
              <para>
                The specified file(s) must conform to the format expected by PostgreSQL's COPY command. &wb-productname;
                creates a <literal>COPY tablename (column, ...) FROM stdin WITH (format csv, delimiter '|', header true)</literal>
                statement and then executes this, passing the actual file contents through the JDBC API.
              </para>
              <para>
                As <literal>COPY</literal> does not support "merging" of data, the only allowed import mode is <literal>insert</literal>.
                If a different mode is specified through the <literal>-mode</literal> parameter, an error will be reported.
              </para>
              <para>
                The options defined in the <literal>WITH (...)</literal> part are influenced by the parameters
                passed to <literal>WbImport</literal>. However <literal>COPY</literal> does not support all
                options that <literal>WbImport</literal> does.

                To control the format of the input file(s) <emphasis role="bold">only</emphasis> the following parameters
                are relevant when using <literal>-usePgCopy</literal>:
								<itemizedlist>
									<listitem><simpara>-header</simpara></listitem>
									<listitem><simpara>-encoding</simpara></listitem>
									<listitem><simpara>-delimiter</simpara></listitem>
								</itemizedlist>
                Especially the formatting options for dates/timestamps and numbers will have
                <emphasis role="bold">no</emphasis> effect. So the input file must be formatted properly.
              </para>
              <para>
                All parameters controlling the target table(s), the columns, the source directory and so on still work.
                Including the import directly from a ZIP archive.
              </para>
						</entry>
					</row>
				</tbody>
			</tgroup>
		</informaltable>

	</section>

	<section id="text-import-examples">
		<title>Text Import Examples</title>

    <section id="wbimport-example-1">
      <title>Importing date columns</title>
        <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,birthday
         -dateformat="yyyy-MM-dd";</programlisting>

      <para>
        This imports a file with three columns into a table named person. The
        first column in the file is <literal>lastname</literal>, the second column
        is <literal>firstname</literal> and the third column is <literal>birthday</literal>.
        Values in date columns are formated as yyyy-MM-dd
      </para>

      <note><para>
        A special timestamp format <literal>millis</literal> is availalbe to identify times represented in
        milliseconds (since January 1, 1970, 00:00:00 GMT).
      </para></note>
   </section>

  <section id="wbimport-example-2">
    <title>Excluding input columns from the import</title>
    <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,$wb_skip$,birthday
         -dateformat="yyyy-MM-dd";</programlisting>

     <para>
       This will import a file with four columns. The third column in the file
       does not have a corresponding column in the table <literal>person</literal>
       so its specified as <literal>$wb_skip$</literal> and will not be imported.
     </para>

    <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,phone,birthday
         -importcolumns=lastname,firstname;</programlisting>

    <para>
      This will import a file with four columns where all columns
      exist in the target table. Only <literal>lastname</literal> and
      <literal>firstname</literal> will be imported. The same effect could
      be achieved by specifying $wb_skip$ for the last two columns and leaving
      out the -importcolumns switch. Using -importcolumns is a bit more readable
      because you can still see the structure of the input file. The
      version with <literal>$wb_skip$</literal> is mandatory if the input file
      contains columns that do not exist in the target table.
    </para>
   </section>

  <section id="wbimport-example-3">
    <title>Importing a file with fixed column widths</title>
    <programlisting>WbImport -file=cust_data.txt
         -table=customer
         -filecolumns=custnr,accountid,region_code
         -columnWidths='custnr=10,accountid=10,region_code=2';</programlisting>

     <para>
       This will import a file with three columns. The first column named <literal>custnr</literal> is taken
       from the characters 1-10, the second column named <literal>accountid</literal> is taken from
       the characters 21-30 and the third the column <literal>region_code</literal> is taken from
       characters 31 and 32
     </para>
   </section>

   <section id="wbimport-example-4">

    <title>Filtering rows during import</title>
    <para>
      If you want to import certain rows from the input file, you can
      use regular expressions:
    </para>

    <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=lastname,firstname,birthday
         -columnfilter=lastname="^Bee.*",firstname="^Za.*"
         -dateformat="yyyy-MM-dd";</programlisting>

    <para>
      The above statement will import only rows where the column <literal>lastname</literal>
      contains values that start with <literal>Bee</literal> and the column <literal>firstname</literal>
      contains values that start with <literal>Za</literal>. So <literal>Zaphod Beeblebrox</literal>
      would be imported, <literal>Arthur Beeblebrox</literal> would not be imported.
    </para>

    <para>
      If you want to learn more about regular expressions, please have a look
      at <ulink url="http://www.regular-expressions.info/"/>
    </para>

    <para>
      If you want to limit the rows that are updated but cannot filter them
      from the input file using <literal>-columnfilter</literal> or <literal>-linefilter</literal>,
      use the <literal>-updatewhere</literal> parameter:
    </para>

    <programlisting>WbImport -file=c:/temp/contacts.txt
         -table=person
         -filecolumns=id,lastname,firstname,birthday
         -keycolumns=id
         -mode=update
         -updatewhere="source &lt;&gt; 'manual'"</programlisting>

    <para>
      This will update the table <literal>PERSON</literal>. The generated <literal>UPDATE</literal>
      statement would normally be: <literal>UPDATE person SET lastname=?, firstname=?, birthday=? WHERE id=?</literal>.
      The table contains entries that are maintained manually (identified by the value 'manual' in
      the column <literal>source</literal>) and should not be updated by &wb-productname;. By specifying
      the <literal>-updatewhere</literal> parameter, the above <literal>UPDATE</literal> statement will
      be extended to <literal>WHERE id=? AND (source &lt;&gt; 'manual')</literal>. Thus skipping
      records that are flagged as manual even if they are contained in the input file.
    </para>

  </section>

  <section id="wbimport-example-5">
    <title>Importing several files</title>

    <programlisting>WbImport -sourceDir=c:/data/backup
         -extension=txt
         -header=true</programlisting>

    <para>
      This will import all files with the extension <literal>txt</literal> located in the
      directory <literal>c:/data/backup</literal> into the database. This assumes that
      each filename indicates the name of the target table.
    </para>

    <programlisting>WbImport -sourceDir=c:/data/backup
         -extension=txt
         -table=person
         -header=true</programlisting>

    <para>
      This will import all files with the extension <literal>txt</literal> located in the
      directory <literal>c:/data/backup</literal> into the table <literal>person</literal> regardless
      of the name of the input file. In this mode, the parameter <literal>-deleteTarget</literal>
      will be ignored.
    </para>
  </section>

  <section id="wbimport-lookup-select">
    <title>Populating columns from the database</title>
    <para>
      When your input file does not contain the actual values to be stored in the target table, but e.g. lookup values, you
      can specify a SELECT statement to retrieve the necessary primary key of the lookup table.
    </para>
    <para>
      Consider the following tables:
      <simplelist columns="1">
        <member>
          <literal>contact (contact_id, first_name, last_name, type_id)</literal>
        </member>
        <member><literal>contact_type (type_id, type_name)</literal></member>
      </simplelist>
    </para>
    <para>
      The table <literal>contact_type</literal> contains: (1, 'business'), (2, 'private'), (3, 'other').
    </para>
    <para>
      Your input file only contains <literal>contact_id, first_name, last_name, type_name</literal>. Where <literal>type_name</literal>
      references an entry from the <literal>contact_type</literal> table.
    </para>
    <para>
      To import this file, the following statement can be used:
    </para>
    <programlisting>WbImport
  -file=contacts.txt
  -type=text
  -header=true
  -table=contact
  -importColumns=contact_id, first_name, last_name
  -constantValues="type_id=$@{SELECT type_id FROM contact_type WHERE type_name = $4}"
         </programlisting>
    <para>
      For every row from the input file, &wb-productname; will run the specified SELECT statement. The value of the first column
      of the first row that is returned by the SELECT, will then be used to populate the <literal>type_id</literal> column. The SELECT
      statement will use the value of the third column of the row that is currently being inserted as the value for the WHERE condition.
    </para>
    <para>
      You must use the -importColumns parameter as well to make sure the type_name column is not processed! As an alternative
      you can also use <literal>-fileColumns=contact_id, first_name, last_name, $wb_skip$</literal> instead of -importColumns.
    </para>
    <note>
      <para>The "placeholders" with the column index must not be quoted (e.g. '$1' for a character column will not work)!</para>
    </note>
    <para>
      If the column <literal>contact_id</literal> should be populated by a sequence, the above statement can be extended to
      include a function call to retrieve the sequence value (PostgreSQL syntax:)
    </para>

    <programlisting>WbImport
  -file=contacts.txt
  -type=text
  -header=true
  -table=contact
  -importColumns=first_name, last_name
  -constantValues="id=${nextval('contact_id_seq'::regclass)}"
  -constantValues="type_id=$@{SELECT type_id FROM contact_type WHERE type_name = $4}"</programlisting>
    <para>
      As the ID column is now populated through a constant expression, it may not appear in the <literal>-importColumns</literal> list. Again you
      could alternatively use  <literal>-fileColumns=$wb_skip$, first_name, last_name, $wb_skip$</literal> to make sure the columns that
      are populated through the -constantValue parameter are not taken from the input file.
    </para>

  </section>

</section>

<section id="import-xml-parameters">
	<title>Parameters for the type XML</title>

		<para>
			The XML import only works with files generated by the <link linkend="command-export">WbExport</link>
			command.
		</para>

			<informaltable frame="all">
				<tgroup cols="2"  align="left">
					<colspec colname="c1" colwidth="4cm" />
					<colspec colname="c2" />
					<thead>
						<row>
							<entry>Parameter</entry>
							<entry>Description</entry>
						</row>
					</thead>
					<tbody valign="top">

						<row>
							<entry>-verboseXML</entry>
							<entry>
								<para>Possible values: <literal>true</literal>, <literal>false</literal></para>
								<para>
									If the XML was generated with <literal>-verboseXML=false</literal>
									then this needs to be specified also when importing the file.
									Beginning with build 78, the &wb-productname; writes the information
									about the used tags into the meta information. So it is no
									longer necessary to specify whether -verboseXML was true when
									creating the XML file.
								</para>
							</entry>
						</row>

						<row>
							<entry>-sourceDir</entry>
							<entry>
								<para>Specify a directory which contains the XML files.
									All files in that directory ending with ".xml"
									(lowercase!) will be processed.
									The table into which the data is imported is read
									from the XML file, also the columns to be imported. The parameters
									<literal>-keycolumns</literal>, <literal>-table</literal> and
									<literal>-file</literal> are ignored if this parameter is specified.
									If XML files are used that are generated with a version prior to
									build 78, then all files need to use either the long or short
									tag format and the <literal>-verboseXML=false</literal> parameter has
									to be specified if the short format was used.
								</para>
								<para>
									When importing several files at once, the files will be
									imported into the tables specified in the XML files. You cannot
									specify a different table (apart from editing the XML file
									before starting the import).
								</para>
							</entry>
						</row>

						<row>
							<entry>-importColumns</entry>
							<entry>
								<para>
									Defines the columns that should be imported. If all
									columns from the input file should be imported (the default), then
									this parameter can be omited. When specified, the columns have to match
									the column names available in the XML file.
								</para>
							</entry>
						</row>

						<row>
							<entry>-createTarget</entry>
							<entry>If this parameter is set to <literal>true</literal> the target table
							will be created, if it doesn't exist.
							Valid values are <literal>true</literal> or <literal>false</literal>.
							</entry>
						</row>

					</tbody>
				</tgroup>
			</informaltable>
	</section>

	<section id="import-spreadsheet-parameters">
		<title>Parameters for spreadsheet import</title>
    <para>
      Both spreadsheet imports (Microsoft Excel, OpenOffice) support a subset of the parameters that are used for flat file imports.
    </para>
    <para>
      These parameters are:
				<itemizedlist>
          <listitem><simpara><literal>-header</literal></simpara></listitem>
          <listitem><simpara><literal>-fileColumns</literal></simpara></listitem>
          <listitem><simpara><literal>-importColumns</literal></simpara></listitem>
          <listitem><simpara><literal>-nullString</literal></simpara></listitem>
          <listitem><simpara><literal>-emptyStringIsNull</literal></simpara></listitem>
          <listitem><simpara><literal>-illegalDateIsNull</literal></simpara></listitem>
        </itemizedlist>
    </para>
    <para>
      The spreadsheet import does not support specifying a date or timestamp format. It is expected that those
      columns are formatted in such a way that they can be identified as date or timestamps.
    </para>
    <para>
      The spreadsheet import also does not support importing BLOB files that are referenced from within the
      spreadsheet. If you want to import this kind of data, you need to convert the spreadsheet into a text file.
    </para>
    <para>
      The spreadsheet import supports one additional parameter that is not available for the text imports:
    </para>
			<informaltable frame="all">
				<tgroup cols="2"  align="left">
					<colspec colname="c1" colwidth="4cm" />
					<colspec colname="c2" />
					<thead>
						<row>
							<entry>Parameter</entry>
							<entry>Description</entry>
						</row>
					</thead>
          <tbody valign="top">
            <row>
              <entry id="import-sheetnumber">-sheetNumber</entry>
              <entry>
                <para>
                  Selects the spread sheet inside the file to be imported. If this is not specified the first
                  sheet is used. The first sheet has the number 1.
                </para>
                <para>
                  All sheets can be imported with a single command when using <literal>-sheetNumber=*</literal>. In that
                  case it is assumed that each sheet has the same name as the target table.
                </para>
                <para>
                  If all sheets are imported, the parameters <literal>-table</literal>, <literal>-fileColumns</literal>
                  and <literal>-importColumns</literal> are ignored.
                </para>
              </entry>
            </row>
            <row>
              <entry>-sheetName</entry>
              <entry>
                <para>
                  Defines the name of the spreedsheet inside the file to be imported. If this is not specified the first
                  sheet is used.
                </para>
              </entry>
            </row>
            <row id="import-excel-stringdates">
              <entry>-stringDates</entry>
              <entry>
                <para>Possible values: <literal>true</literal>, <literal>false</literal></para>
                <para>
                  By default WbImport tries to read "native" date and timestamp values from an Excel Worksheet. When
                  this parameter is set to <literal>true</literal>, the values for date and timestamp values
                  will be retrieved as a (formatted) string value and then converted using the format specified
                  through the <literal>-timestampFormat</literal> and <literal>-dateFormat</literal> parameters.
                </para>
              </entry>
            </row>
          </tbody>
				</tgroup>
			</informaltable>
  </section>


	<section id="import-update-mode">
		<title>Update mode</title>
		<para>The <literal>-mode</literal> parameter controls the way the data is sent
			to the database. The default is <literal>INSERT</literal>. &wb-productname; will
			generate an <literal>INSERT</literal> statement for each record. If the <literal>INSERT</literal>
			fails no further processing takes place for that record.
		</para>
		<para>If <literal>-mode</literal> is set to <literal>UPDATE</literal>, &wb-productname; will
			generate an <literal>UPDATE</literal> statement for each row. In order for this to work,
			the table needs to have a primary key defined, and all columns of the primary key need to
			be present in the import file. Otherwise the generated <literal>UPDATE</literal> statement
			will modify rows that should not be modified. This can be used to update existing
			data in the database based on the data from the export file.
		</para>

		<para>
			To either update or insert data into the table, both keywords can be specified
			for the <literal>-mode</literal> parameter. The order in which they appear as the parameter
			value, defines the order in which the respective statements are sent to the database. If the first
			statement fails, the second will be executed. For <literal>-mode=insert,update</literal> to
			work properly a primary or unique key has to be defined on the table. &wb-productname;
			will catch any exception (=error) when inserting a record, then it will try updating
			the record, based on the specified key columns.
			The <literal>-mode=update,insert</literal> works the other way. First &wb-productname;
			will try to update the record based on the primary keys. If the DBMS signals that no rows
			have been updated, it is assumed that the row does not exist and the record will be inserted
			into the table. This mode is recommended when no primary or unique key is defined on the table,
			and an <literal>INSERT</literal> would always succeed.
		</para>

		<para>
			The keycolumns defined with the <literal>-keycolumns</literal> parameter don't
			have to match the real primary key, but they should identify one row uniquely.
		</para>

		<para>
			You cannot use the update mode, if the tables in question <emphasis role="bold">only</emphasis>
			consist of key columns (or if only key columns are specified).
			The values from the source are used to build up the <literal>WHERE</literal> clause for
			the <literal>UPDATE</literal> statement.
		</para>
		<para id="import-mode-downgrade">
			If you specify a combined mode (e.g.: <literal>update,insert</literal>) and one
			of the tables involved consists only of key columns, the import will revert to
			<literal>insert</literal> mode. In this case database errors during an <literal>INSERT</literal>
			are not considered as real errors and are silently ignored.
		</para>

		<para>
			For maximum performance, choose the update strategy that will result in a succssful
			first statement more often. As a rule of thumb:
			<itemizedlist>
				<listitem><para>Use <literal>-mode=insert,update</literal>, if you expect more rows to be inserted then updated.</para></listitem>
				<listitem><para>Use <literal>-mode=update,insert</literal>, if you expect more rows to be updated then inserted.</para></listitem>
			</itemizedlist>
		</para>

		<para>
			To use insert/update or update/insert with PostgreSQL, make sure you have
			<link linkend="pg-statement-savepoint">enabled savepoints</link> for the import (which is enabled by default).
		</para>
  </section>
	<section id="import-upsert-mode">
		<title>UPSERT mode</title>

    <para>
      When using <literal>-mode=insert,update</literal> and the DBMS supports a native "UPSERT" functionality,
      &wb-productname; will only use a single "UPSERT" statement instead of two statements as described in the previous chapter.
    </para>
    <para>
      For the following database systems, native UPSERT is currently used:
			<itemizedlist>
        <listitem>
          <para>PostgreSQL 9.5, using <literal>INSERT ... ON CONFLICT</literal>: <ulink url="http://www.postgresql.org/docs/9.5/static/sql-insert.html"/></para>
        </listitem>
        <listitem>
          <para>Firebird 2.1, using <literal>UPDATE OR INSERT</literal>: <ulink url="http://www.firebirdfaq.org/faq220/"/></para>
        </listitem>
        <listitem>
          <para>H2 Database, using <literal>MERGE INTO</literal>: <ulink url="http://www.h2database.com/html/grammar.html#merge"/></para>
        </listitem>
        <listitem>
          <para>MySQL, using <literal>INSERT ... ON DUPLICATE</literal>: <ulink url="http://dev.mysql.com/doc/refman/5.1/en/insert-on-duplicate.html"/></para>
        </listitem>
			</itemizedlist>
    </para>

	</section>

</section>